{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2PixBuilding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "siZMXpLIeJIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8120a1a0-b650-45b2-8ef0-5e280f6aead5"
      },
      "source": [
        "!unzip /content/CMP_facade_DB_base.zip\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "def get_shape(tensor):\n",
        "    return tensor.get_shape().as_list()\n",
        "\n",
        "def batch_norm(*args, **kwargs):\n",
        "\n",
        "    with tf.name_scope('bn'):\n",
        "        bn = tf.layers.batch_normalization(*args, **kwargs)\n",
        "\n",
        "    return bn\n",
        "\n",
        "def lkrelu(x, slope=0.01):\n",
        "    return tf.maximum(slope*x, x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/CMP_facade_DB_base.zip\n",
            "   creating: base/\n",
            "  inflating: base/cmp_b0001.jpg      \n",
            "  inflating: base/cmp_b0001.png      \n",
            "  inflating: base/cmp_b0001.xml      \n",
            "  inflating: base/cmp_b0002.jpg      \n",
            "  inflating: base/cmp_b0002.png      \n",
            "  inflating: base/cmp_b0002.xml      \n",
            "  inflating: base/cmp_b0003.jpg      \n",
            "  inflating: base/cmp_b0003.png      \n",
            "  inflating: base/cmp_b0003.xml      \n",
            "  inflating: base/cmp_b0004.jpg      \n",
            "  inflating: base/cmp_b0004.png      \n",
            "  inflating: base/cmp_b0004.xml      \n",
            "  inflating: base/cmp_b0005.jpg      \n",
            "  inflating: base/cmp_b0005.png      \n",
            "  inflating: base/cmp_b0005.xml      \n",
            "  inflating: base/cmp_b0006.jpg      \n",
            "  inflating: base/cmp_b0006.png      \n",
            "  inflating: base/cmp_b0006.xml      \n",
            "  inflating: base/cmp_b0007.jpg      \n",
            "  inflating: base/cmp_b0007.png      \n",
            "  inflating: base/cmp_b0007.xml      \n",
            "  inflating: base/cmp_b0008.jpg      \n",
            "  inflating: base/cmp_b0008.png      \n",
            "  inflating: base/cmp_b0008.xml      \n",
            "  inflating: base/cmp_b0009.jpg      \n",
            "  inflating: base/cmp_b0009.png      \n",
            "  inflating: base/cmp_b0009.xml      \n",
            "  inflating: base/cmp_b0010.jpg      \n",
            "  inflating: base/cmp_b0010.png      \n",
            "  inflating: base/cmp_b0010.xml      \n",
            "  inflating: base/cmp_b0011.jpg      \n",
            "  inflating: base/cmp_b0011.png      \n",
            "  inflating: base/cmp_b0011.xml      \n",
            "  inflating: base/cmp_b0012.jpg      \n",
            "  inflating: base/cmp_b0012.png      \n",
            "  inflating: base/cmp_b0012.xml      \n",
            "  inflating: base/cmp_b0013.jpg      \n",
            "  inflating: base/cmp_b0013.png      \n",
            "  inflating: base/cmp_b0013.xml      \n",
            "  inflating: base/cmp_b0014.jpg      \n",
            "  inflating: base/cmp_b0014.png      \n",
            "  inflating: base/cmp_b0014.xml      \n",
            "  inflating: base/cmp_b0015.jpg      \n",
            "  inflating: base/cmp_b0015.png      \n",
            "  inflating: base/cmp_b0015.xml      \n",
            "  inflating: base/cmp_b0016.jpg      \n",
            "  inflating: base/cmp_b0016.png      \n",
            "  inflating: base/cmp_b0016.xml      \n",
            "  inflating: base/cmp_b0017.jpg      \n",
            "  inflating: base/cmp_b0017.png      \n",
            "  inflating: base/cmp_b0017.xml      \n",
            "  inflating: base/cmp_b0018.jpg      \n",
            "  inflating: base/cmp_b0018.png      \n",
            "  inflating: base/cmp_b0018.xml      \n",
            "  inflating: base/cmp_b0019.jpg      \n",
            "  inflating: base/cmp_b0019.png      \n",
            "  inflating: base/cmp_b0019.xml      \n",
            "  inflating: base/cmp_b0020.jpg      \n",
            "  inflating: base/cmp_b0020.png      \n",
            "  inflating: base/cmp_b0020.xml      \n",
            "  inflating: base/cmp_b0021.jpg      \n",
            "  inflating: base/cmp_b0021.png      \n",
            "  inflating: base/cmp_b0021.xml      \n",
            "  inflating: base/cmp_b0022.jpg      \n",
            "  inflating: base/cmp_b0022.png      \n",
            "  inflating: base/cmp_b0022.xml      \n",
            "  inflating: base/cmp_b0023.jpg      \n",
            "  inflating: base/cmp_b0023.png      \n",
            "  inflating: base/cmp_b0023.xml      \n",
            "  inflating: base/cmp_b0024.jpg      \n",
            "  inflating: base/cmp_b0024.png      \n",
            "  inflating: base/cmp_b0024.xml      \n",
            "  inflating: base/cmp_b0025.jpg      \n",
            "  inflating: base/cmp_b0025.png      \n",
            "  inflating: base/cmp_b0025.xml      \n",
            "  inflating: base/cmp_b0026.jpg      \n",
            "  inflating: base/cmp_b0026.png      \n",
            "  inflating: base/cmp_b0026.xml      \n",
            "  inflating: base/cmp_b0027.jpg      \n",
            "  inflating: base/cmp_b0027.png      \n",
            "  inflating: base/cmp_b0027.xml      \n",
            "  inflating: base/cmp_b0028.jpg      \n",
            "  inflating: base/cmp_b0028.png      \n",
            "  inflating: base/cmp_b0028.xml      \n",
            "  inflating: base/cmp_b0029.jpg      \n",
            "  inflating: base/cmp_b0029.png      \n",
            "  inflating: base/cmp_b0029.xml      \n",
            "  inflating: base/cmp_b0030.jpg      \n",
            "  inflating: base/cmp_b0030.png      \n",
            "  inflating: base/cmp_b0030.xml      \n",
            "  inflating: base/cmp_b0031.jpg      \n",
            "  inflating: base/cmp_b0031.png      \n",
            "  inflating: base/cmp_b0031.xml      \n",
            "  inflating: base/cmp_b0032.jpg      \n",
            "  inflating: base/cmp_b0032.png      \n",
            "  inflating: base/cmp_b0032.xml      \n",
            "  inflating: base/cmp_b0033.jpg      \n",
            "  inflating: base/cmp_b0033.png      \n",
            "  inflating: base/cmp_b0033.xml      \n",
            "  inflating: base/cmp_b0034.jpg      \n",
            "  inflating: base/cmp_b0034.png      \n",
            "  inflating: base/cmp_b0034.xml      \n",
            "  inflating: base/cmp_b0035.jpg      \n",
            "  inflating: base/cmp_b0035.png      \n",
            "  inflating: base/cmp_b0035.xml      \n",
            "  inflating: base/cmp_b0036.jpg      \n",
            "  inflating: base/cmp_b0036.png      \n",
            "  inflating: base/cmp_b0036.xml      \n",
            "  inflating: base/cmp_b0037.jpg      \n",
            "  inflating: base/cmp_b0037.png      \n",
            "  inflating: base/cmp_b0037.xml      \n",
            "  inflating: base/cmp_b0038.jpg      \n",
            "  inflating: base/cmp_b0038.png      \n",
            "  inflating: base/cmp_b0038.xml      \n",
            "  inflating: base/cmp_b0039.jpg      \n",
            "  inflating: base/cmp_b0039.png      \n",
            "  inflating: base/cmp_b0039.xml      \n",
            "  inflating: base/cmp_b0040.jpg      \n",
            "  inflating: base/cmp_b0040.png      \n",
            "  inflating: base/cmp_b0040.xml      \n",
            "  inflating: base/cmp_b0041.jpg      \n",
            "  inflating: base/cmp_b0041.png      \n",
            "  inflating: base/cmp_b0041.xml      \n",
            "  inflating: base/cmp_b0042.jpg      \n",
            "  inflating: base/cmp_b0042.png      \n",
            "  inflating: base/cmp_b0042.xml      \n",
            "  inflating: base/cmp_b0043.jpg      \n",
            "  inflating: base/cmp_b0043.png      \n",
            "  inflating: base/cmp_b0043.xml      \n",
            "  inflating: base/cmp_b0044.jpg      \n",
            "  inflating: base/cmp_b0044.png      \n",
            "  inflating: base/cmp_b0044.xml      \n",
            "  inflating: base/cmp_b0045.jpg      \n",
            "  inflating: base/cmp_b0045.png      \n",
            "  inflating: base/cmp_b0045.xml      \n",
            "  inflating: base/cmp_b0046.jpg      \n",
            "  inflating: base/cmp_b0046.png      \n",
            "  inflating: base/cmp_b0046.xml      \n",
            "  inflating: base/cmp_b0047.jpg      \n",
            "  inflating: base/cmp_b0047.png      \n",
            "  inflating: base/cmp_b0047.xml      \n",
            "  inflating: base/cmp_b0048.jpg      \n",
            "  inflating: base/cmp_b0048.png      \n",
            "  inflating: base/cmp_b0048.xml      \n",
            "  inflating: base/cmp_b0049.jpg      \n",
            "  inflating: base/cmp_b0049.png      \n",
            "  inflating: base/cmp_b0049.xml      \n",
            "  inflating: base/cmp_b0050.jpg      \n",
            "  inflating: base/cmp_b0050.png      \n",
            "  inflating: base/cmp_b0050.xml      \n",
            "  inflating: base/cmp_b0051.jpg      \n",
            "  inflating: base/cmp_b0051.png      \n",
            "  inflating: base/cmp_b0051.xml      \n",
            "  inflating: base/cmp_b0052.jpg      \n",
            "  inflating: base/cmp_b0052.png      \n",
            "  inflating: base/cmp_b0052.xml      \n",
            "  inflating: base/cmp_b0053.jpg      \n",
            "  inflating: base/cmp_b0053.png      \n",
            "  inflating: base/cmp_b0053.xml      \n",
            "  inflating: base/cmp_b0054.jpg      \n",
            "  inflating: base/cmp_b0054.png      \n",
            "  inflating: base/cmp_b0054.xml      \n",
            "  inflating: base/cmp_b0055.jpg      \n",
            "  inflating: base/cmp_b0055.png      \n",
            "  inflating: base/cmp_b0055.xml      \n",
            "  inflating: base/cmp_b0056.jpg      \n",
            "  inflating: base/cmp_b0056.png      \n",
            "  inflating: base/cmp_b0056.xml      \n",
            "  inflating: base/cmp_b0057.jpg      \n",
            "  inflating: base/cmp_b0057.png      \n",
            "  inflating: base/cmp_b0057.xml      \n",
            "  inflating: base/cmp_b0058.jpg      \n",
            "  inflating: base/cmp_b0058.png      \n",
            "  inflating: base/cmp_b0058.xml      \n",
            "  inflating: base/cmp_b0059.jpg      \n",
            "  inflating: base/cmp_b0059.png      \n",
            "  inflating: base/cmp_b0059.xml      \n",
            "  inflating: base/cmp_b0060.jpg      \n",
            "  inflating: base/cmp_b0060.png      \n",
            "  inflating: base/cmp_b0060.xml      \n",
            "  inflating: base/cmp_b0061.jpg      \n",
            "  inflating: base/cmp_b0061.png      \n",
            "  inflating: base/cmp_b0061.xml      \n",
            "  inflating: base/cmp_b0062.jpg      \n",
            "  inflating: base/cmp_b0062.png      \n",
            "  inflating: base/cmp_b0062.xml      \n",
            "  inflating: base/cmp_b0063.jpg      \n",
            "  inflating: base/cmp_b0063.png      \n",
            "  inflating: base/cmp_b0063.xml      \n",
            "  inflating: base/cmp_b0064.jpg      \n",
            "  inflating: base/cmp_b0064.png      \n",
            "  inflating: base/cmp_b0064.xml      \n",
            "  inflating: base/cmp_b0065.jpg      \n",
            "  inflating: base/cmp_b0065.png      \n",
            "  inflating: base/cmp_b0065.xml      \n",
            "  inflating: base/cmp_b0066.jpg      \n",
            "  inflating: base/cmp_b0066.png      \n",
            "  inflating: base/cmp_b0066.xml      \n",
            "  inflating: base/cmp_b0067.jpg      \n",
            "  inflating: base/cmp_b0067.png      \n",
            "  inflating: base/cmp_b0067.xml      \n",
            "  inflating: base/cmp_b0068.jpg      \n",
            "  inflating: base/cmp_b0068.png      \n",
            "  inflating: base/cmp_b0068.xml      \n",
            "  inflating: base/cmp_b0069.jpg      \n",
            "  inflating: base/cmp_b0069.png      \n",
            "  inflating: base/cmp_b0069.xml      \n",
            "  inflating: base/cmp_b0070.jpg      \n",
            "  inflating: base/cmp_b0070.png      \n",
            "  inflating: base/cmp_b0070.xml      \n",
            "  inflating: base/cmp_b0071.jpg      \n",
            "  inflating: base/cmp_b0071.png      \n",
            "  inflating: base/cmp_b0071.xml      \n",
            "  inflating: base/cmp_b0072.jpg      \n",
            "  inflating: base/cmp_b0072.png      \n",
            "  inflating: base/cmp_b0072.xml      \n",
            "  inflating: base/cmp_b0073.jpg      \n",
            "  inflating: base/cmp_b0073.png      \n",
            "  inflating: base/cmp_b0073.xml      \n",
            "  inflating: base/cmp_b0074.jpg      \n",
            "  inflating: base/cmp_b0074.png      \n",
            "  inflating: base/cmp_b0074.xml      \n",
            "  inflating: base/cmp_b0075.jpg      \n",
            "  inflating: base/cmp_b0075.png      \n",
            "  inflating: base/cmp_b0075.xml      \n",
            "  inflating: base/cmp_b0076.jpg      \n",
            "  inflating: base/cmp_b0076.png      \n",
            "  inflating: base/cmp_b0076.xml      \n",
            "  inflating: base/cmp_b0077.jpg      \n",
            "  inflating: base/cmp_b0077.png      \n",
            "  inflating: base/cmp_b0077.xml      \n",
            "  inflating: base/cmp_b0078.jpg      \n",
            "  inflating: base/cmp_b0078.png      \n",
            "  inflating: base/cmp_b0078.xml      \n",
            "  inflating: base/cmp_b0079.jpg      \n",
            "  inflating: base/cmp_b0079.png      \n",
            "  inflating: base/cmp_b0079.xml      \n",
            "  inflating: base/cmp_b0080.jpg      \n",
            "  inflating: base/cmp_b0080.png      \n",
            "  inflating: base/cmp_b0080.xml      \n",
            "  inflating: base/cmp_b0081.jpg      \n",
            "  inflating: base/cmp_b0081.png      \n",
            "  inflating: base/cmp_b0081.xml      \n",
            "  inflating: base/cmp_b0082.jpg      \n",
            "  inflating: base/cmp_b0082.png      \n",
            "  inflating: base/cmp_b0082.xml      \n",
            "  inflating: base/cmp_b0083.jpg      \n",
            "  inflating: base/cmp_b0083.png      \n",
            "  inflating: base/cmp_b0083.xml      \n",
            "  inflating: base/cmp_b0084.jpg      \n",
            "  inflating: base/cmp_b0084.png      \n",
            "  inflating: base/cmp_b0084.xml      \n",
            "  inflating: base/cmp_b0085.jpg      \n",
            "  inflating: base/cmp_b0085.png      \n",
            "  inflating: base/cmp_b0085.xml      \n",
            "  inflating: base/cmp_b0086.jpg      \n",
            "  inflating: base/cmp_b0086.png      \n",
            "  inflating: base/cmp_b0086.xml      \n",
            "  inflating: base/cmp_b0087.jpg      \n",
            "  inflating: base/cmp_b0087.png      \n",
            "  inflating: base/cmp_b0087.xml      \n",
            "  inflating: base/cmp_b0088.jpg      \n",
            "  inflating: base/cmp_b0088.png      \n",
            "  inflating: base/cmp_b0088.xml      \n",
            "  inflating: base/cmp_b0089.jpg      \n",
            "  inflating: base/cmp_b0089.png      \n",
            "  inflating: base/cmp_b0089.xml      \n",
            "  inflating: base/cmp_b0090.jpg      \n",
            "  inflating: base/cmp_b0090.png      \n",
            "  inflating: base/cmp_b0090.xml      \n",
            "  inflating: base/cmp_b0091.jpg      \n",
            "  inflating: base/cmp_b0091.png      \n",
            "  inflating: base/cmp_b0091.xml      \n",
            "  inflating: base/cmp_b0092.jpg      \n",
            "  inflating: base/cmp_b0092.png      \n",
            "  inflating: base/cmp_b0092.xml      \n",
            "  inflating: base/cmp_b0093.jpg      \n",
            "  inflating: base/cmp_b0093.png      \n",
            "  inflating: base/cmp_b0093.xml      \n",
            "  inflating: base/cmp_b0094.jpg      \n",
            "  inflating: base/cmp_b0094.png      \n",
            "  inflating: base/cmp_b0094.xml      \n",
            "  inflating: base/cmp_b0095.jpg      \n",
            "  inflating: base/cmp_b0095.png      \n",
            "  inflating: base/cmp_b0095.xml      \n",
            "  inflating: base/cmp_b0096.jpg      \n",
            "  inflating: base/cmp_b0096.png      \n",
            "  inflating: base/cmp_b0096.xml      \n",
            "  inflating: base/cmp_b0097.jpg      \n",
            "  inflating: base/cmp_b0097.png      \n",
            "  inflating: base/cmp_b0097.xml      \n",
            "  inflating: base/cmp_b0098.jpg      \n",
            "  inflating: base/cmp_b0098.png      \n",
            "  inflating: base/cmp_b0098.xml      \n",
            "  inflating: base/cmp_b0099.jpg      \n",
            "  inflating: base/cmp_b0099.png      \n",
            "  inflating: base/cmp_b0099.xml      \n",
            "  inflating: base/cmp_b0100.jpg      \n",
            "  inflating: base/cmp_b0100.png      \n",
            "  inflating: base/cmp_b0100.xml      \n",
            "  inflating: base/cmp_b0101.jpg      \n",
            "  inflating: base/cmp_b0101.png      \n",
            "  inflating: base/cmp_b0101.xml      \n",
            "  inflating: base/cmp_b0102.jpg      \n",
            "  inflating: base/cmp_b0102.png      \n",
            "  inflating: base/cmp_b0102.xml      \n",
            "  inflating: base/cmp_b0103.jpg      \n",
            "  inflating: base/cmp_b0103.png      \n",
            "  inflating: base/cmp_b0103.xml      \n",
            "  inflating: base/cmp_b0104.jpg      \n",
            "  inflating: base/cmp_b0104.png      \n",
            "  inflating: base/cmp_b0104.xml      \n",
            "  inflating: base/cmp_b0105.jpg      \n",
            "  inflating: base/cmp_b0105.png      \n",
            "  inflating: base/cmp_b0105.xml      \n",
            "  inflating: base/cmp_b0106.jpg      \n",
            "  inflating: base/cmp_b0106.png      \n",
            "  inflating: base/cmp_b0106.xml      \n",
            "  inflating: base/cmp_b0107.jpg      \n",
            "  inflating: base/cmp_b0107.png      \n",
            "  inflating: base/cmp_b0107.xml      \n",
            "  inflating: base/cmp_b0108.jpg      \n",
            "  inflating: base/cmp_b0108.png      \n",
            "  inflating: base/cmp_b0108.xml      \n",
            "  inflating: base/cmp_b0109.jpg      \n",
            "  inflating: base/cmp_b0109.png      \n",
            "  inflating: base/cmp_b0109.xml      \n",
            "  inflating: base/cmp_b0110.jpg      \n",
            "  inflating: base/cmp_b0110.png      \n",
            "  inflating: base/cmp_b0110.xml      \n",
            "  inflating: base/cmp_b0111.jpg      \n",
            "  inflating: base/cmp_b0111.png      \n",
            "  inflating: base/cmp_b0111.xml      \n",
            "  inflating: base/cmp_b0112.jpg      \n",
            "  inflating: base/cmp_b0112.png      \n",
            "  inflating: base/cmp_b0112.xml      \n",
            "  inflating: base/cmp_b0113.jpg      \n",
            "  inflating: base/cmp_b0113.png      \n",
            "  inflating: base/cmp_b0113.xml      \n",
            "  inflating: base/cmp_b0114.jpg      \n",
            "  inflating: base/cmp_b0114.png      \n",
            "  inflating: base/cmp_b0114.xml      \n",
            "  inflating: base/cmp_b0115.jpg      \n",
            "  inflating: base/cmp_b0115.png      \n",
            "  inflating: base/cmp_b0115.xml      \n",
            "  inflating: base/cmp_b0116.jpg      \n",
            "  inflating: base/cmp_b0116.png      \n",
            "  inflating: base/cmp_b0116.xml      \n",
            "  inflating: base/cmp_b0117.jpg      \n",
            "  inflating: base/cmp_b0117.png      \n",
            "  inflating: base/cmp_b0117.xml      \n",
            "  inflating: base/cmp_b0118.jpg      \n",
            "  inflating: base/cmp_b0118.png      \n",
            "  inflating: base/cmp_b0118.xml      \n",
            "  inflating: base/cmp_b0119.jpg      \n",
            "  inflating: base/cmp_b0119.png      \n",
            "  inflating: base/cmp_b0119.xml      \n",
            "  inflating: base/cmp_b0120.jpg      \n",
            "  inflating: base/cmp_b0120.png      \n",
            "  inflating: base/cmp_b0120.xml      \n",
            "  inflating: base/cmp_b0121.jpg      \n",
            "  inflating: base/cmp_b0121.png      \n",
            "  inflating: base/cmp_b0121.xml      \n",
            "  inflating: base/cmp_b0122.jpg      \n",
            "  inflating: base/cmp_b0122.png      \n",
            "  inflating: base/cmp_b0122.xml      \n",
            "  inflating: base/cmp_b0123.jpg      \n",
            "  inflating: base/cmp_b0123.png      \n",
            "  inflating: base/cmp_b0123.xml      \n",
            "  inflating: base/cmp_b0124.jpg      \n",
            "  inflating: base/cmp_b0124.png      \n",
            "  inflating: base/cmp_b0124.xml      \n",
            "  inflating: base/cmp_b0125.jpg      \n",
            "  inflating: base/cmp_b0125.png      \n",
            "  inflating: base/cmp_b0125.xml      \n",
            "  inflating: base/cmp_b0126.jpg      \n",
            "  inflating: base/cmp_b0126.png      \n",
            "  inflating: base/cmp_b0126.xml      \n",
            "  inflating: base/cmp_b0127.jpg      \n",
            "  inflating: base/cmp_b0127.png      \n",
            "  inflating: base/cmp_b0127.xml      \n",
            "  inflating: base/cmp_b0128.jpg      \n",
            "  inflating: base/cmp_b0128.png      \n",
            "  inflating: base/cmp_b0128.xml      \n",
            "  inflating: base/cmp_b0129.jpg      \n",
            "  inflating: base/cmp_b0129.png      \n",
            "  inflating: base/cmp_b0129.xml      \n",
            "  inflating: base/cmp_b0130.jpg      \n",
            "  inflating: base/cmp_b0130.png      \n",
            "  inflating: base/cmp_b0130.xml      \n",
            "  inflating: base/cmp_b0131.jpg      \n",
            "  inflating: base/cmp_b0131.png      \n",
            "  inflating: base/cmp_b0131.xml      \n",
            "  inflating: base/cmp_b0132.jpg      \n",
            "  inflating: base/cmp_b0132.png      \n",
            "  inflating: base/cmp_b0132.xml      \n",
            "  inflating: base/cmp_b0133.jpg      \n",
            "  inflating: base/cmp_b0133.png      \n",
            "  inflating: base/cmp_b0133.xml      \n",
            "  inflating: base/cmp_b0134.jpg      \n",
            "  inflating: base/cmp_b0134.png      \n",
            "  inflating: base/cmp_b0134.xml      \n",
            "  inflating: base/cmp_b0135.jpg      \n",
            "  inflating: base/cmp_b0135.png      \n",
            "  inflating: base/cmp_b0135.xml      \n",
            "  inflating: base/cmp_b0136.jpg      \n",
            "  inflating: base/cmp_b0136.png      \n",
            "  inflating: base/cmp_b0136.xml      \n",
            "  inflating: base/cmp_b0137.jpg      \n",
            "  inflating: base/cmp_b0137.png      \n",
            "  inflating: base/cmp_b0137.xml      \n",
            "  inflating: base/cmp_b0138.jpg      \n",
            "  inflating: base/cmp_b0138.png      \n",
            "  inflating: base/cmp_b0138.xml      \n",
            "  inflating: base/cmp_b0139.jpg      \n",
            "  inflating: base/cmp_b0139.png      \n",
            "  inflating: base/cmp_b0139.xml      \n",
            "  inflating: base/cmp_b0140.jpg      \n",
            "  inflating: base/cmp_b0140.png      \n",
            "  inflating: base/cmp_b0140.xml      \n",
            "  inflating: base/cmp_b0141.jpg      \n",
            "  inflating: base/cmp_b0141.png      \n",
            "  inflating: base/cmp_b0141.xml      \n",
            "  inflating: base/cmp_b0142.jpg      \n",
            "  inflating: base/cmp_b0142.png      \n",
            "  inflating: base/cmp_b0142.xml      \n",
            "  inflating: base/cmp_b0143.jpg      \n",
            "  inflating: base/cmp_b0143.png      \n",
            "  inflating: base/cmp_b0143.xml      \n",
            "  inflating: base/cmp_b0144.jpg      \n",
            "  inflating: base/cmp_b0144.png      \n",
            "  inflating: base/cmp_b0144.xml      \n",
            "  inflating: base/cmp_b0145.jpg      \n",
            "  inflating: base/cmp_b0145.png      \n",
            "  inflating: base/cmp_b0145.xml      \n",
            "  inflating: base/cmp_b0146.jpg      \n",
            "  inflating: base/cmp_b0146.png      \n",
            "  inflating: base/cmp_b0146.xml      \n",
            "  inflating: base/cmp_b0147.jpg      \n",
            "  inflating: base/cmp_b0147.png      \n",
            "  inflating: base/cmp_b0147.xml      \n",
            "  inflating: base/cmp_b0148.jpg      \n",
            "  inflating: base/cmp_b0148.png      \n",
            "  inflating: base/cmp_b0148.xml      \n",
            "  inflating: base/cmp_b0149.jpg      \n",
            "  inflating: base/cmp_b0149.png      \n",
            "  inflating: base/cmp_b0149.xml      \n",
            "  inflating: base/cmp_b0150.jpg      \n",
            "  inflating: base/cmp_b0150.png      \n",
            "  inflating: base/cmp_b0150.xml      \n",
            "  inflating: base/cmp_b0151.jpg      \n",
            "  inflating: base/cmp_b0151.png      \n",
            "  inflating: base/cmp_b0151.xml      \n",
            "  inflating: base/cmp_b0152.jpg      \n",
            "  inflating: base/cmp_b0152.png      \n",
            "  inflating: base/cmp_b0152.xml      \n",
            "  inflating: base/cmp_b0153.jpg      \n",
            "  inflating: base/cmp_b0153.png      \n",
            "  inflating: base/cmp_b0153.xml      \n",
            "  inflating: base/cmp_b0154.jpg      \n",
            "  inflating: base/cmp_b0154.png      \n",
            "  inflating: base/cmp_b0154.xml      \n",
            "  inflating: base/cmp_b0155.jpg      \n",
            "  inflating: base/cmp_b0155.png      \n",
            "  inflating: base/cmp_b0155.xml      \n",
            "  inflating: base/cmp_b0156.jpg      \n",
            "  inflating: base/cmp_b0156.png      \n",
            "  inflating: base/cmp_b0156.xml      \n",
            "  inflating: base/cmp_b0157.jpg      \n",
            "  inflating: base/cmp_b0157.png      \n",
            "  inflating: base/cmp_b0157.xml      \n",
            "  inflating: base/cmp_b0158.jpg      \n",
            "  inflating: base/cmp_b0158.png      \n",
            "  inflating: base/cmp_b0158.xml      \n",
            "  inflating: base/cmp_b0159.jpg      \n",
            "  inflating: base/cmp_b0159.png      \n",
            "  inflating: base/cmp_b0159.xml      \n",
            "  inflating: base/cmp_b0160.jpg      \n",
            "  inflating: base/cmp_b0160.png      \n",
            "  inflating: base/cmp_b0160.xml      \n",
            "  inflating: base/cmp_b0161.jpg      \n",
            "  inflating: base/cmp_b0161.png      \n",
            "  inflating: base/cmp_b0161.xml      \n",
            "  inflating: base/cmp_b0162.jpg      \n",
            "  inflating: base/cmp_b0162.png      \n",
            "  inflating: base/cmp_b0162.xml      \n",
            "  inflating: base/cmp_b0163.jpg      \n",
            "  inflating: base/cmp_b0163.png      \n",
            "  inflating: base/cmp_b0163.xml      \n",
            "  inflating: base/cmp_b0164.jpg      \n",
            "  inflating: base/cmp_b0164.png      \n",
            "  inflating: base/cmp_b0164.xml      \n",
            "  inflating: base/cmp_b0165.jpg      \n",
            "  inflating: base/cmp_b0165.png      \n",
            "  inflating: base/cmp_b0165.xml      \n",
            "  inflating: base/cmp_b0166.jpg      \n",
            "  inflating: base/cmp_b0166.png      \n",
            "  inflating: base/cmp_b0166.xml      \n",
            "  inflating: base/cmp_b0167.jpg      \n",
            "  inflating: base/cmp_b0167.png      \n",
            "  inflating: base/cmp_b0167.xml      \n",
            "  inflating: base/cmp_b0168.jpg      \n",
            "  inflating: base/cmp_b0168.png      \n",
            "  inflating: base/cmp_b0168.xml      \n",
            "  inflating: base/cmp_b0169.jpg      \n",
            "  inflating: base/cmp_b0169.png      \n",
            "  inflating: base/cmp_b0169.xml      \n",
            "  inflating: base/cmp_b0170.jpg      \n",
            "  inflating: base/cmp_b0170.png      \n",
            "  inflating: base/cmp_b0170.xml      \n",
            "  inflating: base/cmp_b0171.jpg      \n",
            "  inflating: base/cmp_b0171.png      \n",
            "  inflating: base/cmp_b0171.xml      \n",
            "  inflating: base/cmp_b0172.jpg      \n",
            "  inflating: base/cmp_b0172.png      \n",
            "  inflating: base/cmp_b0172.xml      \n",
            "  inflating: base/cmp_b0173.jpg      \n",
            "  inflating: base/cmp_b0173.png      \n",
            "  inflating: base/cmp_b0173.xml      \n",
            "  inflating: base/cmp_b0174.jpg      \n",
            "  inflating: base/cmp_b0174.png      \n",
            "  inflating: base/cmp_b0174.xml      \n",
            "  inflating: base/cmp_b0175.jpg      \n",
            "  inflating: base/cmp_b0175.png      \n",
            "  inflating: base/cmp_b0175.xml      \n",
            "  inflating: base/cmp_b0176.jpg      \n",
            "  inflating: base/cmp_b0176.png      \n",
            "  inflating: base/cmp_b0176.xml      \n",
            "  inflating: base/cmp_b0177.jpg      \n",
            "  inflating: base/cmp_b0177.png      \n",
            "  inflating: base/cmp_b0177.xml      \n",
            "  inflating: base/cmp_b0178.jpg      \n",
            "  inflating: base/cmp_b0178.png      \n",
            "  inflating: base/cmp_b0178.xml      \n",
            "  inflating: base/cmp_b0179.jpg      \n",
            "  inflating: base/cmp_b0179.png      \n",
            "  inflating: base/cmp_b0179.xml      \n",
            "  inflating: base/cmp_b0180.jpg      \n",
            "  inflating: base/cmp_b0180.png      \n",
            "  inflating: base/cmp_b0180.xml      \n",
            "  inflating: base/cmp_b0181.jpg      \n",
            "  inflating: base/cmp_b0181.png      \n",
            "  inflating: base/cmp_b0181.xml      \n",
            "  inflating: base/cmp_b0182.jpg      \n",
            "  inflating: base/cmp_b0182.png      \n",
            "  inflating: base/cmp_b0182.xml      \n",
            "  inflating: base/cmp_b0183.jpg      \n",
            "  inflating: base/cmp_b0183.png      \n",
            "  inflating: base/cmp_b0183.xml      \n",
            "  inflating: base/cmp_b0184.jpg      \n",
            "  inflating: base/cmp_b0184.png      \n",
            "  inflating: base/cmp_b0184.xml      \n",
            "  inflating: base/cmp_b0185.jpg      \n",
            "  inflating: base/cmp_b0185.png      \n",
            "  inflating: base/cmp_b0185.xml      \n",
            "  inflating: base/cmp_b0186.jpg      \n",
            "  inflating: base/cmp_b0186.png      \n",
            "  inflating: base/cmp_b0186.xml      \n",
            "  inflating: base/cmp_b0187.jpg      \n",
            "  inflating: base/cmp_b0187.png      \n",
            "  inflating: base/cmp_b0187.xml      \n",
            "  inflating: base/cmp_b0188.jpg      \n",
            "  inflating: base/cmp_b0188.png      \n",
            "  inflating: base/cmp_b0188.xml      \n",
            "  inflating: base/cmp_b0189.jpg      \n",
            "  inflating: base/cmp_b0189.png      \n",
            "  inflating: base/cmp_b0189.xml      \n",
            "  inflating: base/cmp_b0190.jpg      \n",
            "  inflating: base/cmp_b0190.png      \n",
            "  inflating: base/cmp_b0190.xml      \n",
            "  inflating: base/cmp_b0191.jpg      \n",
            "  inflating: base/cmp_b0191.png      \n",
            "  inflating: base/cmp_b0191.xml      \n",
            "  inflating: base/cmp_b0192.jpg      \n",
            "  inflating: base/cmp_b0192.png      \n",
            "  inflating: base/cmp_b0192.xml      \n",
            "  inflating: base/cmp_b0193.jpg      \n",
            "  inflating: base/cmp_b0193.png      \n",
            "  inflating: base/cmp_b0193.xml      \n",
            "  inflating: base/cmp_b0194.jpg      \n",
            "  inflating: base/cmp_b0194.png      \n",
            "  inflating: base/cmp_b0194.xml      \n",
            "  inflating: base/cmp_b0195.jpg      \n",
            "  inflating: base/cmp_b0195.png      \n",
            "  inflating: base/cmp_b0195.xml      \n",
            "  inflating: base/cmp_b0196.jpg      \n",
            "  inflating: base/cmp_b0196.png      \n",
            "  inflating: base/cmp_b0196.xml      \n",
            "  inflating: base/cmp_b0197.jpg      \n",
            "  inflating: base/cmp_b0197.png      \n",
            "  inflating: base/cmp_b0197.xml      \n",
            "  inflating: base/cmp_b0198.jpg      \n",
            "  inflating: base/cmp_b0198.png      \n",
            "  inflating: base/cmp_b0198.xml      \n",
            "  inflating: base/cmp_b0199.jpg      \n",
            "  inflating: base/cmp_b0199.png      \n",
            "  inflating: base/cmp_b0199.xml      \n",
            "  inflating: base/cmp_b0200.jpg      \n",
            "  inflating: base/cmp_b0200.png      \n",
            "  inflating: base/cmp_b0200.xml      \n",
            "  inflating: base/cmp_b0201.jpg      \n",
            "  inflating: base/cmp_b0201.png      \n",
            "  inflating: base/cmp_b0201.xml      \n",
            "  inflating: base/cmp_b0202.jpg      \n",
            "  inflating: base/cmp_b0202.png      \n",
            "  inflating: base/cmp_b0202.xml      \n",
            "  inflating: base/cmp_b0203.jpg      \n",
            "  inflating: base/cmp_b0203.png      \n",
            "  inflating: base/cmp_b0203.xml      \n",
            "  inflating: base/cmp_b0204.jpg      \n",
            "  inflating: base/cmp_b0204.png      \n",
            "  inflating: base/cmp_b0204.xml      \n",
            "  inflating: base/cmp_b0205.jpg      \n",
            "  inflating: base/cmp_b0205.png      \n",
            "  inflating: base/cmp_b0205.xml      \n",
            "  inflating: base/cmp_b0206.jpg      \n",
            "  inflating: base/cmp_b0206.png      \n",
            "  inflating: base/cmp_b0206.xml      \n",
            "  inflating: base/cmp_b0207.jpg      \n",
            "  inflating: base/cmp_b0207.png      \n",
            "  inflating: base/cmp_b0207.xml      \n",
            "  inflating: base/cmp_b0208.jpg      \n",
            "  inflating: base/cmp_b0208.png      \n",
            "  inflating: base/cmp_b0208.xml      \n",
            "  inflating: base/cmp_b0209.jpg      \n",
            "  inflating: base/cmp_b0209.png      \n",
            "  inflating: base/cmp_b0209.xml      \n",
            "  inflating: base/cmp_b0210.jpg      \n",
            "  inflating: base/cmp_b0210.png      \n",
            "  inflating: base/cmp_b0210.xml      \n",
            "  inflating: base/cmp_b0211.jpg      \n",
            "  inflating: base/cmp_b0211.png      \n",
            "  inflating: base/cmp_b0211.xml      \n",
            "  inflating: base/cmp_b0212.jpg      \n",
            "  inflating: base/cmp_b0212.png      \n",
            "  inflating: base/cmp_b0212.xml      \n",
            "  inflating: base/cmp_b0213.jpg      \n",
            "  inflating: base/cmp_b0213.png      \n",
            "  inflating: base/cmp_b0213.xml      \n",
            "  inflating: base/cmp_b0214.jpg      \n",
            "  inflating: base/cmp_b0214.png      \n",
            "  inflating: base/cmp_b0214.xml      \n",
            "  inflating: base/cmp_b0215.jpg      \n",
            "  inflating: base/cmp_b0215.png      \n",
            "  inflating: base/cmp_b0215.xml      \n",
            "  inflating: base/cmp_b0216.jpg      \n",
            "  inflating: base/cmp_b0216.png      \n",
            "  inflating: base/cmp_b0216.xml      \n",
            "  inflating: base/cmp_b0217.jpg      \n",
            "  inflating: base/cmp_b0217.png      \n",
            "  inflating: base/cmp_b0217.xml      \n",
            "  inflating: base/cmp_b0218.jpg      \n",
            "  inflating: base/cmp_b0218.png      \n",
            "  inflating: base/cmp_b0218.xml      \n",
            "  inflating: base/cmp_b0219.jpg      \n",
            "  inflating: base/cmp_b0219.png      \n",
            "  inflating: base/cmp_b0219.xml      \n",
            "  inflating: base/cmp_b0220.jpg      \n",
            "  inflating: base/cmp_b0220.png      \n",
            "  inflating: base/cmp_b0220.xml      \n",
            "  inflating: base/cmp_b0221.jpg      \n",
            "  inflating: base/cmp_b0221.png      \n",
            "  inflating: base/cmp_b0221.xml      \n",
            "  inflating: base/cmp_b0222.jpg      \n",
            "  inflating: base/cmp_b0222.png      \n",
            "  inflating: base/cmp_b0222.xml      \n",
            "  inflating: base/cmp_b0223.jpg      \n",
            "  inflating: base/cmp_b0223.png      \n",
            "  inflating: base/cmp_b0223.xml      \n",
            "  inflating: base/cmp_b0224.jpg      \n",
            "  inflating: base/cmp_b0224.png      \n",
            "  inflating: base/cmp_b0224.xml      \n",
            "  inflating: base/cmp_b0225.jpg      \n",
            "  inflating: base/cmp_b0225.png      \n",
            "  inflating: base/cmp_b0225.xml      \n",
            "  inflating: base/cmp_b0226.jpg      \n",
            "  inflating: base/cmp_b0226.png      \n",
            "  inflating: base/cmp_b0226.xml      \n",
            "  inflating: base/cmp_b0227.jpg      \n",
            "  inflating: base/cmp_b0227.png      \n",
            "  inflating: base/cmp_b0227.xml      \n",
            "  inflating: base/cmp_b0228.jpg      \n",
            "  inflating: base/cmp_b0228.png      \n",
            "  inflating: base/cmp_b0228.xml      \n",
            "  inflating: base/cmp_b0229.jpg      \n",
            "  inflating: base/cmp_b0229.png      \n",
            "  inflating: base/cmp_b0229.xml      \n",
            "  inflating: base/cmp_b0230.jpg      \n",
            "  inflating: base/cmp_b0230.png      \n",
            "  inflating: base/cmp_b0230.xml      \n",
            "  inflating: base/cmp_b0231.jpg      \n",
            "  inflating: base/cmp_b0231.png      \n",
            "  inflating: base/cmp_b0231.xml      \n",
            "  inflating: base/cmp_b0232.jpg      \n",
            "  inflating: base/cmp_b0232.png      \n",
            "  inflating: base/cmp_b0232.xml      \n",
            "  inflating: base/cmp_b0233.jpg      \n",
            "  inflating: base/cmp_b0233.png      \n",
            "  inflating: base/cmp_b0233.xml      \n",
            "  inflating: base/cmp_b0234.jpg      \n",
            "  inflating: base/cmp_b0234.png      \n",
            "  inflating: base/cmp_b0234.xml      \n",
            "  inflating: base/cmp_b0235.jpg      \n",
            "  inflating: base/cmp_b0235.png      \n",
            "  inflating: base/cmp_b0235.xml      \n",
            "  inflating: base/cmp_b0236.jpg      \n",
            "  inflating: base/cmp_b0236.png      \n",
            "  inflating: base/cmp_b0236.xml      \n",
            "  inflating: base/cmp_b0237.jpg      \n",
            "  inflating: base/cmp_b0237.png      \n",
            "  inflating: base/cmp_b0237.xml      \n",
            "  inflating: base/cmp_b0238.jpg      \n",
            "  inflating: base/cmp_b0238.png      \n",
            "  inflating: base/cmp_b0238.xml      \n",
            "  inflating: base/cmp_b0239.jpg      \n",
            "  inflating: base/cmp_b0239.png      \n",
            "  inflating: base/cmp_b0239.xml      \n",
            "  inflating: base/cmp_b0240.jpg      \n",
            "  inflating: base/cmp_b0240.png      \n",
            "  inflating: base/cmp_b0240.xml      \n",
            "  inflating: base/cmp_b0241.jpg      \n",
            "  inflating: base/cmp_b0241.png      \n",
            "  inflating: base/cmp_b0241.xml      \n",
            "  inflating: base/cmp_b0242.jpg      \n",
            "  inflating: base/cmp_b0242.png      \n",
            "  inflating: base/cmp_b0242.xml      \n",
            "  inflating: base/cmp_b0243.jpg      \n",
            "  inflating: base/cmp_b0243.png      \n",
            "  inflating: base/cmp_b0243.xml      \n",
            "  inflating: base/cmp_b0244.jpg      \n",
            "  inflating: base/cmp_b0244.png      \n",
            "  inflating: base/cmp_b0244.xml      \n",
            "  inflating: base/cmp_b0245.jpg      \n",
            "  inflating: base/cmp_b0245.png      \n",
            "  inflating: base/cmp_b0245.xml      \n",
            "  inflating: base/cmp_b0246.jpg      \n",
            "  inflating: base/cmp_b0246.png      \n",
            "  inflating: base/cmp_b0246.xml      \n",
            "  inflating: base/cmp_b0247.jpg      \n",
            "  inflating: base/cmp_b0247.png      \n",
            "  inflating: base/cmp_b0247.xml      \n",
            "  inflating: base/cmp_b0248.jpg      \n",
            "  inflating: base/cmp_b0248.png      \n",
            "  inflating: base/cmp_b0248.xml      \n",
            "  inflating: base/cmp_b0249.jpg      \n",
            "  inflating: base/cmp_b0249.png      \n",
            "  inflating: base/cmp_b0249.xml      \n",
            "  inflating: base/cmp_b0250.jpg      \n",
            "  inflating: base/cmp_b0250.png      \n",
            "  inflating: base/cmp_b0250.xml      \n",
            "  inflating: base/cmp_b0251.jpg      \n",
            "  inflating: base/cmp_b0251.png      \n",
            "  inflating: base/cmp_b0251.xml      \n",
            "  inflating: base/cmp_b0252.jpg      \n",
            "  inflating: base/cmp_b0252.png      \n",
            "  inflating: base/cmp_b0252.xml      \n",
            "  inflating: base/cmp_b0253.jpg      \n",
            "  inflating: base/cmp_b0253.png      \n",
            "  inflating: base/cmp_b0253.xml      \n",
            "  inflating: base/cmp_b0254.jpg      \n",
            "  inflating: base/cmp_b0254.png      \n",
            "  inflating: base/cmp_b0254.xml      \n",
            "  inflating: base/cmp_b0255.jpg      \n",
            "  inflating: base/cmp_b0255.png      \n",
            "  inflating: base/cmp_b0255.xml      \n",
            "  inflating: base/cmp_b0256.jpg      \n",
            "  inflating: base/cmp_b0256.png      \n",
            "  inflating: base/cmp_b0256.xml      \n",
            "  inflating: base/cmp_b0257.jpg      \n",
            "  inflating: base/cmp_b0257.png      \n",
            "  inflating: base/cmp_b0257.xml      \n",
            "  inflating: base/cmp_b0258.jpg      \n",
            "  inflating: base/cmp_b0258.png      \n",
            "  inflating: base/cmp_b0258.xml      \n",
            "  inflating: base/cmp_b0259.jpg      \n",
            "  inflating: base/cmp_b0259.png      \n",
            "  inflating: base/cmp_b0259.xml      \n",
            "  inflating: base/cmp_b0260.jpg      \n",
            "  inflating: base/cmp_b0260.png      \n",
            "  inflating: base/cmp_b0260.xml      \n",
            "  inflating: base/cmp_b0261.jpg      \n",
            "  inflating: base/cmp_b0261.png      \n",
            "  inflating: base/cmp_b0261.xml      \n",
            "  inflating: base/cmp_b0262.jpg      \n",
            "  inflating: base/cmp_b0262.png      \n",
            "  inflating: base/cmp_b0262.xml      \n",
            "  inflating: base/cmp_b0263.jpg      \n",
            "  inflating: base/cmp_b0263.png      \n",
            "  inflating: base/cmp_b0263.xml      \n",
            "  inflating: base/cmp_b0264.jpg      \n",
            "  inflating: base/cmp_b0264.png      \n",
            "  inflating: base/cmp_b0264.xml      \n",
            "  inflating: base/cmp_b0265.jpg      \n",
            "  inflating: base/cmp_b0265.png      \n",
            "  inflating: base/cmp_b0265.xml      \n",
            "  inflating: base/cmp_b0266.jpg      \n",
            "  inflating: base/cmp_b0266.png      \n",
            "  inflating: base/cmp_b0266.xml      \n",
            "  inflating: base/cmp_b0267.jpg      \n",
            "  inflating: base/cmp_b0267.png      \n",
            "  inflating: base/cmp_b0267.xml      \n",
            "  inflating: base/cmp_b0268.jpg      \n",
            "  inflating: base/cmp_b0268.png      \n",
            "  inflating: base/cmp_b0268.xml      \n",
            "  inflating: base/cmp_b0269.jpg      \n",
            "  inflating: base/cmp_b0269.png      \n",
            "  inflating: base/cmp_b0269.xml      \n",
            "  inflating: base/cmp_b0270.jpg      \n",
            "  inflating: base/cmp_b0270.png      \n",
            "  inflating: base/cmp_b0270.xml      \n",
            "  inflating: base/cmp_b0271.jpg      \n",
            "  inflating: base/cmp_b0271.png      \n",
            "  inflating: base/cmp_b0271.xml      \n",
            "  inflating: base/cmp_b0272.jpg      \n",
            "  inflating: base/cmp_b0272.png      \n",
            "  inflating: base/cmp_b0272.xml      \n",
            "  inflating: base/cmp_b0273.jpg      \n",
            "  inflating: base/cmp_b0273.png      \n",
            "  inflating: base/cmp_b0273.xml      \n",
            "  inflating: base/cmp_b0274.jpg      \n",
            "  inflating: base/cmp_b0274.png      \n",
            "  inflating: base/cmp_b0274.xml      \n",
            "  inflating: base/cmp_b0275.jpg      \n",
            "  inflating: base/cmp_b0275.png      \n",
            "  inflating: base/cmp_b0275.xml      \n",
            "  inflating: base/cmp_b0276.jpg      \n",
            "  inflating: base/cmp_b0276.png      \n",
            "  inflating: base/cmp_b0276.xml      \n",
            "  inflating: base/cmp_b0277.jpg      \n",
            "  inflating: base/cmp_b0277.png      \n",
            "  inflating: base/cmp_b0277.xml      \n",
            "  inflating: base/cmp_b0278.jpg      \n",
            "  inflating: base/cmp_b0278.png      \n",
            "  inflating: base/cmp_b0278.xml      \n",
            "  inflating: base/cmp_b0279.jpg      \n",
            "  inflating: base/cmp_b0279.png      \n",
            "  inflating: base/cmp_b0279.xml      \n",
            "  inflating: base/cmp_b0280.jpg      \n",
            "  inflating: base/cmp_b0280.png      \n",
            "  inflating: base/cmp_b0280.xml      \n",
            "  inflating: base/cmp_b0281.jpg      \n",
            "  inflating: base/cmp_b0281.png      \n",
            "  inflating: base/cmp_b0281.xml      \n",
            "  inflating: base/cmp_b0282.jpg      \n",
            "  inflating: base/cmp_b0282.png      \n",
            "  inflating: base/cmp_b0282.xml      \n",
            "  inflating: base/cmp_b0283.jpg      \n",
            "  inflating: base/cmp_b0283.png      \n",
            "  inflating: base/cmp_b0283.xml      \n",
            "  inflating: base/cmp_b0284.jpg      \n",
            "  inflating: base/cmp_b0284.png      \n",
            "  inflating: base/cmp_b0284.xml      \n",
            "  inflating: base/cmp_b0285.jpg      \n",
            "  inflating: base/cmp_b0285.png      \n",
            "  inflating: base/cmp_b0285.xml      \n",
            "  inflating: base/cmp_b0286.jpg      \n",
            "  inflating: base/cmp_b0286.png      \n",
            "  inflating: base/cmp_b0286.xml      \n",
            "  inflating: base/cmp_b0287.jpg      \n",
            "  inflating: base/cmp_b0287.png      \n",
            "  inflating: base/cmp_b0287.xml      \n",
            "  inflating: base/cmp_b0288.jpg      \n",
            "  inflating: base/cmp_b0288.png      \n",
            "  inflating: base/cmp_b0288.xml      \n",
            "  inflating: base/cmp_b0289.jpg      \n",
            "  inflating: base/cmp_b0289.png      \n",
            "  inflating: base/cmp_b0289.xml      \n",
            "  inflating: base/cmp_b0290.jpg      \n",
            "  inflating: base/cmp_b0290.png      \n",
            "  inflating: base/cmp_b0290.xml      \n",
            "  inflating: base/cmp_b0291.jpg      \n",
            "  inflating: base/cmp_b0291.png      \n",
            "  inflating: base/cmp_b0291.xml      \n",
            "  inflating: base/cmp_b0292.jpg      \n",
            "  inflating: base/cmp_b0292.png      \n",
            "  inflating: base/cmp_b0292.xml      \n",
            "  inflating: base/cmp_b0293.jpg      \n",
            "  inflating: base/cmp_b0293.png      \n",
            "  inflating: base/cmp_b0293.xml      \n",
            "  inflating: base/cmp_b0294.jpg      \n",
            "  inflating: base/cmp_b0294.png      \n",
            "  inflating: base/cmp_b0294.xml      \n",
            "  inflating: base/cmp_b0295.jpg      \n",
            "  inflating: base/cmp_b0295.png      \n",
            "  inflating: base/cmp_b0295.xml      \n",
            "  inflating: base/cmp_b0296.jpg      \n",
            "  inflating: base/cmp_b0296.png      \n",
            "  inflating: base/cmp_b0296.xml      \n",
            "  inflating: base/cmp_b0297.jpg      \n",
            "  inflating: base/cmp_b0297.png      \n",
            "  inflating: base/cmp_b0297.xml      \n",
            "  inflating: base/cmp_b0298.jpg      \n",
            "  inflating: base/cmp_b0298.png      \n",
            "  inflating: base/cmp_b0298.xml      \n",
            "  inflating: base/cmp_b0299.jpg      \n",
            "  inflating: base/cmp_b0299.png      \n",
            "  inflating: base/cmp_b0299.xml      \n",
            "  inflating: base/cmp_b0300.jpg      \n",
            "  inflating: base/cmp_b0300.png      \n",
            "  inflating: base/cmp_b0300.xml      \n",
            "  inflating: base/cmp_b0301.jpg      \n",
            "  inflating: base/cmp_b0301.png      \n",
            "  inflating: base/cmp_b0301.xml      \n",
            "  inflating: base/cmp_b0302.jpg      \n",
            "  inflating: base/cmp_b0302.png      \n",
            "  inflating: base/cmp_b0302.xml      \n",
            "  inflating: base/cmp_b0303.jpg      \n",
            "  inflating: base/cmp_b0303.png      \n",
            "  inflating: base/cmp_b0303.xml      \n",
            "  inflating: base/cmp_b0304.jpg      \n",
            "  inflating: base/cmp_b0304.png      \n",
            "  inflating: base/cmp_b0304.xml      \n",
            "  inflating: base/cmp_b0305.jpg      \n",
            "  inflating: base/cmp_b0305.png      \n",
            "  inflating: base/cmp_b0305.xml      \n",
            "  inflating: base/cmp_b0306.jpg      \n",
            "  inflating: base/cmp_b0306.png      \n",
            "  inflating: base/cmp_b0306.xml      \n",
            "  inflating: base/cmp_b0307.jpg      \n",
            "  inflating: base/cmp_b0307.png      \n",
            "  inflating: base/cmp_b0307.xml      \n",
            "  inflating: base/cmp_b0308.jpg      \n",
            "  inflating: base/cmp_b0308.png      \n",
            "  inflating: base/cmp_b0308.xml      \n",
            "  inflating: base/cmp_b0309.jpg      \n",
            "  inflating: base/cmp_b0309.png      \n",
            "  inflating: base/cmp_b0309.xml      \n",
            "  inflating: base/cmp_b0310.jpg      \n",
            "  inflating: base/cmp_b0310.png      \n",
            "  inflating: base/cmp_b0310.xml      \n",
            "  inflating: base/cmp_b0311.jpg      \n",
            "  inflating: base/cmp_b0311.png      \n",
            "  inflating: base/cmp_b0311.xml      \n",
            "  inflating: base/cmp_b0312.jpg      \n",
            "  inflating: base/cmp_b0312.png      \n",
            "  inflating: base/cmp_b0312.xml      \n",
            "  inflating: base/cmp_b0313.jpg      \n",
            "  inflating: base/cmp_b0313.png      \n",
            "  inflating: base/cmp_b0313.xml      \n",
            "  inflating: base/cmp_b0314.jpg      \n",
            "  inflating: base/cmp_b0314.png      \n",
            "  inflating: base/cmp_b0314.xml      \n",
            "  inflating: base/cmp_b0315.jpg      \n",
            "  inflating: base/cmp_b0315.png      \n",
            "  inflating: base/cmp_b0315.xml      \n",
            "  inflating: base/cmp_b0316.jpg      \n",
            "  inflating: base/cmp_b0316.png      \n",
            "  inflating: base/cmp_b0316.xml      \n",
            "  inflating: base/cmp_b0317.jpg      \n",
            "  inflating: base/cmp_b0317.png      \n",
            "  inflating: base/cmp_b0317.xml      \n",
            "  inflating: base/cmp_b0318.jpg      \n",
            "  inflating: base/cmp_b0318.png      \n",
            "  inflating: base/cmp_b0318.xml      \n",
            "  inflating: base/cmp_b0319.jpg      \n",
            "  inflating: base/cmp_b0319.png      \n",
            "  inflating: base/cmp_b0319.xml      \n",
            "  inflating: base/cmp_b0320.jpg      \n",
            "  inflating: base/cmp_b0320.png      \n",
            "  inflating: base/cmp_b0320.xml      \n",
            "  inflating: base/cmp_b0321.jpg      \n",
            "  inflating: base/cmp_b0321.png      \n",
            "  inflating: base/cmp_b0321.xml      \n",
            "  inflating: base/cmp_b0322.jpg      \n",
            "  inflating: base/cmp_b0322.png      \n",
            "  inflating: base/cmp_b0322.xml      \n",
            "  inflating: base/cmp_b0323.jpg      \n",
            "  inflating: base/cmp_b0323.png      \n",
            "  inflating: base/cmp_b0323.xml      \n",
            "  inflating: base/cmp_b0324.jpg      \n",
            "  inflating: base/cmp_b0324.png      \n",
            "  inflating: base/cmp_b0324.xml      \n",
            "  inflating: base/cmp_b0325.jpg      \n",
            "  inflating: base/cmp_b0325.png      \n",
            "  inflating: base/cmp_b0325.xml      \n",
            "  inflating: base/cmp_b0326.jpg      \n",
            "  inflating: base/cmp_b0326.png      \n",
            "  inflating: base/cmp_b0326.xml      \n",
            "  inflating: base/cmp_b0327.jpg      \n",
            "  inflating: base/cmp_b0327.png      \n",
            "  inflating: base/cmp_b0327.xml      \n",
            "  inflating: base/cmp_b0328.jpg      \n",
            "  inflating: base/cmp_b0328.png      \n",
            "  inflating: base/cmp_b0328.xml      \n",
            "  inflating: base/cmp_b0329.jpg      \n",
            "  inflating: base/cmp_b0329.png      \n",
            "  inflating: base/cmp_b0329.xml      \n",
            "  inflating: base/cmp_b0330.jpg      \n",
            "  inflating: base/cmp_b0330.png      \n",
            "  inflating: base/cmp_b0330.xml      \n",
            "  inflating: base/cmp_b0331.jpg      \n",
            "  inflating: base/cmp_b0331.png      \n",
            "  inflating: base/cmp_b0331.xml      \n",
            "  inflating: base/cmp_b0332.jpg      \n",
            "  inflating: base/cmp_b0332.png      \n",
            "  inflating: base/cmp_b0332.xml      \n",
            "  inflating: base/cmp_b0333.jpg      \n",
            "  inflating: base/cmp_b0333.png      \n",
            "  inflating: base/cmp_b0333.xml      \n",
            "  inflating: base/cmp_b0334.jpg      \n",
            "  inflating: base/cmp_b0334.png      \n",
            "  inflating: base/cmp_b0334.xml      \n",
            "  inflating: base/cmp_b0335.jpg      \n",
            "  inflating: base/cmp_b0335.png      \n",
            "  inflating: base/cmp_b0335.xml      \n",
            "  inflating: base/cmp_b0336.jpg      \n",
            "  inflating: base/cmp_b0336.png      \n",
            "  inflating: base/cmp_b0336.xml      \n",
            "  inflating: base/cmp_b0337.jpg      \n",
            "  inflating: base/cmp_b0337.png      \n",
            "  inflating: base/cmp_b0337.xml      \n",
            "  inflating: base/cmp_b0338.jpg      \n",
            "  inflating: base/cmp_b0338.png      \n",
            "  inflating: base/cmp_b0338.xml      \n",
            "  inflating: base/cmp_b0339.jpg      \n",
            "  inflating: base/cmp_b0339.png      \n",
            "  inflating: base/cmp_b0339.xml      \n",
            "  inflating: base/cmp_b0340.jpg      \n",
            "  inflating: base/cmp_b0340.png      \n",
            "  inflating: base/cmp_b0340.xml      \n",
            "  inflating: base/cmp_b0341.jpg      \n",
            "  inflating: base/cmp_b0341.png      \n",
            "  inflating: base/cmp_b0341.xml      \n",
            "  inflating: base/cmp_b0342.jpg      \n",
            "  inflating: base/cmp_b0342.png      \n",
            "  inflating: base/cmp_b0342.xml      \n",
            "  inflating: base/cmp_b0343.jpg      \n",
            "  inflating: base/cmp_b0343.png      \n",
            "  inflating: base/cmp_b0343.xml      \n",
            "  inflating: base/cmp_b0344.jpg      \n",
            "  inflating: base/cmp_b0344.png      \n",
            "  inflating: base/cmp_b0344.xml      \n",
            "  inflating: base/cmp_b0345.jpg      \n",
            "  inflating: base/cmp_b0345.png      \n",
            "  inflating: base/cmp_b0345.xml      \n",
            "  inflating: base/cmp_b0346.jpg      \n",
            "  inflating: base/cmp_b0346.png      \n",
            "  inflating: base/cmp_b0346.xml      \n",
            "  inflating: base/cmp_b0347.jpg      \n",
            "  inflating: base/cmp_b0347.png      \n",
            "  inflating: base/cmp_b0347.xml      \n",
            "  inflating: base/cmp_b0348.jpg      \n",
            "  inflating: base/cmp_b0348.png      \n",
            "  inflating: base/cmp_b0348.xml      \n",
            "  inflating: base/cmp_b0349.jpg      \n",
            "  inflating: base/cmp_b0349.png      \n",
            "  inflating: base/cmp_b0349.xml      \n",
            "  inflating: base/cmp_b0350.jpg      \n",
            "  inflating: base/cmp_b0350.png      \n",
            "  inflating: base/cmp_b0350.xml      \n",
            "  inflating: base/cmp_b0351.jpg      \n",
            "  inflating: base/cmp_b0351.png      \n",
            "  inflating: base/cmp_b0351.xml      \n",
            "  inflating: base/cmp_b0352.jpg      \n",
            "  inflating: base/cmp_b0352.png      \n",
            "  inflating: base/cmp_b0352.xml      \n",
            "  inflating: base/cmp_b0353.jpg      \n",
            "  inflating: base/cmp_b0353.png      \n",
            "  inflating: base/cmp_b0353.xml      \n",
            "  inflating: base/cmp_b0354.jpg      \n",
            "  inflating: base/cmp_b0354.png      \n",
            "  inflating: base/cmp_b0354.xml      \n",
            "  inflating: base/cmp_b0355.jpg      \n",
            "  inflating: base/cmp_b0355.png      \n",
            "  inflating: base/cmp_b0355.xml      \n",
            "  inflating: base/cmp_b0356.jpg      \n",
            "  inflating: base/cmp_b0356.png      \n",
            "  inflating: base/cmp_b0356.xml      \n",
            "  inflating: base/cmp_b0357.jpg      \n",
            "  inflating: base/cmp_b0357.png      \n",
            "  inflating: base/cmp_b0357.xml      \n",
            "  inflating: base/cmp_b0358.jpg      \n",
            "  inflating: base/cmp_b0358.png      \n",
            "  inflating: base/cmp_b0358.xml      \n",
            "  inflating: base/cmp_b0359.jpg      \n",
            "  inflating: base/cmp_b0359.png      \n",
            "  inflating: base/cmp_b0359.xml      \n",
            "  inflating: base/cmp_b0360.jpg      \n",
            "  inflating: base/cmp_b0360.png      \n",
            "  inflating: base/cmp_b0360.xml      \n",
            "  inflating: base/cmp_b0361.jpg      \n",
            "  inflating: base/cmp_b0361.png      \n",
            "  inflating: base/cmp_b0361.xml      \n",
            "  inflating: base/cmp_b0362.jpg      \n",
            "  inflating: base/cmp_b0362.png      \n",
            "  inflating: base/cmp_b0362.xml      \n",
            "  inflating: base/cmp_b0363.jpg      \n",
            "  inflating: base/cmp_b0363.png      \n",
            "  inflating: base/cmp_b0363.xml      \n",
            "  inflating: base/cmp_b0364.jpg      \n",
            "  inflating: base/cmp_b0364.png      \n",
            "  inflating: base/cmp_b0364.xml      \n",
            "  inflating: base/cmp_b0365.jpg      \n",
            "  inflating: base/cmp_b0365.png      \n",
            "  inflating: base/cmp_b0365.xml      \n",
            "  inflating: base/cmp_b0366.jpg      \n",
            "  inflating: base/cmp_b0366.png      \n",
            "  inflating: base/cmp_b0366.xml      \n",
            "  inflating: base/cmp_b0367.jpg      \n",
            "  inflating: base/cmp_b0367.png      \n",
            "  inflating: base/cmp_b0367.xml      \n",
            "  inflating: base/cmp_b0368.jpg      \n",
            "  inflating: base/cmp_b0368.png      \n",
            "  inflating: base/cmp_b0368.xml      \n",
            "  inflating: base/cmp_b0369.jpg      \n",
            "  inflating: base/cmp_b0369.png      \n",
            "  inflating: base/cmp_b0369.xml      \n",
            "  inflating: base/cmp_b0370.jpg      \n",
            "  inflating: base/cmp_b0370.png      \n",
            "  inflating: base/cmp_b0370.xml      \n",
            "  inflating: base/cmp_b0371.jpg      \n",
            "  inflating: base/cmp_b0371.png      \n",
            "  inflating: base/cmp_b0371.xml      \n",
            "  inflating: base/cmp_b0372.jpg      \n",
            "  inflating: base/cmp_b0372.png      \n",
            "  inflating: base/cmp_b0372.xml      \n",
            "  inflating: base/cmp_b0373.jpg      \n",
            "  inflating: base/cmp_b0373.png      \n",
            "  inflating: base/cmp_b0373.xml      \n",
            "  inflating: base/cmp_b0374.jpg      \n",
            "  inflating: base/cmp_b0374.png      \n",
            "  inflating: base/cmp_b0374.xml      \n",
            "  inflating: base/cmp_b0375.jpg      \n",
            "  inflating: base/cmp_b0375.png      \n",
            "  inflating: base/cmp_b0375.xml      \n",
            "  inflating: base/cmp_b0376.jpg      \n",
            "  inflating: base/cmp_b0376.png      \n",
            "  inflating: base/cmp_b0376.xml      \n",
            "  inflating: base/cmp_b0377.jpg      \n",
            "  inflating: base/cmp_b0377.png      \n",
            "  inflating: base/cmp_b0377.xml      \n",
            "  inflating: base/cmp_b0378.jpg      \n",
            "  inflating: base/cmp_b0378.png      \n",
            "  inflating: base/cmp_b0378.xml      \n",
            "  inflating: label_names.txt         \n",
            "  inflating: readme.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-39HI40-U04b"
      },
      "source": [
        "class Discriminator(object):\n",
        "    def __init__(self, inputs, is_training, stddev=0.02, center=True, scale=True, reuse=None):\n",
        "        self._is_training = is_training\n",
        "        self._stddev = stddev\n",
        "\n",
        "        with tf.variable_scope('D', initializer=tf.truncated_normal_initializer(stddev=self._stddev), reuse=reuse):\n",
        "            self._center = center\n",
        "            self._scale = scale\n",
        "            self._prob = 0.5\n",
        "            self._inputs = inputs\n",
        "            self._discriminator = self._build_discriminator(inputs, reuse=reuse)\n",
        "\n",
        "    def build_layer(self, name, inputs, k, bn=True, use_dropout=False):\n",
        "        layer = dict()\n",
        "\n",
        "        with tf.variable_scope(name):\n",
        "            layer['filters'] = tf.get_variable('filters', [4, 4, get_shape(inputs)[-1], k])\n",
        "            layer['conv'] = tf.nn.conv2d(inputs, layer['filters'], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            layer['bn'] = batch_norm(layer['conv'], center=self._center, scale=self._scale, training=self._is_training) if bn else layer['conv']\n",
        "            layer['dropout'] = tf.nn.dropout(layer['bn'], self._prob) if use_dropout else layer['bn']\n",
        "            layer['fmap'] = lkrelu(layer['dropout'], slope=0.2)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    def _build_discriminator(self, inputs, reuse=None):\n",
        "        discriminator = dict()\n",
        "\n",
        "        discriminator['l1'] = self.build_layer('l1', inputs, 64, bn=False)\n",
        "        discriminator['l2'] = self.build_layer('l2', discriminator['l1']['fmap'], 128)\n",
        "        discriminator['l3'] = self.build_layer('l3', discriminator['l2']['fmap'], 256)\n",
        "        discriminator['l4'] = self.build_layer('l4', discriminator['l3']['fmap'], 512)\n",
        "\n",
        "        with tf.variable_scope('15'):\n",
        "            l5 = dict()\n",
        "            l5['filters'] = tf.get_variable('filters', [4, 4, get_shape(discriminator['l4']['fmap'])[-1], 1])\n",
        "            l5['conv'] = tf.nn.conv2d(discriminator['l4']['fmap'], l5['filters'], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            l5['bn'] = batch_norm(l5['conv'], center=self._center, scale=self._scale, training=self._is_training)\n",
        "            l5['fmap'] = tf.nn.sigmoid(l5['bn'])\n",
        "            discriminator['l5'] = l5\n",
        "\n",
        "        return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHUkxB0tfMNJ"
      },
      "source": [
        "class Generator(object):\n",
        "    def __init__(self, inputs, is_training, ochan, stddev=0.02, center=True, scale=True, reuse=None):\n",
        "        self._is_training = is_training\n",
        "        self._stddev = stddev\n",
        "        self._ochan = ochan\n",
        "        with tf.variable_scope('G', initializer=tf.truncated_normal_initializer(stddev=self._stddev), reuse=reuse):\n",
        "            self._center = center\n",
        "            self._scale = scale\n",
        "            self._prob = 0.5\n",
        "            self._inputs = inputs\n",
        "            self._encoder = self._build_encoder(inputs)\n",
        "            self._decoder = self._build_decoder(self._encoder)\n",
        "\n",
        "    def _build_encoder_layer(self, name, inputs, k, bn=True, use_dropout=False):\n",
        "        layer = dict()\n",
        "        with tf.variable_scope(name):\n",
        "            layer['filters'] = tf.get_variable('filters', [4, 4, get_shape(inputs)[-1], k])\n",
        "            layer['conv'] = tf.nn.conv2d(inputs, layer['filters'], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            layer['bn'] = batch_norm(layer['conv'], center=self._center, scale=self._scale, training=self._is_training) if bn else layer['conv']\n",
        "            layer['dropout'] = tf.nn.dropout(layer['bn'], self._prob) if use_dropout else layer['bn']\n",
        "            layer['fmap'] = lkrelu(layer['dropout'], slope=0.2)\n",
        "        return layer\n",
        "\n",
        "    def _build_encoder(self, inputs):\n",
        "        encoder = dict()\n",
        "\n",
        "        \n",
        "        with tf.variable_scope('encoder'):\n",
        "            encoder['l1'] = self._build_encoder_layer('l1', inputs, 64, bn=False)\n",
        "            encoder['l2'] = self._build_encoder_layer('l2', encoder['l1']['fmap'], 128)\n",
        "            encoder['l3'] = self._build_encoder_layer('l3', encoder['l2']['fmap'], 256)\n",
        "            encoder['l4'] = self._build_encoder_layer('l4', encoder['l3']['fmap'], 512)\n",
        "            encoder['l5'] = self._build_encoder_layer('l5', encoder['l4']['fmap'], 512)\n",
        "            encoder['l6'] = self._build_encoder_layer('l6', encoder['l5']['fmap'], 512)\n",
        "            encoder['l7'] = self._build_encoder_layer('l7', encoder['l6']['fmap'], 512)\n",
        "            encoder['l8'] = self._build_encoder_layer('l8', encoder['l7']['fmap'], 512)\n",
        "        return encoder\n",
        "\n",
        "    def _build_decoder_layer(self, name, inputs, output_shape_from,use_dropout=False):\n",
        "        layer = dict()\n",
        "\n",
        "        with tf.variable_scope(name):\n",
        "            output_shape = tf.shape(output_shape_from)\n",
        "            layer['filters'] = tf.get_variable('filters', [4, 4, get_shape(output_shape_from)[-1], get_shape(inputs)[-1]])\n",
        "            layer['conv'] = tf.nn.conv2d_transpose(inputs, layer['filters'], output_shape=output_shape, strides=[1, 2, 2, 1], padding='SAME')\n",
        "            layer['bn'] = batch_norm(tf.reshape(layer['conv'], output_shape), center=self._center, scale=self._scale, training=self._is_training)\n",
        "            layer['dropout'] = tf.nn.dropout(layer['bn'], self._prob) if use_dropout else layer['bn']\n",
        "            layer['fmap'] = tf.nn.relu(layer['dropout'])\n",
        "        return layer\n",
        "\n",
        "    def _build_decoder(self, encoder):\n",
        "        decoder = dict()\n",
        "\n",
        "        with tf.variable_scope('decoder'): \n",
        "            decoder['dl1'] = self._build_decoder_layer('dl1', encoder['l8']['fmap'], output_shape_from=encoder['l7']['fmap'], use_dropout=True)\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl1']['fmap'], encoder['l7']['fmap']], axis=3)\n",
        "            decoder['dl2'] = self._build_decoder_layer('dl2', fmap_concat, output_shape_from=encoder['l6']['fmap'], use_dropout=True)\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl2']['fmap'], encoder['l6']['fmap']], axis=3)\n",
        "            decoder['dl3'] = self._build_decoder_layer('dl3', fmap_concat, output_shape_from=encoder['l5']['fmap'], use_dropout=True)\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl3']['fmap'], encoder['l5']['fmap']], axis=3)\n",
        "            decoder['dl4'] = self._build_decoder_layer('dl4', fmap_concat, output_shape_from=encoder['l4']['fmap'])\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl4']['fmap'], encoder['l4']['fmap']], axis=3)\n",
        "            decoder['dl5'] = self._build_decoder_layer('dl5', fmap_concat, output_shape_from=encoder['l3']['fmap'])\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl5']['fmap'], encoder['l3']['fmap']], axis=3)\n",
        "            decoder['dl6'] = self._build_decoder_layer('dl6', fmap_concat, output_shape_from=encoder['l2']['fmap'])\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl6']['fmap'], encoder['l2']['fmap']], axis=3)\n",
        "            decoder['dl7'] = self._build_decoder_layer('dl7', fmap_concat, output_shape_from=encoder['l1']['fmap'])\n",
        "\n",
        "            fmap_concat = tf.concat([decoder['dl7']['fmap'], encoder['l1']['fmap']], axis=3)\n",
        "            decoder['dl8'] = self._build_decoder_layer('dl8', fmap_concat, output_shape_from=self._inputs)\n",
        "\n",
        "            with tf.variable_scope('cl9'):\n",
        "                cl9 = dict()\n",
        "                cl9['filters'] = tf.get_variable('filters', [4, 4, get_shape(decoder['dl8']['fmap'])[-1], self._ochan])\n",
        "                cl9['conv'] =  tf.nn.conv2d(decoder['dl8']['fmap'], cl9['filters'], strides=[1, 1, 1, 1], padding='SAME')\n",
        "                cl9['fmap'] = tf.nn.tanh(cl9['conv'])\n",
        "                decoder['cl9'] = cl9\n",
        "        return decoder\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zy7dmR4qyBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "013f353f-1af9-4cd7-e51e-3cc3efcf82cd"
      },
      "source": [
        "print(os.listdir('/content/base/'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cmp_b0370.png', 'cmp_b0294.xml', 'cmp_b0154.png', 'cmp_b0044.xml', 'cmp_b0358.jpg', 'cmp_b0054.xml', 'cmp_b0129.jpg', 'cmp_b0355.xml', 'cmp_b0273.xml', 'cmp_b0162.png', 'cmp_b0364.xml', 'cmp_b0116.jpg', 'cmp_b0349.xml', 'cmp_b0011.xml', 'cmp_b0089.png', 'cmp_b0026.jpg', 'cmp_b0107.xml', 'cmp_b0163.jpg', 'cmp_b0111.xml', 'cmp_b0080.png', 'cmp_b0178.xml', 'cmp_b0184.png', 'cmp_b0066.png', 'cmp_b0123.jpg', 'cmp_b0367.xml', 'cmp_b0340.jpg', 'cmp_b0290.xml', 'cmp_b0161.xml', 'cmp_b0319.xml', 'cmp_b0236.xml', 'cmp_b0233.png', 'cmp_b0006.xml', 'cmp_b0338.jpg', 'cmp_b0371.png', 'cmp_b0115.xml', 'cmp_b0035.xml', 'cmp_b0170.png', 'cmp_b0339.png', 'cmp_b0232.jpg', 'cmp_b0077.jpg', 'cmp_b0082.jpg', 'cmp_b0237.jpg', 'cmp_b0257.jpg', 'cmp_b0189.xml', 'cmp_b0299.png', 'cmp_b0205.xml', 'cmp_b0051.jpg', 'cmp_b0357.xml', 'cmp_b0186.xml', 'cmp_b0358.png', 'cmp_b0128.xml', 'cmp_b0378.png', 'cmp_b0112.png', 'cmp_b0088.jpg', 'cmp_b0071.xml', 'cmp_b0028.xml', 'cmp_b0246.xml', 'cmp_b0019.xml', 'cmp_b0231.png', 'cmp_b0052.xml', 'cmp_b0053.png', 'cmp_b0210.jpg', 'cmp_b0302.png', 'cmp_b0294.jpg', 'cmp_b0283.xml', 'cmp_b0311.jpg', 'cmp_b0264.png', 'cmp_b0373.png', 'cmp_b0080.jpg', 'cmp_b0222.png', 'cmp_b0316.png', 'cmp_b0004.jpg', 'cmp_b0328.png', 'cmp_b0050.png', 'cmp_b0192.jpg', 'cmp_b0088.xml', 'cmp_b0304.xml', 'cmp_b0010.xml', 'cmp_b0196.png', 'cmp_b0348.jpg', 'cmp_b0278.jpg', 'cmp_b0228.xml', 'cmp_b0051.xml', 'cmp_b0010.jpg', 'cmp_b0241.png', 'cmp_b0228.png', 'cmp_b0024.jpg', 'cmp_b0177.xml', 'cmp_b0206.xml', 'cmp_b0218.jpg', 'cmp_b0139.xml', 'cmp_b0354.png', 'cmp_b0008.xml', 'cmp_b0244.jpg', 'cmp_b0130.xml', 'cmp_b0186.jpg', 'cmp_b0164.jpg', 'cmp_b0032.jpg', 'cmp_b0109.jpg', 'cmp_b0212.jpg', 'cmp_b0208.xml', 'cmp_b0303.xml', 'cmp_b0057.png', 'cmp_b0212.xml', 'cmp_b0124.jpg', 'cmp_b0040.png', 'cmp_b0154.xml', 'cmp_b0357.png', 'cmp_b0115.jpg', 'cmp_b0147.jpg', 'cmp_b0092.jpg', 'cmp_b0104.xml', 'cmp_b0284.xml', 'cmp_b0077.png', 'cmp_b0192.xml', 'cmp_b0352.png', 'cmp_b0039.xml', 'cmp_b0039.jpg', 'cmp_b0176.jpg', 'cmp_b0230.xml', 'cmp_b0226.jpg', 'cmp_b0116.xml', 'cmp_b0359.jpg', 'cmp_b0152.xml', 'cmp_b0114.xml', 'cmp_b0013.jpg', 'cmp_b0227.jpg', 'cmp_b0145.xml', 'cmp_b0147.xml', 'cmp_b0292.xml', 'cmp_b0086.jpg', 'cmp_b0278.png', 'cmp_b0317.xml', 'cmp_b0193.jpg', 'cmp_b0095.png', 'cmp_b0067.png', 'cmp_b0102.jpg', 'cmp_b0041.xml', 'cmp_b0199.png', 'cmp_b0003.xml', 'cmp_b0028.jpg', 'cmp_b0059.png', 'cmp_b0030.png', 'cmp_b0187.jpg', 'cmp_b0311.png', 'cmp_b0105.xml', 'cmp_b0124.xml', 'cmp_b0348.png', 'cmp_b0175.jpg', 'cmp_b0003.jpg', 'cmp_b0086.png', 'cmp_b0244.png', 'cmp_b0315.xml', 'cmp_b0214.xml', 'cmp_b0353.png', 'cmp_b0158.jpg', 'cmp_b0153.xml', 'cmp_b0356.jpg', 'cmp_b0376.jpg', 'cmp_b0108.png', 'cmp_b0172.png', 'cmp_b0245.png', 'cmp_b0374.jpg', 'cmp_b0247.jpg', 'cmp_b0019.png', 'cmp_b0121.jpg', 'cmp_b0188.xml', 'cmp_b0238.jpg', 'cmp_b0041.jpg', 'cmp_b0290.jpg', 'cmp_b0323.jpg', 'cmp_b0258.xml', 'cmp_b0345.xml', 'cmp_b0359.png', 'cmp_b0377.png', 'cmp_b0312.png', 'cmp_b0272.xml', 'cmp_b0062.png', 'cmp_b0026.png', 'cmp_b0066.xml', 'cmp_b0171.jpg', 'cmp_b0114.png', 'cmp_b0375.xml', 'cmp_b0375.jpg', 'cmp_b0031.jpg', 'cmp_b0377.xml', 'cmp_b0127.xml', 'cmp_b0300.png', 'cmp_b0144.xml', 'cmp_b0169.jpg', 'cmp_b0180.jpg', 'cmp_b0156.png', 'cmp_b0175.xml', 'cmp_b0350.jpg', 'cmp_b0306.png', 'cmp_b0149.png', 'cmp_b0275.jpg', 'cmp_b0317.jpg', 'cmp_b0035.png', 'cmp_b0167.png', 'cmp_b0233.jpg', 'cmp_b0253.png', 'cmp_b0075.xml', 'cmp_b0277.png', 'cmp_b0259.xml', 'cmp_b0251.jpg', 'cmp_b0005.xml', 'cmp_b0088.png', 'cmp_b0354.jpg', 'cmp_b0368.jpg', 'cmp_b0097.png', 'cmp_b0271.png', 'cmp_b0047.jpg', 'cmp_b0269.png', 'cmp_b0268.png', 'cmp_b0002.xml', 'cmp_b0335.png', 'cmp_b0202.xml', 'cmp_b0131.png', 'cmp_b0187.png', 'cmp_b0138.xml', 'cmp_b0150.jpg', 'cmp_b0044.jpg', 'cmp_b0047.png', 'cmp_b0254.png', 'cmp_b0312.xml', 'cmp_b0018.jpg', 'cmp_b0361.xml', 'cmp_b0250.jpg', 'cmp_b0225.jpg', 'cmp_b0074.png', 'cmp_b0166.png', 'cmp_b0125.jpg', 'cmp_b0365.png', 'cmp_b0201.png', 'cmp_b0069.xml', 'cmp_b0136.jpg', 'cmp_b0285.xml', 'cmp_b0048.jpg', 'cmp_b0118.png', 'cmp_b0173.xml', 'cmp_b0157.png', 'cmp_b0098.jpg', 'cmp_b0033.png', 'cmp_b0193.xml', 'cmp_b0219.jpg', 'cmp_b0252.png', 'cmp_b0374.xml', 'cmp_b0308.xml', 'cmp_b0223.xml', 'cmp_b0355.png', 'cmp_b0248.xml', 'cmp_b0001.jpg', 'cmp_b0131.xml', 'cmp_b0323.png', 'cmp_b0057.jpg', 'cmp_b0269.xml', 'cmp_b0140.xml', 'cmp_b0160.xml', 'cmp_b0177.jpg', 'cmp_b0099.jpg', 'cmp_b0339.xml', 'cmp_b0221.png', 'cmp_b0307.jpg', 'cmp_b0036.xml', 'cmp_b0093.jpg', 'cmp_b0174.xml', 'cmp_b0368.png', 'cmp_b0334.jpg', 'cmp_b0288.xml', 'cmp_b0319.png', 'cmp_b0222.jpg', 'cmp_b0136.xml', 'cmp_b0112.jpg', 'cmp_b0276.png', 'cmp_b0049.xml', 'cmp_b0287.jpg', 'cmp_b0331.xml', 'cmp_b0249.xml', 'cmp_b0041.png', 'cmp_b0237.xml', 'cmp_b0037.xml', 'cmp_b0064.xml', 'cmp_b0134.png', 'cmp_b0306.xml', 'cmp_b0296.jpg', 'cmp_b0356.xml', 'cmp_b0132.png', 'cmp_b0274.png', 'cmp_b0331.png', 'cmp_b0363.jpg', 'cmp_b0092.xml', 'cmp_b0211.xml', 'cmp_b0321.xml', 'cmp_b0295.jpg', 'cmp_b0079.xml', 'cmp_b0068.png', 'cmp_b0030.jpg', 'cmp_b0155.xml', 'cmp_b0076.png', 'cmp_b0118.jpg', 'cmp_b0098.xml', 'cmp_b0025.xml', 'cmp_b0253.jpg', 'cmp_b0066.jpg', 'cmp_b0213.png', 'cmp_b0126.png', 'cmp_b0032.xml', 'cmp_b0284.png', 'cmp_b0326.xml', 'cmp_b0224.jpg', 'cmp_b0007.jpg', 'cmp_b0068.jpg', 'cmp_b0349.png', 'cmp_b0300.jpg', 'cmp_b0029.jpg', 'cmp_b0009.png', 'cmp_b0282.xml', 'cmp_b0122.jpg', 'cmp_b0023.png', 'cmp_b0275.png', 'cmp_b0332.png', 'cmp_b0129.png', 'cmp_b0042.png', 'cmp_b0296.xml', 'cmp_b0140.jpg', 'cmp_b0033.xml', 'cmp_b0163.png', 'cmp_b0169.png', 'cmp_b0089.xml', 'cmp_b0255.xml', 'cmp_b0033.jpg', 'cmp_b0198.png', 'cmp_b0094.xml', 'cmp_b0162.xml', 'cmp_b0353.xml', 'cmp_b0352.jpg', 'cmp_b0091.png', 'cmp_b0345.jpg', 'cmp_b0112.xml', 'cmp_b0104.png', 'cmp_b0152.jpg', 'cmp_b0300.xml', 'cmp_b0189.png', 'cmp_b0277.jpg', 'cmp_b0040.xml', 'cmp_b0070.jpg', 'cmp_b0168.png', 'cmp_b0188.png', 'cmp_b0026.xml', 'cmp_b0135.xml', 'cmp_b0143.xml', 'cmp_b0021.png', 'cmp_b0264.xml', 'cmp_b0069.png', 'cmp_b0199.jpg', 'cmp_b0367.jpg', 'cmp_b0220.jpg', 'cmp_b0043.jpg', 'cmp_b0085.xml', 'cmp_b0265.png', 'cmp_b0333.xml', 'cmp_b0016.jpg', 'cmp_b0034.xml', 'cmp_b0329.png', 'cmp_b0067.jpg', 'cmp_b0346.xml', 'cmp_b0078.png', 'cmp_b0224.xml', 'cmp_b0212.png', 'cmp_b0240.jpg', 'cmp_b0321.png', 'cmp_b0180.png', 'cmp_b0141.xml', 'cmp_b0176.png', 'cmp_b0215.xml', 'cmp_b0325.xml', 'cmp_b0150.xml', 'cmp_b0081.png', 'cmp_b0056.png', 'cmp_b0111.png', 'cmp_b0349.jpg', 'cmp_b0173.png', 'cmp_b0279.jpg', 'cmp_b0224.png', 'cmp_b0252.xml', 'cmp_b0332.xml', 'cmp_b0022.png', 'cmp_b0326.jpg', 'cmp_b0328.xml', 'cmp_b0281.jpg', 'cmp_b0369.png', 'cmp_b0023.jpg', 'cmp_b0333.jpg', 'cmp_b0320.png', 'cmp_b0163.xml', 'cmp_b0049.jpg', 'cmp_b0084.png', 'cmp_b0322.jpg', 'cmp_b0258.png', 'cmp_b0378.jpg', 'cmp_b0065.png', 'cmp_b0133.xml', 'cmp_b0229.xml', 'cmp_b0223.png', 'cmp_b0285.jpg', 'cmp_b0133.png', 'cmp_b0082.png', 'cmp_b0006.png', 'cmp_b0189.jpg', 'cmp_b0208.png', 'cmp_b0090.xml', 'cmp_b0025.jpg', 'cmp_b0156.jpg', 'cmp_b0190.xml', 'cmp_b0010.png', 'cmp_b0072.jpg', 'cmp_b0179.xml', 'cmp_b0248.png', 'cmp_b0377.jpg', 'cmp_b0206.jpg', 'cmp_b0267.xml', 'cmp_b0290.png', 'cmp_b0042.jpg', 'cmp_b0344.jpg', 'cmp_b0248.jpg', 'cmp_b0058.xml', 'cmp_b0263.png', 'cmp_b0242.jpg', 'cmp_b0045.png', 'cmp_b0324.jpg', 'cmp_b0305.jpg', 'cmp_b0005.png', 'cmp_b0027.jpg', 'cmp_b0185.png', 'cmp_b0210.png', 'cmp_b0127.jpg', 'cmp_b0038.png', 'cmp_b0310.jpg', 'cmp_b0162.jpg', 'cmp_b0029.xml', 'cmp_b0060.xml', 'cmp_b0017.jpg', 'cmp_b0117.png', 'cmp_b0067.xml', 'cmp_b0157.jpg', 'cmp_b0371.jpg', 'cmp_b0264.jpg', 'cmp_b0072.xml', 'cmp_b0138.png', 'cmp_b0341.png', 'cmp_b0297.jpg', 'cmp_b0235.xml', 'cmp_b0120.xml', 'cmp_b0139.jpg', 'cmp_b0184.jpg', 'cmp_b0014.jpg', 'cmp_b0120.png', 'cmp_b0256.xml', 'cmp_b0121.xml', 'cmp_b0050.xml', 'cmp_b0156.xml', 'cmp_b0091.xml', 'cmp_b0201.xml', 'cmp_b0280.jpg', 'cmp_b0337.png', 'cmp_b0022.xml', 'cmp_b0145.png', 'cmp_b0320.xml', 'cmp_b0218.xml', 'cmp_b0061.png', 'cmp_b0250.xml', 'cmp_b0128.png', 'cmp_b0095.jpg', 'cmp_b0200.jpg', 'cmp_b0347.xml', 'cmp_b0348.xml', 'cmp_b0190.jpg', 'cmp_b0105.jpg', 'cmp_b0343.jpg', 'cmp_b0077.xml', 'cmp_b0208.jpg', 'cmp_b0203.xml', 'cmp_b0364.jpg', 'cmp_b0037.jpg', 'cmp_b0143.jpg', 'cmp_b0250.png', 'cmp_b0242.xml', 'cmp_b0015.png', 'cmp_b0055.jpg', 'cmp_b0073.xml', 'cmp_b0311.xml', 'cmp_b0192.png', 'cmp_b0285.png', 'cmp_b0306.jpg', 'cmp_b0014.xml', 'cmp_b0363.xml', 'cmp_b0227.png', 'cmp_b0369.xml', 'cmp_b0230.png', 'cmp_b0144.png', 'cmp_b0139.png', 'cmp_b0215.jpg', 'cmp_b0175.png', 'cmp_b0343.png', 'cmp_b0376.xml', 'cmp_b0372.jpg', 'cmp_b0174.jpg', 'cmp_b0151.jpg', 'cmp_b0298.xml', 'cmp_b0251.png', 'cmp_b0317.png', 'cmp_b0173.jpg', 'cmp_b0101.png', 'cmp_b0313.png', 'cmp_b0018.png', 'cmp_b0062.xml', 'cmp_b0319.jpg', 'cmp_b0149.jpg', 'cmp_b0282.png', 'cmp_b0094.jpg', 'cmp_b0194.xml', 'cmp_b0219.xml', 'cmp_b0238.xml', 'cmp_b0336.jpg', 'cmp_b0335.jpg', 'cmp_b0237.png', 'cmp_b0213.jpg', 'cmp_b0298.jpg', 'cmp_b0124.png', 'cmp_b0164.xml', 'cmp_b0191.jpg', 'cmp_b0318.png', 'cmp_b0166.jpg', 'cmp_b0013.xml', 'cmp_b0313.jpg', 'cmp_b0086.xml', 'cmp_b0171.png', 'cmp_b0370.jpg', 'cmp_b0287.xml', 'cmp_b0254.xml', 'cmp_b0361.png', 'cmp_b0052.png', 'cmp_b0011.png', 'cmp_b0341.jpg', 'cmp_b0243.xml', 'cmp_b0216.png', 'cmp_b0040.jpg', 'cmp_b0366.png', 'cmp_b0110.xml', 'cmp_b0136.png', 'cmp_b0352.xml', 'cmp_b0324.png', 'cmp_b0338.xml', 'cmp_b0281.png', 'cmp_b0149.xml', 'cmp_b0365.jpg', 'cmp_b0181.xml', 'cmp_b0055.xml', 'cmp_b0272.jpg', 'cmp_b0113.png', 'cmp_b0249.jpg', 'cmp_b0235.jpg', 'cmp_b0307.png', 'cmp_b0063.xml', 'cmp_b0046.xml', 'cmp_b0194.jpg', 'cmp_b0123.xml', 'cmp_b0360.png', 'cmp_b0001.png', 'cmp_b0069.jpg', 'cmp_b0351.jpg', 'cmp_b0065.jpg', 'cmp_b0273.jpg', 'cmp_b0117.jpg', 'cmp_b0151.png', 'cmp_b0330.xml', 'cmp_b0233.xml', 'cmp_b0036.png', 'cmp_b0195.png', 'cmp_b0328.jpg', 'cmp_b0079.png', 'cmp_b0340.xml', 'cmp_b0061.jpg', 'cmp_b0098.png', 'cmp_b0118.xml', 'cmp_b0230.jpg', 'cmp_b0181.png', 'cmp_b0324.xml', 'cmp_b0036.jpg', 'cmp_b0111.jpg', 'cmp_b0029.png', 'cmp_b0071.png', 'cmp_b0142.xml', 'cmp_b0138.jpg', 'cmp_b0314.jpg', 'cmp_b0362.xml', 'cmp_b0128.jpg', 'cmp_b0117.xml', 'cmp_b0294.png', 'cmp_b0344.xml', 'cmp_b0246.png', 'cmp_b0196.jpg', 'cmp_b0102.xml', 'cmp_b0289.xml', 'cmp_b0359.xml', 'cmp_b0291.png', 'cmp_b0191.xml', 'cmp_b0331.jpg', 'cmp_b0089.jpg', 'cmp_b0375.png', 'cmp_b0205.png', 'cmp_b0172.xml', 'cmp_b0090.png', 'cmp_b0274.xml', 'cmp_b0293.png', 'cmp_b0332.jpg', 'cmp_b0148.jpg', 'cmp_b0218.png', 'cmp_b0239.jpg', 'cmp_b0045.xml', 'cmp_b0064.jpg', 'cmp_b0376.png', 'cmp_b0060.jpg', 'cmp_b0337.jpg', 'cmp_b0209.jpg', 'cmp_b0193.png', 'cmp_b0203.jpg', 'cmp_b0020.xml', 'cmp_b0312.jpg', 'cmp_b0161.png', 'cmp_b0231.xml', 'cmp_b0082.xml', 'cmp_b0283.png', 'cmp_b0108.jpg', 'cmp_b0236.png', 'cmp_b0071.jpg', 'cmp_b0261.jpg', 'cmp_b0127.png', 'cmp_b0099.png', 'cmp_b0188.jpg', 'cmp_b0262.jpg', 'cmp_b0070.xml', 'cmp_b0226.xml', 'cmp_b0371.xml', 'cmp_b0159.png', 'cmp_b0054.jpg', 'cmp_b0143.png', 'cmp_b0199.xml', 'cmp_b0220.xml', 'cmp_b0336.xml', 'cmp_b0096.png', 'cmp_b0159.jpg', 'cmp_b0268.jpg', 'cmp_b0148.xml', 'cmp_b0225.xml', 'cmp_b0165.jpg', 'cmp_b0078.jpg', 'cmp_b0263.jpg', 'cmp_b0272.png', 'cmp_b0011.jpg', 'cmp_b0003.png', 'cmp_b0183.jpg', 'cmp_b0083.jpg', 'cmp_b0241.xml', 'cmp_b0297.xml', 'cmp_b0084.jpg', 'cmp_b0252.jpg', 'cmp_b0291.jpg', 'cmp_b0153.jpg', 'cmp_b0015.jpg', 'cmp_b0009.jpg', 'cmp_b0176.xml', 'cmp_b0020.jpg', 'cmp_b0146.xml', 'cmp_b0207.jpg', 'cmp_b0273.png', 'cmp_b0277.xml', 'cmp_b0228.jpg', 'cmp_b0302.xml', 'cmp_b0004.xml', 'cmp_b0318.xml', 'cmp_b0024.png', 'cmp_b0144.jpg', 'cmp_b0100.png', 'cmp_b0353.jpg', 'cmp_b0346.png', 'cmp_b0095.xml', 'cmp_b0076.jpg', 'cmp_b0007.png', 'cmp_b0322.png', 'cmp_b0137.xml', 'cmp_b0084.xml', 'cmp_b0058.png', 'cmp_b0113.jpg', 'cmp_b0137.png', 'cmp_b0119.xml', 'cmp_b0024.xml', 'cmp_b0213.xml', 'cmp_b0166.xml', 'cmp_b0330.png', 'cmp_b0315.png', 'cmp_b0186.png', 'cmp_b0266.jpg', 'cmp_b0081.jpg', 'cmp_b0094.png', 'cmp_b0270.png', 'cmp_b0074.xml', 'cmp_b0279.png', 'cmp_b0341.xml', 'cmp_b0027.xml', 'cmp_b0085.png', 'cmp_b0050.jpg', 'cmp_b0267.jpg', 'cmp_b0223.jpg', 'cmp_b0361.jpg', 'cmp_b0342.jpg', 'cmp_b0016.png', 'cmp_b0342.xml', 'cmp_b0153.png', 'cmp_b0261.png', 'cmp_b0310.xml', 'cmp_b0155.png', 'cmp_b0204.xml', 'cmp_b0325.png', 'cmp_b0028.png', 'cmp_b0148.png', 'cmp_b0106.png', 'cmp_b0293.xml', 'cmp_b0022.jpg', 'cmp_b0132.jpg', 'cmp_b0204.png', 'cmp_b0255.png', 'cmp_b0063.png', 'cmp_b0065.xml', 'cmp_b0195.jpg', 'cmp_b0135.jpg', 'cmp_b0258.jpg', 'cmp_b0157.xml', 'cmp_b0012.xml', 'cmp_b0146.png', 'cmp_b0125.xml', 'cmp_b0295.png', 'cmp_b0292.png', 'cmp_b0284.jpg', 'cmp_b0178.jpg', 'cmp_b0045.jpg', 'cmp_b0221.jpg', 'cmp_b0062.jpg', 'cmp_b0037.png', 'cmp_b0046.png', 'cmp_b0255.jpg', 'cmp_b0302.jpg', 'cmp_b0046.jpg', 'cmp_b0206.png', 'cmp_b0229.jpg', 'cmp_b0378.xml', 'cmp_b0278.xml', 'cmp_b0281.xml', 'cmp_b0351.xml', 'cmp_b0366.jpg', 'cmp_b0038.jpg', 'cmp_b0242.png', 'cmp_b0119.jpg', 'cmp_b0246.jpg', 'cmp_b0370.xml', 'cmp_b0304.png', 'cmp_b0121.png', 'cmp_b0367.png', 'cmp_b0145.jpg', 'cmp_b0320.jpg', 'cmp_b0314.png', 'cmp_b0052.jpg', 'cmp_b0158.png', 'cmp_b0130.png', 'cmp_b0179.jpg', 'cmp_b0275.xml', 'cmp_b0038.xml', 'cmp_b0271.jpg', 'cmp_b0075.jpg', 'cmp_b0210.xml', 'cmp_b0301.png', 'cmp_b0190.png', 'cmp_b0295.xml', 'cmp_b0091.jpg', 'cmp_b0297.png', 'cmp_b0200.xml', 'cmp_b0351.png', 'cmp_b0261.xml', 'cmp_b0308.jpg', 'cmp_b0085.jpg', 'cmp_b0137.jpg', 'cmp_b0097.xml', 'cmp_b0257.png', 'cmp_b0048.png', 'cmp_b0303.jpg', 'cmp_b0232.png', 'cmp_b0110.jpg', 'cmp_b0195.xml', 'cmp_b0140.png', 'cmp_b0280.png', 'cmp_b0141.png', 'cmp_b0276.xml', 'cmp_b0201.jpg', 'cmp_b0350.xml', 'cmp_b0043.png', 'cmp_b0168.jpg', 'cmp_b0279.xml', 'cmp_b0203.png', 'cmp_b0363.png', 'cmp_b0288.jpg', 'cmp_b0316.jpg', 'cmp_b0276.jpg', 'cmp_b0265.xml', 'cmp_b0305.xml', 'cmp_b0216.jpg', 'cmp_b0154.jpg', 'cmp_b0214.jpg', 'cmp_b0287.png', 'cmp_b0126.xml', 'cmp_b0122.xml', 'cmp_b0032.png', 'cmp_b0337.xml', 'cmp_b0161.jpg', 'cmp_b0059.xml', 'cmp_b0044.png', 'cmp_b0308.png', 'cmp_b0310.png', 'cmp_b0209.png', 'cmp_b0004.png', 'cmp_b0134.xml', 'cmp_b0239.png', 'cmp_b0013.png', 'cmp_b0260.png', 'cmp_b0299.xml', 'cmp_b0232.xml', 'cmp_b0256.png', 'cmp_b0256.jpg', 'cmp_b0152.png', 'cmp_b0025.png', 'cmp_b0262.xml', 'cmp_b0340.png', 'cmp_b0364.png', 'cmp_b0160.jpg', 'cmp_b0347.jpg', 'cmp_b0030.xml', 'cmp_b0240.xml', 'cmp_b0043.xml', 'cmp_b0247.png', 'cmp_b0103.png', 'cmp_b0202.png', 'cmp_b0217.xml', 'cmp_b0322.xml', 'cmp_b0288.png', 'cmp_b0182.xml', 'cmp_b0330.jpg', 'cmp_b0103.jpg', 'cmp_b0298.png', 'cmp_b0299.jpg', 'cmp_b0087.png', 'cmp_b0326.png', 'cmp_b0021.jpg', 'cmp_b0333.png', 'cmp_b0305.png', 'cmp_b0076.xml', 'cmp_b0236.jpg', 'cmp_b0268.xml', 'cmp_b0135.png', 'cmp_b0008.png', 'cmp_b0307.xml', 'cmp_b0204.jpg', 'cmp_b0209.xml', 'cmp_b0167.xml', 'cmp_b0202.jpg', 'cmp_b0007.xml', 'cmp_b0056.xml', 'cmp_b0008.jpg', 'cmp_b0063.jpg', 'cmp_b0146.jpg', 'cmp_b0227.xml', 'cmp_b0304.jpg', 'cmp_b0225.png', 'cmp_b0042.xml', 'cmp_b0198.xml', 'cmp_b0280.xml', 'cmp_b0283.jpg', 'cmp_b0093.png', 'cmp_b0133.jpg', 'cmp_b0329.xml', 'cmp_b0105.png', 'cmp_b0123.png', 'cmp_b0345.png', 'cmp_b0197.png', 'cmp_b0090.jpg', 'cmp_b0096.xml', 'cmp_b0023.xml', 'cmp_b0260.jpg', 'cmp_b0198.jpg', 'cmp_b0365.xml', 'cmp_b0231.jpg', 'cmp_b0116.png', 'cmp_b0211.png', 'cmp_b0241.jpg', 'cmp_b0301.xml', 'cmp_b0081.xml', 'cmp_b0327.jpg', 'cmp_b0309.xml', 'cmp_b0266.xml', 'cmp_b0017.xml', 'cmp_b0057.xml', 'cmp_b0080.xml', 'cmp_b0093.xml', 'cmp_b0315.jpg', 'cmp_b0002.png', 'cmp_b0245.jpg', 'cmp_b0150.png', 'cmp_b0015.xml', 'cmp_b0271.xml', 'cmp_b0021.xml', 'cmp_b0181.jpg', 'cmp_b0114.jpg', 'cmp_b0196.xml', 'cmp_b0020.png', 'cmp_b0031.xml', 'cmp_b0286.xml', 'cmp_b0327.png', 'cmp_b0034.png', 'cmp_b0054.png', 'cmp_b0219.png', 'cmp_b0074.jpg', 'cmp_b0027.png', 'cmp_b0334.xml', 'cmp_b0313.xml', 'cmp_b0234.xml', 'cmp_b0001.xml', 'cmp_b0070.png', 'cmp_b0303.png', 'cmp_b0200.png', 'cmp_b0141.jpg', 'cmp_b0170.jpg', 'cmp_b0182.png', 'cmp_b0329.jpg', 'cmp_b0002.jpg', 'cmp_b0327.xml', 'cmp_b0125.png', 'cmp_b0061.xml', 'cmp_b0072.png', 'cmp_b0321.jpg', 'cmp_b0263.xml', 'cmp_b0012.png', 'cmp_b0229.png', 'cmp_b0286.png', 'cmp_b0254.jpg', 'cmp_b0119.png', 'cmp_b0075.png', 'cmp_b0168.xml', 'cmp_b0174.png', 'cmp_b0079.jpg', 'cmp_b0293.jpg', 'cmp_b0165.png', 'cmp_b0134.jpg', 'cmp_b0197.jpg', 'cmp_b0226.png', 'cmp_b0073.png', 'cmp_b0170.xml', 'cmp_b0245.xml', 'cmp_b0107.png', 'cmp_b0360.xml', 'cmp_b0049.png', 'cmp_b0083.png', 'cmp_b0355.jpg', 'cmp_b0323.xml', 'cmp_b0339.jpg', 'cmp_b0267.png', 'cmp_b0100.jpg', 'cmp_b0207.xml', 'cmp_b0172.jpg', 'cmp_b0035.jpg', 'cmp_b0120.jpg', 'cmp_b0221.xml', 'cmp_b0301.jpg', 'cmp_b0053.jpg', 'cmp_b0318.jpg', 'cmp_b0282.jpg', 'cmp_b0214.png', 'cmp_b0182.jpg', 'cmp_b0217.png', 'cmp_b0101.jpg', 'cmp_b0087.jpg', 'cmp_b0325.jpg', 'cmp_b0031.png', 'cmp_b0368.xml', 'cmp_b0103.xml', 'cmp_b0344.png', 'cmp_b0106.jpg', 'cmp_b0012.jpg', 'cmp_b0243.png', 'cmp_b0346.jpg', 'cmp_b0334.png', 'cmp_b0270.xml', 'cmp_b0238.png', 'cmp_b0109.png', 'cmp_b0343.xml', 'cmp_b0289.jpg', 'cmp_b0243.jpg', 'cmp_b0292.jpg', 'cmp_b0096.jpg', 'cmp_b0211.jpg', 'cmp_b0006.jpg', 'cmp_b0164.png', 'cmp_b0338.png', 'cmp_b0357.jpg', 'cmp_b0358.xml', 'cmp_b0104.jpg', 'cmp_b0274.jpg', 'cmp_b0100.xml', 'cmp_b0240.png', 'cmp_b0314.xml', 'cmp_b0055.png', 'cmp_b0151.xml', 'cmp_b0373.xml', 'cmp_b0058.jpg', 'cmp_b0354.xml', 'cmp_b0102.png', 'cmp_b0160.png', 'cmp_b0247.xml', 'cmp_b0108.xml', 'cmp_b0362.jpg', 'cmp_b0360.jpg', 'cmp_b0142.jpg', 'cmp_b0373.jpg', 'cmp_b0244.xml', 'cmp_b0056.jpg', 'cmp_b0335.xml', 'cmp_b0122.png', 'cmp_b0309.png', 'cmp_b0197.xml', 'cmp_b0092.png', 'cmp_b0205.jpg', 'cmp_b0132.xml', 'cmp_b0177.png', 'cmp_b0309.jpg', 'cmp_b0068.xml', 'cmp_b0110.png', 'cmp_b0078.xml', 'cmp_b0234.jpg', 'cmp_b0018.xml', 'cmp_b0034.jpg', 'cmp_b0286.jpg', 'cmp_b0369.jpg', 'cmp_b0249.png', 'cmp_b0165.xml', 'cmp_b0217.jpg', 'cmp_b0216.xml', 'cmp_b0005.jpg', 'cmp_b0262.png', 'cmp_b0342.png', 'cmp_b0051.png', 'cmp_b0129.xml', 'cmp_b0269.jpg', 'cmp_b0019.jpg', 'cmp_b0180.xml', 'cmp_b0039.png', 'cmp_b0158.xml', 'cmp_b0316.xml', 'cmp_b0187.xml', 'cmp_b0083.xml', 'cmp_b0362.png', 'cmp_b0270.jpg', 'cmp_b0234.png', 'cmp_b0179.png', 'cmp_b0220.png', 'cmp_b0167.jpg', 'cmp_b0014.png', 'cmp_b0215.png', 'cmp_b0106.xml', 'cmp_b0207.png', 'cmp_b0060.png', 'cmp_b0183.png', 'cmp_b0009.xml', 'cmp_b0374.png', 'cmp_b0184.xml', 'cmp_b0296.png', 'cmp_b0347.png', 'cmp_b0101.xml', 'cmp_b0251.xml', 'cmp_b0253.xml', 'cmp_b0336.png', 'cmp_b0130.jpg', 'cmp_b0291.xml', 'cmp_b0260.xml', 'cmp_b0194.png', 'cmp_b0107.jpg', 'cmp_b0097.jpg', 'cmp_b0259.png', 'cmp_b0185.xml', 'cmp_b0109.xml', 'cmp_b0159.xml', 'cmp_b0372.png', 'cmp_b0064.png', 'cmp_b0131.jpg', 'cmp_b0048.xml', 'cmp_b0059.jpg', 'cmp_b0265.jpg', 'cmp_b0178.png', 'cmp_b0372.xml', 'cmp_b0016.xml', 'cmp_b0222.xml', 'cmp_b0017.png', 'cmp_b0191.png', 'cmp_b0073.jpg', 'cmp_b0155.jpg', 'cmp_b0266.png', 'cmp_b0047.xml', 'cmp_b0239.xml', 'cmp_b0366.xml', 'cmp_b0235.png', 'cmp_b0053.xml', 'cmp_b0289.png', 'cmp_b0356.png', 'cmp_b0087.xml', 'cmp_b0171.xml', 'cmp_b0147.png', 'cmp_b0350.png', 'cmp_b0099.xml', 'cmp_b0126.jpg', 'cmp_b0259.jpg', 'cmp_b0185.jpg', 'cmp_b0115.png', 'cmp_b0113.xml', 'cmp_b0169.xml', 'cmp_b0257.xml', 'cmp_b0142.png', 'cmp_b0183.xml']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alvLGzYD7zoQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "919b95b4-7a7e-4b51-d12d-80e9ffc8b3da"
      },
      "source": [
        "path = '/content/base/'\n",
        "\n",
        "def image_preprocessing(filename, x_size, y_size):\n",
        "    im = Image.open(filename)\n",
        "    if filename.endswith('.png'):\n",
        "        im = im.convert('RGB')\n",
        "\n",
        "    downsampled_im = ImageOps.fit(im, (x_size, y_size), method=Image.LANCZOS)\n",
        "    norm_im = np.array(downsampled_im, dtype=np.float32)/255.\n",
        "\n",
        "    downsampled_im.close()\n",
        "    im.close()\n",
        "\n",
        "    return norm_im\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    names = []\n",
        "\n",
        "    for name in os.listdir(path):\n",
        "        if name.endswith('.jpg'):\n",
        "            names.append(name[:-4])\n",
        "\n",
        "    dataset_X = np.zeros((len(names), 256, 256, 3))\n",
        "    dataset_Y = np.zeros((len(names), 256, 256, 3))\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        print(names[i])\n",
        "        dataset_X[i] = image_preprocessing(os.path.join(path, names[i] + '.jpg'), 256, 256)\n",
        "        dataset_Y[i] = image_preprocessing(os.path.join(path, names[i] + '.png'), 256, 256)\n",
        "\n",
        "    np.save('dataset_X.npy', dataset_X)\n",
        "    np.save('dataset_Y.npy', dataset_Y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cmp_b0358\n",
            "cmp_b0129\n",
            "cmp_b0116\n",
            "cmp_b0026\n",
            "cmp_b0163\n",
            "cmp_b0123\n",
            "cmp_b0340\n",
            "cmp_b0338\n",
            "cmp_b0232\n",
            "cmp_b0077\n",
            "cmp_b0082\n",
            "cmp_b0237\n",
            "cmp_b0257\n",
            "cmp_b0051\n",
            "cmp_b0088\n",
            "cmp_b0210\n",
            "cmp_b0294\n",
            "cmp_b0311\n",
            "cmp_b0080\n",
            "cmp_b0004\n",
            "cmp_b0192\n",
            "cmp_b0348\n",
            "cmp_b0278\n",
            "cmp_b0010\n",
            "cmp_b0024\n",
            "cmp_b0218\n",
            "cmp_b0244\n",
            "cmp_b0186\n",
            "cmp_b0164\n",
            "cmp_b0032\n",
            "cmp_b0109\n",
            "cmp_b0212\n",
            "cmp_b0124\n",
            "cmp_b0115\n",
            "cmp_b0147\n",
            "cmp_b0092\n",
            "cmp_b0039\n",
            "cmp_b0176\n",
            "cmp_b0226\n",
            "cmp_b0359\n",
            "cmp_b0013\n",
            "cmp_b0227\n",
            "cmp_b0086\n",
            "cmp_b0193\n",
            "cmp_b0102\n",
            "cmp_b0028\n",
            "cmp_b0187\n",
            "cmp_b0175\n",
            "cmp_b0003\n",
            "cmp_b0158\n",
            "cmp_b0356\n",
            "cmp_b0376\n",
            "cmp_b0374\n",
            "cmp_b0247\n",
            "cmp_b0121\n",
            "cmp_b0238\n",
            "cmp_b0041\n",
            "cmp_b0290\n",
            "cmp_b0323\n",
            "cmp_b0171\n",
            "cmp_b0375\n",
            "cmp_b0031\n",
            "cmp_b0169\n",
            "cmp_b0180\n",
            "cmp_b0350\n",
            "cmp_b0275\n",
            "cmp_b0317\n",
            "cmp_b0233\n",
            "cmp_b0251\n",
            "cmp_b0354\n",
            "cmp_b0368\n",
            "cmp_b0047\n",
            "cmp_b0150\n",
            "cmp_b0044\n",
            "cmp_b0018\n",
            "cmp_b0250\n",
            "cmp_b0225\n",
            "cmp_b0125\n",
            "cmp_b0136\n",
            "cmp_b0048\n",
            "cmp_b0098\n",
            "cmp_b0219\n",
            "cmp_b0001\n",
            "cmp_b0057\n",
            "cmp_b0177\n",
            "cmp_b0099\n",
            "cmp_b0307\n",
            "cmp_b0093\n",
            "cmp_b0334\n",
            "cmp_b0222\n",
            "cmp_b0112\n",
            "cmp_b0287\n",
            "cmp_b0296\n",
            "cmp_b0363\n",
            "cmp_b0295\n",
            "cmp_b0030\n",
            "cmp_b0118\n",
            "cmp_b0253\n",
            "cmp_b0066\n",
            "cmp_b0224\n",
            "cmp_b0007\n",
            "cmp_b0068\n",
            "cmp_b0300\n",
            "cmp_b0029\n",
            "cmp_b0122\n",
            "cmp_b0140\n",
            "cmp_b0033\n",
            "cmp_b0352\n",
            "cmp_b0345\n",
            "cmp_b0152\n",
            "cmp_b0277\n",
            "cmp_b0070\n",
            "cmp_b0199\n",
            "cmp_b0367\n",
            "cmp_b0220\n",
            "cmp_b0043\n",
            "cmp_b0016\n",
            "cmp_b0067\n",
            "cmp_b0240\n",
            "cmp_b0349\n",
            "cmp_b0279\n",
            "cmp_b0326\n",
            "cmp_b0281\n",
            "cmp_b0023\n",
            "cmp_b0333\n",
            "cmp_b0049\n",
            "cmp_b0322\n",
            "cmp_b0378\n",
            "cmp_b0285\n",
            "cmp_b0189\n",
            "cmp_b0025\n",
            "cmp_b0156\n",
            "cmp_b0072\n",
            "cmp_b0377\n",
            "cmp_b0206\n",
            "cmp_b0042\n",
            "cmp_b0344\n",
            "cmp_b0248\n",
            "cmp_b0242\n",
            "cmp_b0324\n",
            "cmp_b0305\n",
            "cmp_b0027\n",
            "cmp_b0127\n",
            "cmp_b0310\n",
            "cmp_b0162\n",
            "cmp_b0017\n",
            "cmp_b0157\n",
            "cmp_b0371\n",
            "cmp_b0264\n",
            "cmp_b0297\n",
            "cmp_b0139\n",
            "cmp_b0184\n",
            "cmp_b0014\n",
            "cmp_b0280\n",
            "cmp_b0095\n",
            "cmp_b0200\n",
            "cmp_b0190\n",
            "cmp_b0105\n",
            "cmp_b0343\n",
            "cmp_b0208\n",
            "cmp_b0364\n",
            "cmp_b0037\n",
            "cmp_b0143\n",
            "cmp_b0055\n",
            "cmp_b0306\n",
            "cmp_b0215\n",
            "cmp_b0372\n",
            "cmp_b0174\n",
            "cmp_b0151\n",
            "cmp_b0173\n",
            "cmp_b0319\n",
            "cmp_b0149\n",
            "cmp_b0094\n",
            "cmp_b0336\n",
            "cmp_b0335\n",
            "cmp_b0213\n",
            "cmp_b0298\n",
            "cmp_b0191\n",
            "cmp_b0166\n",
            "cmp_b0313\n",
            "cmp_b0370\n",
            "cmp_b0341\n",
            "cmp_b0040\n",
            "cmp_b0365\n",
            "cmp_b0272\n",
            "cmp_b0249\n",
            "cmp_b0235\n",
            "cmp_b0194\n",
            "cmp_b0069\n",
            "cmp_b0351\n",
            "cmp_b0065\n",
            "cmp_b0273\n",
            "cmp_b0117\n",
            "cmp_b0328\n",
            "cmp_b0061\n",
            "cmp_b0230\n",
            "cmp_b0036\n",
            "cmp_b0111\n",
            "cmp_b0138\n",
            "cmp_b0314\n",
            "cmp_b0128\n",
            "cmp_b0196\n",
            "cmp_b0331\n",
            "cmp_b0089\n",
            "cmp_b0332\n",
            "cmp_b0148\n",
            "cmp_b0239\n",
            "cmp_b0064\n",
            "cmp_b0060\n",
            "cmp_b0337\n",
            "cmp_b0209\n",
            "cmp_b0203\n",
            "cmp_b0312\n",
            "cmp_b0108\n",
            "cmp_b0071\n",
            "cmp_b0261\n",
            "cmp_b0188\n",
            "cmp_b0262\n",
            "cmp_b0054\n",
            "cmp_b0159\n",
            "cmp_b0268\n",
            "cmp_b0165\n",
            "cmp_b0078\n",
            "cmp_b0263\n",
            "cmp_b0011\n",
            "cmp_b0183\n",
            "cmp_b0083\n",
            "cmp_b0084\n",
            "cmp_b0252\n",
            "cmp_b0291\n",
            "cmp_b0153\n",
            "cmp_b0015\n",
            "cmp_b0009\n",
            "cmp_b0020\n",
            "cmp_b0207\n",
            "cmp_b0228\n",
            "cmp_b0144\n",
            "cmp_b0353\n",
            "cmp_b0076\n",
            "cmp_b0113\n",
            "cmp_b0266\n",
            "cmp_b0081\n",
            "cmp_b0050\n",
            "cmp_b0267\n",
            "cmp_b0223\n",
            "cmp_b0361\n",
            "cmp_b0342\n",
            "cmp_b0022\n",
            "cmp_b0132\n",
            "cmp_b0195\n",
            "cmp_b0135\n",
            "cmp_b0258\n",
            "cmp_b0284\n",
            "cmp_b0178\n",
            "cmp_b0045\n",
            "cmp_b0221\n",
            "cmp_b0062\n",
            "cmp_b0255\n",
            "cmp_b0302\n",
            "cmp_b0046\n",
            "cmp_b0229\n",
            "cmp_b0366\n",
            "cmp_b0038\n",
            "cmp_b0119\n",
            "cmp_b0246\n",
            "cmp_b0145\n",
            "cmp_b0320\n",
            "cmp_b0052\n",
            "cmp_b0179\n",
            "cmp_b0271\n",
            "cmp_b0075\n",
            "cmp_b0091\n",
            "cmp_b0308\n",
            "cmp_b0085\n",
            "cmp_b0137\n",
            "cmp_b0303\n",
            "cmp_b0110\n",
            "cmp_b0201\n",
            "cmp_b0168\n",
            "cmp_b0288\n",
            "cmp_b0316\n",
            "cmp_b0276\n",
            "cmp_b0216\n",
            "cmp_b0154\n",
            "cmp_b0214\n",
            "cmp_b0161\n",
            "cmp_b0256\n",
            "cmp_b0160\n",
            "cmp_b0347\n",
            "cmp_b0330\n",
            "cmp_b0103\n",
            "cmp_b0299\n",
            "cmp_b0021\n",
            "cmp_b0236\n",
            "cmp_b0204\n",
            "cmp_b0202\n",
            "cmp_b0008\n",
            "cmp_b0063\n",
            "cmp_b0146\n",
            "cmp_b0304\n",
            "cmp_b0283\n",
            "cmp_b0133\n",
            "cmp_b0090\n",
            "cmp_b0260\n",
            "cmp_b0198\n",
            "cmp_b0231\n",
            "cmp_b0241\n",
            "cmp_b0327\n",
            "cmp_b0315\n",
            "cmp_b0245\n",
            "cmp_b0181\n",
            "cmp_b0114\n",
            "cmp_b0074\n",
            "cmp_b0141\n",
            "cmp_b0170\n",
            "cmp_b0329\n",
            "cmp_b0002\n",
            "cmp_b0321\n",
            "cmp_b0254\n",
            "cmp_b0079\n",
            "cmp_b0293\n",
            "cmp_b0134\n",
            "cmp_b0197\n",
            "cmp_b0355\n",
            "cmp_b0339\n",
            "cmp_b0100\n",
            "cmp_b0172\n",
            "cmp_b0035\n",
            "cmp_b0120\n",
            "cmp_b0301\n",
            "cmp_b0053\n",
            "cmp_b0318\n",
            "cmp_b0282\n",
            "cmp_b0182\n",
            "cmp_b0101\n",
            "cmp_b0087\n",
            "cmp_b0325\n",
            "cmp_b0106\n",
            "cmp_b0012\n",
            "cmp_b0346\n",
            "cmp_b0289\n",
            "cmp_b0243\n",
            "cmp_b0292\n",
            "cmp_b0096\n",
            "cmp_b0211\n",
            "cmp_b0006\n",
            "cmp_b0357\n",
            "cmp_b0104\n",
            "cmp_b0274\n",
            "cmp_b0058\n",
            "cmp_b0362\n",
            "cmp_b0360\n",
            "cmp_b0142\n",
            "cmp_b0373\n",
            "cmp_b0056\n",
            "cmp_b0205\n",
            "cmp_b0309\n",
            "cmp_b0234\n",
            "cmp_b0034\n",
            "cmp_b0286\n",
            "cmp_b0369\n",
            "cmp_b0217\n",
            "cmp_b0005\n",
            "cmp_b0269\n",
            "cmp_b0019\n",
            "cmp_b0270\n",
            "cmp_b0167\n",
            "cmp_b0130\n",
            "cmp_b0107\n",
            "cmp_b0097\n",
            "cmp_b0131\n",
            "cmp_b0059\n",
            "cmp_b0265\n",
            "cmp_b0073\n",
            "cmp_b0155\n",
            "cmp_b0126\n",
            "cmp_b0259\n",
            "cmp_b0185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JituB7WsJZD"
      },
      "source": [
        "class Pix2pix(object):\n",
        "    def __init__(self, width, height, ichan, ochan, l1_weight=100., lr=0.0002, beta1=0.5):\n",
        "\n",
        "        self._is_training = tf.placeholder(tf.bool)\n",
        "        self._g_inputs = tf.placeholder(tf.float32, [None, width, height, ichan])\n",
        "        self._d_inputs_a = tf.placeholder(tf.float32, [None, width, height, ichan])\n",
        "        self._d_inputs_b = tf.placeholder(tf.float32, [None, width, height, ochan])\n",
        "        self._g = Generator(self._g_inputs, self._is_training, ochan)\n",
        "        self._real_d = Discriminator(tf.concat([self._d_inputs_a, self._d_inputs_b], axis=3), self._is_training)\n",
        "        self._fake_d = Discriminator(tf.concat([self._d_inputs_a, self._g._decoder['cl9']['fmap']], axis=3), self._is_training, reuse=tf.AUTO_REUSE)\n",
        "\n",
        "        self._g_loss = -tf.reduce_mean(tf.log(self._fake_d._discriminator['l5']['fmap'])) + l1_weight * tf.reduce_mean(tf.abs(\n",
        "                                                                            self._d_inputs_b - self._g._decoder['cl9']['fmap']))\n",
        "        self._d_loss = -tf.reduce_mean(tf.log(self._real_d._discriminator['l5']['fmap']) + tf.log(1.0 - self._fake_d._discriminator['l5']['fmap']))\n",
        "\n",
        "        g_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='G')\n",
        "\n",
        "        with tf.control_dependencies(g_update_ops):\n",
        "            self._g_train_step = tf.train.AdamOptimizer(lr, beta1=beta1).minimize(self._g_loss,\n",
        "                    var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='G'))\n",
        "        \n",
        "        d_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='D')\n",
        "\n",
        "        with tf.control_dependencies(d_update_ops):\n",
        "            self._d_train_step = tf.train.AdamOptimizer(lr, beta1=beta1).minimize(self._d_loss,\n",
        "                    var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='D'))\n",
        "            \n",
        "    def train_step(self, sess, g_inputs, d_inputs_a, d_inputs_b, is_training=True):\n",
        "        _, dloss_curr = sess.run([self._d_train_step, self._d_loss],\n",
        "            feed_dict={self._d_inputs_a : d_inputs_a, self._d_inputs_b : d_inputs_b, self._g_inputs : g_inputs, self._is_training : is_training})\n",
        "        _, gloss_curr = sess.run([self._g_train_step, self._g_loss],\n",
        "                feed_dict={self._g_inputs : g_inputs, self._d_inputs_a : d_inputs_a,   self._d_inputs_b : d_inputs_b,self._is_training : is_training})\n",
        "        return (gloss_curr, dloss_curr)\n",
        "\n",
        "    def sample_generator(self, sess, g_inputs, is_training=False):\n",
        "        return sess.run(self._g._decoder['cl9']['fmap'], feed_dict={self._g_inputs : g_inputs, self._is_training : is_training})\n",
        "            \n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_BvkK5Sk82p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1ac3fa2-9296-4a31-f084-c26d0d7b5046"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iters = 200*400\n",
        "batch_size = 1\n",
        "\n",
        "A = np.load('dataset_Y.npy') \n",
        "B = np.load('dataset_X.npy') \n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    model = Pix2pix(256, 256, ichan=3, ochan=3)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(iters):\n",
        "        a = np.expand_dims(A[step % A.shape[0]], axis=0)\n",
        "        b = 2. * np.expand_dims(B[step % B.shape[0]], axis=0) - 1. \n",
        "\n",
        "        gloss_curr, dloss_curr = model.train_step(sess, a, a, b)\n",
        "        print('Step %d: G loss: %f | D loss: %f' % (step, gloss_curr, dloss_curr))\n",
        "\n",
        "        if step % 500 == 0:\n",
        "            fig = plt.figure()\n",
        "            fig.set_size_inches(10, 10)\n",
        "            fig.subplots_adjust(left=0, bottom=0,\n",
        "                                   right=1, top=1, wspace=0, hspace=0.1)\n",
        "            p = np.random.permutation(B.shape[0])\n",
        "            for i in range(0, 81, 3):\n",
        "\n",
        "                fig.add_subplot(9, 9, i + 1)\n",
        "                plt.imshow(A[p[i // 3]])\n",
        "                plt.axis('off')\n",
        "                fig.add_subplot(9, 9, i + 2)\n",
        "                plt.imshow((model.sample_generator(sess, np.expand_dims(A[p[i // 3]], axis=0), is_training=True)[0] + 1.) / 2.)\n",
        "                plt.axis('off')\n",
        "                fig.add_subplot(9, 9, i +3)\n",
        "                plt.imshow(B[p[i // 3]])\n",
        "                plt.axis('off')\n",
        "            plt.savefig('/content/images/iter_%d.jpg' % step)\n",
        "            plt.close()\n",
        "        if step % 3000 == 0:\n",
        "\n",
        "            save_path = saver.save(sess, \"/content/models/model.ckpt\")\n",
        "            print(\"Model saved in file: %s\" % save_path)\n",
        "\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Step 1306: G loss: 18.352171 | D loss: 1.457745\n",
            "Step 1307: G loss: 24.134260 | D loss: 1.475767\n",
            "Step 1308: G loss: 41.665051 | D loss: 1.466530\n",
            "Step 1309: G loss: 37.142006 | D loss: 1.458157\n",
            "Step 1310: G loss: 40.669586 | D loss: 1.474568\n",
            "Step 1311: G loss: 33.156548 | D loss: 1.480198\n",
            "Step 1312: G loss: 25.748291 | D loss: 1.451580\n",
            "Step 1313: G loss: 38.712467 | D loss: 1.447943\n",
            "Step 1314: G loss: 40.121525 | D loss: 1.477658\n",
            "Step 1315: G loss: 38.337742 | D loss: 1.456954\n",
            "Step 1316: G loss: 27.951324 | D loss: 1.468169\n",
            "Step 1317: G loss: 29.460909 | D loss: 1.455571\n",
            "Step 1318: G loss: 28.934275 | D loss: 1.467973\n",
            "Step 1319: G loss: 29.134802 | D loss: 1.477405\n",
            "Step 1320: G loss: 33.142921 | D loss: 1.449015\n",
            "Step 1321: G loss: 25.128792 | D loss: 1.451960\n",
            "Step 1322: G loss: 44.536415 | D loss: 1.472603\n",
            "Step 1323: G loss: 29.887190 | D loss: 1.473131\n",
            "Step 1324: G loss: 42.319950 | D loss: 1.518323\n",
            "Step 1325: G loss: 26.139912 | D loss: 1.482186\n",
            "Step 1326: G loss: 29.918653 | D loss: 1.435155\n",
            "Step 1327: G loss: 37.926765 | D loss: 1.487253\n",
            "Step 1328: G loss: 43.406792 | D loss: 1.461291\n",
            "Step 1329: G loss: 35.398869 | D loss: 1.482785\n",
            "Step 1330: G loss: 25.446087 | D loss: 1.436319\n",
            "Step 1331: G loss: 19.445213 | D loss: 1.456169\n",
            "Step 1332: G loss: 38.121483 | D loss: 1.444617\n",
            "Step 1333: G loss: 34.436871 | D loss: 1.462065\n",
            "Step 1334: G loss: 44.118877 | D loss: 1.433928\n",
            "Step 1335: G loss: 39.570564 | D loss: 1.450069\n",
            "Step 1336: G loss: 44.149990 | D loss: 1.434184\n",
            "Step 1337: G loss: 30.606739 | D loss: 1.436637\n",
            "Step 1338: G loss: 42.154678 | D loss: 1.455606\n",
            "Step 1339: G loss: 31.326487 | D loss: 1.453929\n",
            "Step 1340: G loss: 26.322260 | D loss: 1.448195\n",
            "Step 1341: G loss: 46.940613 | D loss: 1.511193\n",
            "Step 1342: G loss: 42.936176 | D loss: 1.468406\n",
            "Step 1343: G loss: 33.772717 | D loss: 1.448948\n",
            "Step 1344: G loss: 21.877420 | D loss: 1.450374\n",
            "Step 1345: G loss: 24.043468 | D loss: 1.467180\n",
            "Step 1346: G loss: 41.873119 | D loss: 1.467040\n",
            "Step 1347: G loss: 35.502651 | D loss: 1.463603\n",
            "Step 1348: G loss: 48.744175 | D loss: 1.444006\n",
            "Step 1349: G loss: 24.713100 | D loss: 1.446260\n",
            "Step 1350: G loss: 27.776714 | D loss: 1.446371\n",
            "Step 1351: G loss: 30.044868 | D loss: 1.468101\n",
            "Step 1352: G loss: 28.070765 | D loss: 1.448470\n",
            "Step 1353: G loss: 30.334202 | D loss: 1.453221\n",
            "Step 1354: G loss: 39.116367 | D loss: 1.468415\n",
            "Step 1355: G loss: 29.190422 | D loss: 1.457888\n",
            "Step 1356: G loss: 26.995190 | D loss: 1.440718\n",
            "Step 1357: G loss: 30.596392 | D loss: 1.436600\n",
            "Step 1358: G loss: 17.060694 | D loss: 1.514055\n",
            "Step 1359: G loss: 27.729549 | D loss: 1.490270\n",
            "Step 1360: G loss: 39.479046 | D loss: 1.467539\n",
            "Step 1361: G loss: 29.140234 | D loss: 1.449670\n",
            "Step 1362: G loss: 30.350330 | D loss: 1.473460\n",
            "Step 1363: G loss: 47.950657 | D loss: 1.465957\n",
            "Step 1364: G loss: 32.292728 | D loss: 1.452959\n",
            "Step 1365: G loss: 25.125082 | D loss: 1.477907\n",
            "Step 1366: G loss: 35.421734 | D loss: 1.484534\n",
            "Step 1367: G loss: 28.187914 | D loss: 1.451639\n",
            "Step 1368: G loss: 26.728693 | D loss: 1.446809\n",
            "Step 1369: G loss: 30.484962 | D loss: 1.459008\n",
            "Step 1370: G loss: 28.343809 | D loss: 1.468355\n",
            "Step 1371: G loss: 21.845701 | D loss: 1.458595\n",
            "Step 1372: G loss: 31.144974 | D loss: 1.483454\n",
            "Step 1373: G loss: 32.003490 | D loss: 1.483273\n",
            "Step 1374: G loss: 22.693333 | D loss: 1.466846\n",
            "Step 1375: G loss: 23.955593 | D loss: 1.488756\n",
            "Step 1376: G loss: 42.258305 | D loss: 1.454129\n",
            "Step 1377: G loss: 26.936455 | D loss: 1.464170\n",
            "Step 1378: G loss: 29.032234 | D loss: 1.452856\n",
            "Step 1379: G loss: 30.252876 | D loss: 1.456617\n",
            "Step 1380: G loss: 38.069862 | D loss: 1.466450\n",
            "Step 1381: G loss: 31.670763 | D loss: 1.454693\n",
            "Step 1382: G loss: 36.357876 | D loss: 1.459300\n",
            "Step 1383: G loss: 26.521246 | D loss: 1.467319\n",
            "Step 1384: G loss: 22.815222 | D loss: 1.460763\n",
            "Step 1385: G loss: 30.488991 | D loss: 1.459421\n",
            "Step 1386: G loss: 30.613243 | D loss: 1.436280\n",
            "Step 1387: G loss: 47.629478 | D loss: 1.431511\n",
            "Step 1388: G loss: 24.365730 | D loss: 1.504888\n",
            "Step 1389: G loss: 28.298542 | D loss: 1.464479\n",
            "Step 1390: G loss: 48.008877 | D loss: 1.458712\n",
            "Step 1391: G loss: 26.814787 | D loss: 1.459397\n",
            "Step 1392: G loss: 35.711739 | D loss: 1.444612\n",
            "Step 1393: G loss: 38.499470 | D loss: 1.433964\n",
            "Step 1394: G loss: 28.287546 | D loss: 1.453892\n",
            "Step 1395: G loss: 38.409058 | D loss: 1.471256\n",
            "Step 1396: G loss: 31.735804 | D loss: 1.446980\n",
            "Step 1397: G loss: 27.396679 | D loss: 1.441766\n",
            "Step 1398: G loss: 26.119949 | D loss: 1.471859\n",
            "Step 1399: G loss: 36.341629 | D loss: 1.466328\n",
            "Step 1400: G loss: 32.894886 | D loss: 1.450515\n",
            "Step 1401: G loss: 32.807690 | D loss: 1.446242\n",
            "Step 1402: G loss: 47.460575 | D loss: 1.443878\n",
            "Step 1403: G loss: 26.592628 | D loss: 1.447456\n",
            "Step 1404: G loss: 27.259020 | D loss: 1.512654\n",
            "Step 1405: G loss: 46.048344 | D loss: 1.450965\n",
            "Step 1406: G loss: 32.264526 | D loss: 1.445616\n",
            "Step 1407: G loss: 38.494968 | D loss: 1.451212\n",
            "Step 1408: G loss: 26.184204 | D loss: 1.434421\n",
            "Step 1409: G loss: 33.209625 | D loss: 1.464984\n",
            "Step 1410: G loss: 30.968199 | D loss: 1.471164\n",
            "Step 1411: G loss: 28.203888 | D loss: 1.449288\n",
            "Step 1412: G loss: 19.445042 | D loss: 1.460030\n",
            "Step 1413: G loss: 38.548103 | D loss: 1.449547\n",
            "Step 1414: G loss: 39.256607 | D loss: 1.461320\n",
            "Step 1415: G loss: 23.560818 | D loss: 1.436670\n",
            "Step 1416: G loss: 36.345879 | D loss: 1.444206\n",
            "Step 1417: G loss: 30.193989 | D loss: 1.440312\n",
            "Step 1418: G loss: 35.979225 | D loss: 1.479616\n",
            "Step 1419: G loss: 27.537561 | D loss: 1.446062\n",
            "Step 1420: G loss: 25.865067 | D loss: 1.477511\n",
            "Step 1421: G loss: 34.760216 | D loss: 1.469918\n",
            "Step 1422: G loss: 30.539062 | D loss: 1.456607\n",
            "Step 1423: G loss: 27.106007 | D loss: 1.483125\n",
            "Step 1424: G loss: 38.819862 | D loss: 1.464355\n",
            "Step 1425: G loss: 34.752666 | D loss: 1.464354\n",
            "Step 1426: G loss: 32.976780 | D loss: 1.442326\n",
            "Step 1427: G loss: 30.983599 | D loss: 1.435291\n",
            "Step 1428: G loss: 20.858377 | D loss: 1.451116\n",
            "Step 1429: G loss: 23.648588 | D loss: 1.484877\n",
            "Step 1430: G loss: 25.021368 | D loss: 1.494062\n",
            "Step 1431: G loss: 43.380146 | D loss: 1.439828\n",
            "Step 1432: G loss: 38.847347 | D loss: 1.443455\n",
            "Step 1433: G loss: 38.547367 | D loss: 1.447146\n",
            "Step 1434: G loss: 31.534386 | D loss: 1.481899\n",
            "Step 1435: G loss: 40.767223 | D loss: 1.456975\n",
            "Step 1436: G loss: 44.552856 | D loss: 1.468148\n",
            "Step 1437: G loss: 39.526752 | D loss: 1.477776\n",
            "Step 1438: G loss: 33.818008 | D loss: 1.458418\n",
            "Step 1439: G loss: 32.932987 | D loss: 1.460526\n",
            "Step 1440: G loss: 28.733328 | D loss: 1.455693\n",
            "Step 1441: G loss: 45.403671 | D loss: 1.443584\n",
            "Step 1442: G loss: 46.167187 | D loss: 1.461502\n",
            "Step 1443: G loss: 32.760410 | D loss: 1.450599\n",
            "Step 1444: G loss: 33.298672 | D loss: 1.444386\n",
            "Step 1445: G loss: 38.078705 | D loss: 1.472215\n",
            "Step 1446: G loss: 40.641792 | D loss: 1.468330\n",
            "Step 1447: G loss: 25.799904 | D loss: 1.448588\n",
            "Step 1448: G loss: 37.330444 | D loss: 1.432729\n",
            "Step 1449: G loss: 42.422024 | D loss: 1.442938\n",
            "Step 1450: G loss: 23.302475 | D loss: 1.475690\n",
            "Step 1451: G loss: 38.657303 | D loss: 1.467929\n",
            "Step 1452: G loss: 28.703852 | D loss: 1.487795\n",
            "Step 1453: G loss: 37.151413 | D loss: 1.456576\n",
            "Step 1454: G loss: 27.588348 | D loss: 1.456844\n",
            "Step 1455: G loss: 28.185146 | D loss: 1.472186\n",
            "Step 1456: G loss: 24.339842 | D loss: 1.438950\n",
            "Step 1457: G loss: 31.437033 | D loss: 1.456567\n",
            "Step 1458: G loss: 29.034697 | D loss: 1.456941\n",
            "Step 1459: G loss: 23.871927 | D loss: 1.457278\n",
            "Step 1460: G loss: 32.254879 | D loss: 1.448249\n",
            "Step 1461: G loss: 41.496338 | D loss: 1.433939\n",
            "Step 1462: G loss: 24.982569 | D loss: 1.444922\n",
            "Step 1463: G loss: 41.533398 | D loss: 1.440806\n",
            "Step 1464: G loss: 40.727535 | D loss: 1.436089\n",
            "Step 1465: G loss: 30.558329 | D loss: 1.438086\n",
            "Step 1466: G loss: 25.126484 | D loss: 1.453990\n",
            "Step 1467: G loss: 29.082401 | D loss: 1.463035\n",
            "Step 1468: G loss: 26.351419 | D loss: 1.443904\n",
            "Step 1469: G loss: 33.001987 | D loss: 1.449100\n",
            "Step 1470: G loss: 32.331738 | D loss: 1.446790\n",
            "Step 1471: G loss: 30.003017 | D loss: 1.466191\n",
            "Step 1472: G loss: 27.320286 | D loss: 1.482316\n",
            "Step 1473: G loss: 28.883007 | D loss: 1.444706\n",
            "Step 1474: G loss: 38.451473 | D loss: 1.453542\n",
            "Step 1475: G loss: 24.728767 | D loss: 1.432143\n",
            "Step 1476: G loss: 42.472977 | D loss: 1.431176\n",
            "Step 1477: G loss: 24.457041 | D loss: 1.441597\n",
            "Step 1478: G loss: 33.475201 | D loss: 1.433635\n",
            "Step 1479: G loss: 19.635483 | D loss: 1.473696\n",
            "Step 1480: G loss: 29.668657 | D loss: 1.472931\n",
            "Step 1481: G loss: 29.670979 | D loss: 1.451247\n",
            "Step 1482: G loss: 28.088598 | D loss: 1.458170\n",
            "Step 1483: G loss: 31.770548 | D loss: 1.453163\n",
            "Step 1484: G loss: 32.866226 | D loss: 1.445878\n",
            "Step 1485: G loss: 29.097933 | D loss: 1.445402\n",
            "Step 1486: G loss: 26.193966 | D loss: 1.446784\n",
            "Step 1487: G loss: 32.273144 | D loss: 1.474572\n",
            "Step 1488: G loss: 37.767929 | D loss: 1.489205\n",
            "Step 1489: G loss: 26.595819 | D loss: 1.444635\n",
            "Step 1490: G loss: 41.617851 | D loss: 1.456384\n",
            "Step 1491: G loss: 35.609158 | D loss: 1.454481\n",
            "Step 1492: G loss: 39.587795 | D loss: 1.463394\n",
            "Step 1493: G loss: 30.959087 | D loss: 1.456837\n",
            "Step 1494: G loss: 39.776398 | D loss: 1.467210\n",
            "Step 1495: G loss: 46.410690 | D loss: 1.437218\n",
            "Step 1496: G loss: 30.225441 | D loss: 1.455448\n",
            "Step 1497: G loss: 35.434456 | D loss: 1.466673\n",
            "Step 1498: G loss: 39.309338 | D loss: 1.449197\n",
            "Step 1499: G loss: 28.191700 | D loss: 1.438752\n",
            "Step 1500: G loss: 33.771179 | D loss: 1.446684\n",
            "Step 1501: G loss: 27.854467 | D loss: 1.436902\n",
            "Step 1502: G loss: 32.055954 | D loss: 1.464255\n",
            "Step 1503: G loss: 29.038254 | D loss: 1.458544\n",
            "Step 1504: G loss: 35.086536 | D loss: 1.457012\n",
            "Step 1505: G loss: 39.752441 | D loss: 1.449620\n",
            "Step 1506: G loss: 29.180071 | D loss: 1.463591\n",
            "Step 1507: G loss: 54.405159 | D loss: 1.461138\n",
            "Step 1508: G loss: 30.346783 | D loss: 1.468273\n",
            "Step 1509: G loss: 23.205225 | D loss: 1.456333\n",
            "Step 1510: G loss: 34.807106 | D loss: 1.436598\n",
            "Step 1511: G loss: 26.318743 | D loss: 1.450336\n",
            "Step 1512: G loss: 27.818602 | D loss: 1.446323\n",
            "Step 1513: G loss: 26.829470 | D loss: 1.435912\n",
            "Step 1514: G loss: 35.600754 | D loss: 1.447756\n",
            "Step 1515: G loss: 28.877975 | D loss: 1.462403\n",
            "Step 1516: G loss: 29.048141 | D loss: 1.436955\n",
            "Step 1517: G loss: 19.267509 | D loss: 1.461532\n",
            "Step 1518: G loss: 33.549217 | D loss: 1.445424\n",
            "Step 1519: G loss: 35.164368 | D loss: 1.447669\n",
            "Step 1520: G loss: 30.760818 | D loss: 1.446061\n",
            "Step 1521: G loss: 29.214970 | D loss: 1.449701\n",
            "Step 1522: G loss: 24.409836 | D loss: 1.482687\n",
            "Step 1523: G loss: 28.331627 | D loss: 1.435008\n",
            "Step 1524: G loss: 21.876249 | D loss: 1.463457\n",
            "Step 1525: G loss: 27.017824 | D loss: 1.462547\n",
            "Step 1526: G loss: 39.815807 | D loss: 1.441688\n",
            "Step 1527: G loss: 26.242476 | D loss: 1.452974\n",
            "Step 1528: G loss: 42.087704 | D loss: 1.439666\n",
            "Step 1529: G loss: 35.162060 | D loss: 1.450364\n",
            "Step 1530: G loss: 34.295650 | D loss: 1.429843\n",
            "Step 1531: G loss: 30.681793 | D loss: 1.437839\n",
            "Step 1532: G loss: 27.914175 | D loss: 1.451033\n",
            "Step 1533: G loss: 34.209122 | D loss: 1.476673\n",
            "Step 1534: G loss: 28.265741 | D loss: 1.476410\n",
            "Step 1535: G loss: 22.700464 | D loss: 1.480862\n",
            "Step 1536: G loss: 20.086355 | D loss: 1.475870\n",
            "Step 1537: G loss: 44.968307 | D loss: 1.483813\n",
            "Step 1538: G loss: 37.392181 | D loss: 1.454268\n",
            "Step 1539: G loss: 23.136774 | D loss: 1.462598\n",
            "Step 1540: G loss: 22.485744 | D loss: 1.438877\n",
            "Step 1541: G loss: 41.521767 | D loss: 1.445111\n",
            "Step 1542: G loss: 27.107693 | D loss: 1.442141\n",
            "Step 1543: G loss: 43.102261 | D loss: 1.455115\n",
            "Step 1544: G loss: 25.495514 | D loss: 1.431221\n",
            "Step 1545: G loss: 29.590105 | D loss: 1.503493\n",
            "Step 1546: G loss: 23.401554 | D loss: 1.469095\n",
            "Step 1547: G loss: 41.122253 | D loss: 1.430892\n",
            "Step 1548: G loss: 35.274643 | D loss: 1.444728\n",
            "Step 1549: G loss: 49.439289 | D loss: 1.441221\n",
            "Step 1550: G loss: 31.661264 | D loss: 1.468533\n",
            "Step 1551: G loss: 34.641754 | D loss: 1.454608\n",
            "Step 1552: G loss: 30.083347 | D loss: 1.442161\n",
            "Step 1553: G loss: 34.755154 | D loss: 1.463707\n",
            "Step 1554: G loss: 39.042885 | D loss: 1.442191\n",
            "Step 1555: G loss: 23.970224 | D loss: 1.458554\n",
            "Step 1556: G loss: 31.240812 | D loss: 1.450291\n",
            "Step 1557: G loss: 29.468304 | D loss: 1.432384\n",
            "Step 1558: G loss: 26.483152 | D loss: 1.461601\n",
            "Step 1559: G loss: 36.441868 | D loss: 1.430549\n",
            "Step 1560: G loss: 27.555550 | D loss: 1.450557\n",
            "Step 1561: G loss: 32.235336 | D loss: 1.453402\n",
            "Step 1562: G loss: 25.701376 | D loss: 1.435516\n",
            "Step 1563: G loss: 31.254198 | D loss: 1.451653\n",
            "Step 1564: G loss: 30.839750 | D loss: 1.430187\n",
            "Step 1565: G loss: 28.506226 | D loss: 1.451134\n",
            "Step 1566: G loss: 33.441494 | D loss: 1.462665\n",
            "Step 1567: G loss: 26.854729 | D loss: 1.448873\n",
            "Step 1568: G loss: 25.783779 | D loss: 1.459454\n",
            "Step 1569: G loss: 40.943462 | D loss: 1.462392\n",
            "Step 1570: G loss: 32.803432 | D loss: 1.456742\n",
            "Step 1571: G loss: 32.440174 | D loss: 1.461627\n",
            "Step 1572: G loss: 41.667992 | D loss: 1.430748\n",
            "Step 1573: G loss: 28.616165 | D loss: 1.430135\n",
            "Step 1574: G loss: 41.216377 | D loss: 1.456465\n",
            "Step 1575: G loss: 35.267174 | D loss: 1.465926\n",
            "Step 1576: G loss: 24.572573 | D loss: 1.429780\n",
            "Step 1577: G loss: 25.209272 | D loss: 1.456354\n",
            "Step 1578: G loss: 31.541435 | D loss: 1.435008\n",
            "Step 1579: G loss: 31.920485 | D loss: 1.430807\n",
            "Step 1580: G loss: 28.672153 | D loss: 1.445577\n",
            "Step 1581: G loss: 35.573334 | D loss: 1.430297\n",
            "Step 1582: G loss: 42.405899 | D loss: 1.432692\n",
            "Step 1583: G loss: 31.636463 | D loss: 1.446516\n",
            "Step 1584: G loss: 31.233326 | D loss: 1.455433\n",
            "Step 1585: G loss: 31.214911 | D loss: 1.429875\n",
            "Step 1586: G loss: 31.290070 | D loss: 1.464550\n",
            "Step 1587: G loss: 32.549126 | D loss: 1.430136\n",
            "Step 1588: G loss: 47.552013 | D loss: 1.448502\n",
            "Step 1589: G loss: 23.615845 | D loss: 1.457926\n",
            "Step 1590: G loss: 29.833513 | D loss: 1.456275\n",
            "Step 1591: G loss: 48.518478 | D loss: 1.431586\n",
            "Step 1592: G loss: 20.915016 | D loss: 1.449531\n",
            "Step 1593: G loss: 35.220806 | D loss: 1.433037\n",
            "Step 1594: G loss: 23.231493 | D loss: 1.445408\n",
            "Step 1595: G loss: 33.509922 | D loss: 1.433408\n",
            "Step 1596: G loss: 49.856380 | D loss: 1.450884\n",
            "Step 1597: G loss: 28.645260 | D loss: 1.449374\n",
            "Step 1598: G loss: 37.043037 | D loss: 1.450413\n",
            "Step 1599: G loss: 37.951698 | D loss: 1.458761\n",
            "Step 1600: G loss: 29.363222 | D loss: 1.451931\n",
            "Step 1601: G loss: 28.809261 | D loss: 1.460075\n",
            "Step 1602: G loss: 28.704172 | D loss: 1.458287\n",
            "Step 1603: G loss: 35.103519 | D loss: 1.434041\n",
            "Step 1604: G loss: 45.958263 | D loss: 1.463232\n",
            "Step 1605: G loss: 36.753281 | D loss: 1.445310\n",
            "Step 1606: G loss: 39.282181 | D loss: 1.438714\n",
            "Step 1607: G loss: 39.067272 | D loss: 1.440029\n",
            "Step 1608: G loss: 28.340696 | D loss: 1.446945\n",
            "Step 1609: G loss: 30.430874 | D loss: 1.456311\n",
            "Step 1610: G loss: 33.426609 | D loss: 1.474289\n",
            "Step 1611: G loss: 36.763138 | D loss: 1.471765\n",
            "Step 1612: G loss: 27.645996 | D loss: 1.473479\n",
            "Step 1613: G loss: 37.018017 | D loss: 1.458942\n",
            "Step 1614: G loss: 44.782848 | D loss: 1.449203\n",
            "Step 1615: G loss: 25.749725 | D loss: 1.439108\n",
            "Step 1616: G loss: 26.830349 | D loss: 1.462440\n",
            "Step 1617: G loss: 22.447584 | D loss: 1.440418\n",
            "Step 1618: G loss: 27.826675 | D loss: 1.443154\n",
            "Step 1619: G loss: 24.005568 | D loss: 1.435534\n",
            "Step 1620: G loss: 32.545979 | D loss: 1.444567\n",
            "Step 1621: G loss: 53.350155 | D loss: 1.442418\n",
            "Step 1622: G loss: 34.035572 | D loss: 1.469971\n",
            "Step 1623: G loss: 30.023317 | D loss: 1.492877\n",
            "Step 1624: G loss: 32.246971 | D loss: 1.471923\n",
            "Step 1625: G loss: 34.018570 | D loss: 1.454632\n",
            "Step 1626: G loss: 39.817844 | D loss: 1.447089\n",
            "Step 1627: G loss: 24.477106 | D loss: 1.448028\n",
            "Step 1628: G loss: 24.672180 | D loss: 1.475586\n",
            "Step 1629: G loss: 48.163048 | D loss: 1.443169\n",
            "Step 1630: G loss: 25.857346 | D loss: 1.467563\n",
            "Step 1631: G loss: 30.544806 | D loss: 1.471970\n",
            "Step 1632: G loss: 30.943768 | D loss: 1.454958\n",
            "Step 1633: G loss: 24.478365 | D loss: 1.433427\n",
            "Step 1634: G loss: 23.645113 | D loss: 1.454462\n",
            "Step 1635: G loss: 32.423504 | D loss: 1.489786\n",
            "Step 1636: G loss: 29.404753 | D loss: 1.449679\n",
            "Step 1637: G loss: 38.815098 | D loss: 1.442918\n",
            "Step 1638: G loss: 36.807487 | D loss: 1.463739\n",
            "Step 1639: G loss: 37.755573 | D loss: 1.475118\n",
            "Step 1640: G loss: 27.000221 | D loss: 1.464918\n",
            "Step 1641: G loss: 33.944706 | D loss: 1.437984\n",
            "Step 1642: G loss: 29.155310 | D loss: 1.457532\n",
            "Step 1643: G loss: 36.350430 | D loss: 1.468163\n",
            "Step 1644: G loss: 40.517689 | D loss: 1.432944\n",
            "Step 1645: G loss: 37.824532 | D loss: 1.453127\n",
            "Step 1646: G loss: 26.122862 | D loss: 1.463544\n",
            "Step 1647: G loss: 22.328402 | D loss: 1.464223\n",
            "Step 1648: G loss: 35.014046 | D loss: 1.458003\n",
            "Step 1649: G loss: 29.308155 | D loss: 1.431696\n",
            "Step 1650: G loss: 25.524797 | D loss: 1.429249\n",
            "Step 1651: G loss: 32.605663 | D loss: 1.473503\n",
            "Step 1652: G loss: 35.612926 | D loss: 1.429894\n",
            "Step 1653: G loss: 34.430546 | D loss: 1.451283\n",
            "Step 1654: G loss: 38.984203 | D loss: 1.440904\n",
            "Step 1655: G loss: 38.439091 | D loss: 1.447153\n",
            "Step 1656: G loss: 20.319965 | D loss: 1.436476\n",
            "Step 1657: G loss: 40.172676 | D loss: 1.456455\n",
            "Step 1658: G loss: 42.850292 | D loss: 1.447304\n",
            "Step 1659: G loss: 32.272984 | D loss: 1.458118\n",
            "Step 1660: G loss: 29.495644 | D loss: 1.460407\n",
            "Step 1661: G loss: 43.127144 | D loss: 1.471320\n",
            "Step 1662: G loss: 26.764175 | D loss: 1.440566\n",
            "Step 1663: G loss: 27.557852 | D loss: 1.436330\n",
            "Step 1664: G loss: 24.892153 | D loss: 1.466505\n",
            "Step 1665: G loss: 22.647865 | D loss: 1.451249\n",
            "Step 1666: G loss: 24.385120 | D loss: 1.443482\n",
            "Step 1667: G loss: 33.238209 | D loss: 1.429681\n",
            "Step 1668: G loss: 29.827799 | D loss: 1.462255\n",
            "Step 1669: G loss: 30.658016 | D loss: 1.440205\n",
            "Step 1670: G loss: 42.116867 | D loss: 1.471791\n",
            "Step 1671: G loss: 26.525949 | D loss: 1.431982\n",
            "Step 1672: G loss: 39.580444 | D loss: 1.448044\n",
            "Step 1673: G loss: 31.760315 | D loss: 1.452426\n",
            "Step 1674: G loss: 43.027767 | D loss: 1.457937\n",
            "Step 1675: G loss: 36.400032 | D loss: 1.466321\n",
            "Step 1676: G loss: 43.597561 | D loss: 1.450565\n",
            "Step 1677: G loss: 31.325159 | D loss: 1.440748\n",
            "Step 1678: G loss: 31.782333 | D loss: 1.477891\n",
            "Step 1679: G loss: 40.183319 | D loss: 1.476801\n",
            "Step 1680: G loss: 34.772987 | D loss: 1.442318\n",
            "Step 1681: G loss: 42.684727 | D loss: 1.463649\n",
            "Step 1682: G loss: 26.119991 | D loss: 1.467733\n",
            "Step 1683: G loss: 43.160480 | D loss: 1.469710\n",
            "Step 1684: G loss: 18.641874 | D loss: 1.449342\n",
            "Step 1685: G loss: 24.434641 | D loss: 1.447321\n",
            "Step 1686: G loss: 41.502922 | D loss: 1.448551\n",
            "Step 1687: G loss: 36.627735 | D loss: 1.450979\n",
            "Step 1688: G loss: 40.108757 | D loss: 1.469807\n",
            "Step 1689: G loss: 32.478096 | D loss: 1.438366\n",
            "Step 1690: G loss: 25.434191 | D loss: 1.437396\n",
            "Step 1691: G loss: 37.913631 | D loss: 1.429342\n",
            "Step 1692: G loss: 39.822971 | D loss: 1.452859\n",
            "Step 1693: G loss: 37.923992 | D loss: 1.447594\n",
            "Step 1694: G loss: 28.111076 | D loss: 1.459546\n",
            "Step 1695: G loss: 28.894943 | D loss: 1.431054\n",
            "Step 1696: G loss: 27.901985 | D loss: 1.460374\n",
            "Step 1697: G loss: 28.519037 | D loss: 1.460489\n",
            "Step 1698: G loss: 32.574295 | D loss: 1.451926\n",
            "Step 1699: G loss: 24.459549 | D loss: 1.435740\n",
            "Step 1700: G loss: 44.490665 | D loss: 1.455654\n",
            "Step 1701: G loss: 30.013330 | D loss: 1.460862\n",
            "Step 1702: G loss: 41.861443 | D loss: 1.469346\n",
            "Step 1703: G loss: 25.949451 | D loss: 1.461822\n",
            "Step 1704: G loss: 29.783627 | D loss: 1.428612\n",
            "Step 1705: G loss: 37.903503 | D loss: 1.470826\n",
            "Step 1706: G loss: 42.637516 | D loss: 1.451588\n",
            "Step 1707: G loss: 35.607010 | D loss: 1.461626\n",
            "Step 1708: G loss: 25.047884 | D loss: 1.433402\n",
            "Step 1709: G loss: 19.995338 | D loss: 1.432520\n",
            "Step 1710: G loss: 38.030472 | D loss: 1.432046\n",
            "Step 1711: G loss: 34.436016 | D loss: 1.452263\n",
            "Step 1712: G loss: 44.323441 | D loss: 1.428391\n",
            "Step 1713: G loss: 39.540592 | D loss: 1.446709\n",
            "Step 1714: G loss: 43.912659 | D loss: 1.431770\n",
            "Step 1715: G loss: 30.624508 | D loss: 1.431934\n",
            "Step 1716: G loss: 41.029850 | D loss: 1.436689\n",
            "Step 1717: G loss: 31.384600 | D loss: 1.444489\n",
            "Step 1718: G loss: 25.913454 | D loss: 1.438386\n",
            "Step 1719: G loss: 46.659138 | D loss: 1.458353\n",
            "Step 1720: G loss: 42.316898 | D loss: 1.457296\n",
            "Step 1721: G loss: 32.416466 | D loss: 1.435589\n",
            "Step 1722: G loss: 22.142778 | D loss: 1.444508\n",
            "Step 1723: G loss: 23.428919 | D loss: 1.457865\n",
            "Step 1724: G loss: 40.955544 | D loss: 1.436078\n",
            "Step 1725: G loss: 35.084351 | D loss: 1.454798\n",
            "Step 1726: G loss: 48.880089 | D loss: 1.434473\n",
            "Step 1727: G loss: 24.284220 | D loss: 1.440748\n",
            "Step 1728: G loss: 27.260023 | D loss: 1.437008\n",
            "Step 1729: G loss: 30.004539 | D loss: 1.454414\n",
            "Step 1730: G loss: 27.118368 | D loss: 1.441871\n",
            "Step 1731: G loss: 30.134546 | D loss: 1.445349\n",
            "Step 1732: G loss: 38.619911 | D loss: 1.449335\n",
            "Step 1733: G loss: 28.834589 | D loss: 1.448839\n",
            "Step 1734: G loss: 27.100641 | D loss: 1.433760\n",
            "Step 1735: G loss: 30.138273 | D loss: 1.433346\n",
            "Step 1736: G loss: 16.897921 | D loss: 1.504589\n",
            "Step 1737: G loss: 27.325312 | D loss: 1.465268\n",
            "Step 1738: G loss: 38.928112 | D loss: 1.465246\n",
            "Step 1739: G loss: 28.540800 | D loss: 1.435986\n",
            "Step 1740: G loss: 29.862495 | D loss: 1.466119\n",
            "Step 1741: G loss: 47.590717 | D loss: 1.451932\n",
            "Step 1742: G loss: 32.390728 | D loss: 1.433362\n",
            "Step 1743: G loss: 24.689880 | D loss: 1.463609\n",
            "Step 1744: G loss: 33.943222 | D loss: 1.458260\n",
            "Step 1745: G loss: 28.448772 | D loss: 1.445050\n",
            "Step 1746: G loss: 26.904325 | D loss: 1.443898\n",
            "Step 1747: G loss: 30.718493 | D loss: 1.448909\n",
            "Step 1748: G loss: 28.058947 | D loss: 1.470218\n",
            "Step 1749: G loss: 22.203548 | D loss: 1.457828\n",
            "Step 1750: G loss: 31.169302 | D loss: 1.461549\n",
            "Step 1751: G loss: 32.137604 | D loss: 1.466426\n",
            "Step 1752: G loss: 22.520632 | D loss: 1.458699\n",
            "Step 1753: G loss: 24.024582 | D loss: 1.462019\n",
            "Step 1754: G loss: 41.661228 | D loss: 1.438182\n",
            "Step 1755: G loss: 26.391331 | D loss: 1.439895\n",
            "Step 1756: G loss: 28.459585 | D loss: 1.467344\n",
            "Step 1757: G loss: 28.836290 | D loss: 1.444630\n",
            "Step 1758: G loss: 38.050365 | D loss: 1.450953\n",
            "Step 1759: G loss: 31.133209 | D loss: 1.453628\n",
            "Step 1760: G loss: 36.097202 | D loss: 1.452574\n",
            "Step 1761: G loss: 26.602594 | D loss: 1.457011\n",
            "Step 1762: G loss: 22.716553 | D loss: 1.452639\n",
            "Step 1763: G loss: 30.552555 | D loss: 1.455308\n",
            "Step 1764: G loss: 30.172888 | D loss: 1.433341\n",
            "Step 1765: G loss: 47.361385 | D loss: 1.428256\n",
            "Step 1766: G loss: 24.058914 | D loss: 1.456114\n",
            "Step 1767: G loss: 28.024284 | D loss: 1.440759\n",
            "Step 1768: G loss: 47.390194 | D loss: 1.447390\n",
            "Step 1769: G loss: 26.468988 | D loss: 1.455732\n",
            "Step 1770: G loss: 35.415646 | D loss: 1.431577\n",
            "Step 1771: G loss: 38.663986 | D loss: 1.430713\n",
            "Step 1772: G loss: 28.123739 | D loss: 1.435833\n",
            "Step 1773: G loss: 38.343273 | D loss: 1.463981\n",
            "Step 1774: G loss: 31.683363 | D loss: 1.441619\n",
            "Step 1775: G loss: 27.547529 | D loss: 1.440572\n",
            "Step 1776: G loss: 26.165642 | D loss: 1.448168\n",
            "Step 1777: G loss: 35.843044 | D loss: 1.468329\n",
            "Step 1778: G loss: 33.827492 | D loss: 1.442997\n",
            "Step 1779: G loss: 32.274647 | D loss: 1.441655\n",
            "Step 1780: G loss: 47.687786 | D loss: 1.439778\n",
            "Step 1781: G loss: 26.117861 | D loss: 1.441815\n",
            "Step 1782: G loss: 26.583044 | D loss: 1.461537\n",
            "Step 1783: G loss: 46.053265 | D loss: 1.443515\n",
            "Step 1784: G loss: 31.861698 | D loss: 1.446547\n",
            "Step 1785: G loss: 38.295162 | D loss: 1.444367\n",
            "Step 1786: G loss: 25.940428 | D loss: 1.431543\n",
            "Step 1787: G loss: 32.914703 | D loss: 1.466648\n",
            "Step 1788: G loss: 30.381744 | D loss: 1.451725\n",
            "Step 1789: G loss: 27.837294 | D loss: 1.443774\n",
            "Step 1790: G loss: 19.391335 | D loss: 1.444952\n",
            "Step 1791: G loss: 38.208935 | D loss: 1.449468\n",
            "Step 1792: G loss: 39.366756 | D loss: 1.460223\n",
            "Step 1793: G loss: 23.159710 | D loss: 1.453294\n",
            "Step 1794: G loss: 36.149361 | D loss: 1.441712\n",
            "Step 1795: G loss: 29.745041 | D loss: 1.442572\n",
            "Step 1796: G loss: 35.610416 | D loss: 1.464017\n",
            "Step 1797: G loss: 27.104116 | D loss: 1.429425\n",
            "Step 1798: G loss: 25.451906 | D loss: 1.460486\n",
            "Step 1799: G loss: 34.148590 | D loss: 1.460429\n",
            "Step 1800: G loss: 30.342876 | D loss: 1.447578\n",
            "Step 1801: G loss: 26.911924 | D loss: 1.469012\n",
            "Step 1802: G loss: 39.252857 | D loss: 1.452920\n",
            "Step 1803: G loss: 34.442307 | D loss: 1.456807\n",
            "Step 1804: G loss: 33.005444 | D loss: 1.444223\n",
            "Step 1805: G loss: 30.932108 | D loss: 1.440004\n",
            "Step 1806: G loss: 20.956686 | D loss: 1.444503\n",
            "Step 1807: G loss: 23.450464 | D loss: 1.464149\n",
            "Step 1808: G loss: 24.793150 | D loss: 1.460548\n",
            "Step 1809: G loss: 42.870193 | D loss: 1.439600\n",
            "Step 1810: G loss: 37.756222 | D loss: 1.445504\n",
            "Step 1811: G loss: 38.109249 | D loss: 1.438402\n",
            "Step 1812: G loss: 31.393290 | D loss: 1.461299\n",
            "Step 1813: G loss: 40.589443 | D loss: 1.444332\n",
            "Step 1814: G loss: 44.535580 | D loss: 1.452914\n",
            "Step 1815: G loss: 39.468887 | D loss: 1.459885\n",
            "Step 1816: G loss: 32.924843 | D loss: 1.436109\n",
            "Step 1817: G loss: 32.444389 | D loss: 1.450268\n",
            "Step 1818: G loss: 28.508242 | D loss: 1.445560\n",
            "Step 1819: G loss: 44.817284 | D loss: 1.434745\n",
            "Step 1820: G loss: 45.652863 | D loss: 1.443048\n",
            "Step 1821: G loss: 32.277779 | D loss: 1.441514\n",
            "Step 1822: G loss: 33.084091 | D loss: 1.441854\n",
            "Step 1823: G loss: 37.139912 | D loss: 1.462911\n",
            "Step 1824: G loss: 39.712521 | D loss: 1.474059\n",
            "Step 1825: G loss: 25.313166 | D loss: 1.440781\n",
            "Step 1826: G loss: 36.352341 | D loss: 1.450072\n",
            "Step 1827: G loss: 41.665649 | D loss: 1.439838\n",
            "Step 1828: G loss: 22.461370 | D loss: 1.468225\n",
            "Step 1829: G loss: 38.221451 | D loss: 1.451308\n",
            "Step 1830: G loss: 27.132027 | D loss: 1.454077\n",
            "Step 1831: G loss: 36.959362 | D loss: 1.450898\n",
            "Step 1832: G loss: 27.797523 | D loss: 1.446044\n",
            "Step 1833: G loss: 27.635967 | D loss: 1.480386\n",
            "Step 1834: G loss: 24.371174 | D loss: 1.437649\n",
            "Step 1835: G loss: 30.502171 | D loss: 1.448727\n",
            "Step 1836: G loss: 28.883558 | D loss: 1.449655\n",
            "Step 1837: G loss: 23.709782 | D loss: 1.457617\n",
            "Step 1838: G loss: 31.674709 | D loss: 1.450190\n",
            "Step 1839: G loss: 40.636829 | D loss: 1.428520\n",
            "Step 1840: G loss: 22.984123 | D loss: 1.442752\n",
            "Step 1841: G loss: 40.635403 | D loss: 1.448953\n",
            "Step 1842: G loss: 40.486565 | D loss: 1.430081\n",
            "Step 1843: G loss: 30.007475 | D loss: 1.428680\n",
            "Step 1844: G loss: 25.389650 | D loss: 1.437667\n",
            "Step 1845: G loss: 28.279140 | D loss: 1.434057\n",
            "Step 1846: G loss: 26.332644 | D loss: 1.430320\n",
            "Step 1847: G loss: 32.743866 | D loss: 1.439909\n",
            "Step 1848: G loss: 32.079552 | D loss: 1.451093\n",
            "Step 1849: G loss: 30.192518 | D loss: 1.455720\n",
            "Step 1850: G loss: 25.510155 | D loss: 1.469685\n",
            "Step 1851: G loss: 28.674654 | D loss: 1.457234\n",
            "Step 1852: G loss: 38.941998 | D loss: 1.442661\n",
            "Step 1853: G loss: 24.417664 | D loss: 1.432238\n",
            "Step 1854: G loss: 43.096252 | D loss: 1.430092\n",
            "Step 1855: G loss: 24.547340 | D loss: 1.431775\n",
            "Step 1856: G loss: 33.296185 | D loss: 1.429473\n",
            "Step 1857: G loss: 19.372972 | D loss: 1.465356\n",
            "Step 1858: G loss: 29.443676 | D loss: 1.446262\n",
            "Step 1859: G loss: 28.677631 | D loss: 1.443172\n",
            "Step 1860: G loss: 27.912928 | D loss: 1.448932\n",
            "Step 1861: G loss: 31.781706 | D loss: 1.442498\n",
            "Step 1862: G loss: 32.039654 | D loss: 1.438775\n",
            "Step 1863: G loss: 29.216185 | D loss: 1.435287\n",
            "Step 1864: G loss: 26.567898 | D loss: 1.437325\n",
            "Step 1865: G loss: 32.710148 | D loss: 1.462339\n",
            "Step 1866: G loss: 37.759682 | D loss: 1.466362\n",
            "Step 1867: G loss: 25.892416 | D loss: 1.440660\n",
            "Step 1868: G loss: 40.568325 | D loss: 1.439280\n",
            "Step 1869: G loss: 34.044128 | D loss: 1.440703\n",
            "Step 1870: G loss: 38.586437 | D loss: 1.449096\n",
            "Step 1871: G loss: 29.987270 | D loss: 1.449704\n",
            "Step 1872: G loss: 38.679943 | D loss: 1.449845\n",
            "Step 1873: G loss: 46.193447 | D loss: 1.435442\n",
            "Step 1874: G loss: 30.123783 | D loss: 1.441770\n",
            "Step 1875: G loss: 34.859825 | D loss: 1.445348\n",
            "Step 1876: G loss: 39.371853 | D loss: 1.441329\n",
            "Step 1877: G loss: 27.593273 | D loss: 1.441079\n",
            "Step 1878: G loss: 33.585514 | D loss: 1.436710\n",
            "Step 1879: G loss: 27.745640 | D loss: 1.426939\n",
            "Step 1880: G loss: 32.190735 | D loss: 1.449270\n",
            "Step 1881: G loss: 28.752676 | D loss: 1.463309\n",
            "Step 1882: G loss: 34.977104 | D loss: 1.447252\n",
            "Step 1883: G loss: 39.193535 | D loss: 1.445778\n",
            "Step 1884: G loss: 28.508205 | D loss: 1.447332\n",
            "Step 1885: G loss: 52.868984 | D loss: 1.437042\n",
            "Step 1886: G loss: 29.787811 | D loss: 1.459312\n",
            "Step 1887: G loss: 23.473791 | D loss: 1.443612\n",
            "Step 1888: G loss: 34.073746 | D loss: 1.432007\n",
            "Step 1889: G loss: 25.476835 | D loss: 1.454588\n",
            "Step 1890: G loss: 27.737007 | D loss: 1.454677\n",
            "Step 1891: G loss: 26.746553 | D loss: 1.440972\n",
            "Step 1892: G loss: 35.392323 | D loss: 1.456428\n",
            "Step 1893: G loss: 28.419762 | D loss: 1.462422\n",
            "Step 1894: G loss: 28.578857 | D loss: 1.432793\n",
            "Step 1895: G loss: 19.056692 | D loss: 1.442871\n",
            "Step 1896: G loss: 33.850056 | D loss: 1.439958\n",
            "Step 1897: G loss: 34.392033 | D loss: 1.443705\n",
            "Step 1898: G loss: 30.203020 | D loss: 1.437461\n",
            "Step 1899: G loss: 29.420046 | D loss: 1.453038\n",
            "Step 1900: G loss: 24.255056 | D loss: 1.440957\n",
            "Step 1901: G loss: 26.664988 | D loss: 1.426383\n",
            "Step 1902: G loss: 21.956879 | D loss: 1.446217\n",
            "Step 1903: G loss: 26.907675 | D loss: 1.446687\n",
            "Step 1904: G loss: 38.823765 | D loss: 1.432561\n",
            "Step 1905: G loss: 26.014177 | D loss: 1.443166\n",
            "Step 1906: G loss: 40.482899 | D loss: 1.430521\n",
            "Step 1907: G loss: 34.571888 | D loss: 1.439642\n",
            "Step 1908: G loss: 33.577126 | D loss: 1.426904\n",
            "Step 1909: G loss: 30.628973 | D loss: 1.429537\n",
            "Step 1910: G loss: 28.091528 | D loss: 1.453042\n",
            "Step 1911: G loss: 33.124187 | D loss: 1.468227\n",
            "Step 1912: G loss: 27.471272 | D loss: 1.459099\n",
            "Step 1913: G loss: 22.199270 | D loss: 1.456084\n",
            "Step 1914: G loss: 19.743376 | D loss: 1.475201\n",
            "Step 1915: G loss: 45.067783 | D loss: 1.460818\n",
            "Step 1916: G loss: 36.066170 | D loss: 1.443089\n",
            "Step 1917: G loss: 22.476263 | D loss: 1.449975\n",
            "Step 1918: G loss: 21.461531 | D loss: 1.438876\n",
            "Step 1919: G loss: 38.883041 | D loss: 1.441035\n",
            "Step 1920: G loss: 26.635096 | D loss: 1.429640\n",
            "Step 1921: G loss: 42.916054 | D loss: 1.438445\n",
            "Step 1922: G loss: 25.512922 | D loss: 1.427393\n",
            "Step 1923: G loss: 29.288359 | D loss: 1.489962\n",
            "Step 1924: G loss: 24.109966 | D loss: 1.446473\n",
            "Step 1925: G loss: 41.262672 | D loss: 1.429081\n",
            "Step 1926: G loss: 34.221924 | D loss: 1.440640\n",
            "Step 1927: G loss: 48.713062 | D loss: 1.438775\n",
            "Step 1928: G loss: 31.456764 | D loss: 1.462256\n",
            "Step 1929: G loss: 33.828304 | D loss: 1.453208\n",
            "Step 1930: G loss: 29.884001 | D loss: 1.431755\n",
            "Step 1931: G loss: 35.692932 | D loss: 1.465052\n",
            "Step 1932: G loss: 39.477665 | D loss: 1.438585\n",
            "Step 1933: G loss: 23.865356 | D loss: 1.457334\n",
            "Step 1934: G loss: 30.831163 | D loss: 1.442902\n",
            "Step 1935: G loss: 27.977936 | D loss: 1.429819\n",
            "Step 1936: G loss: 25.447271 | D loss: 1.444063\n",
            "Step 1937: G loss: 36.994797 | D loss: 1.426498\n",
            "Step 1938: G loss: 25.932056 | D loss: 1.443614\n",
            "Step 1939: G loss: 32.314224 | D loss: 1.435254\n",
            "Step 1940: G loss: 25.447001 | D loss: 1.427793\n",
            "Step 1941: G loss: 30.970530 | D loss: 1.439861\n",
            "Step 1942: G loss: 29.998423 | D loss: 1.426320\n",
            "Step 1943: G loss: 27.848314 | D loss: 1.448397\n",
            "Step 1944: G loss: 33.463791 | D loss: 1.449369\n",
            "Step 1945: G loss: 26.343079 | D loss: 1.441183\n",
            "Step 1946: G loss: 26.278240 | D loss: 1.447395\n",
            "Step 1947: G loss: 40.425755 | D loss: 1.454991\n",
            "Step 1948: G loss: 32.854656 | D loss: 1.451426\n",
            "Step 1949: G loss: 31.822504 | D loss: 1.454899\n",
            "Step 1950: G loss: 42.189640 | D loss: 1.426495\n",
            "Step 1951: G loss: 28.138157 | D loss: 1.426157\n",
            "Step 1952: G loss: 39.762726 | D loss: 1.448682\n",
            "Step 1953: G loss: 34.820724 | D loss: 1.456239\n",
            "Step 1954: G loss: 23.173447 | D loss: 1.428626\n",
            "Step 1955: G loss: 24.671965 | D loss: 1.446543\n",
            "Step 1956: G loss: 29.760281 | D loss: 1.426050\n",
            "Step 1957: G loss: 31.507517 | D loss: 1.428342\n",
            "Step 1958: G loss: 27.878563 | D loss: 1.439448\n",
            "Step 1959: G loss: 34.893738 | D loss: 1.426952\n",
            "Step 1960: G loss: 40.945484 | D loss: 1.434029\n",
            "Step 1961: G loss: 30.940449 | D loss: 1.443042\n",
            "Step 1962: G loss: 30.774151 | D loss: 1.444018\n",
            "Step 1963: G loss: 31.630266 | D loss: 1.425858\n",
            "Step 1964: G loss: 29.975233 | D loss: 1.454417\n",
            "Step 1965: G loss: 31.983110 | D loss: 1.428576\n",
            "Step 1966: G loss: 47.299236 | D loss: 1.428093\n",
            "Step 1967: G loss: 24.374172 | D loss: 1.439717\n",
            "Step 1968: G loss: 29.489117 | D loss: 1.440145\n",
            "Step 1969: G loss: 47.975903 | D loss: 1.427971\n",
            "Step 1970: G loss: 21.721720 | D loss: 1.439865\n",
            "Step 1971: G loss: 34.793194 | D loss: 1.427582\n",
            "Step 1972: G loss: 23.954529 | D loss: 1.444963\n",
            "Step 1973: G loss: 33.026920 | D loss: 1.426981\n",
            "Step 1974: G loss: 49.434113 | D loss: 1.439969\n",
            "Step 1975: G loss: 27.914772 | D loss: 1.439488\n",
            "Step 1976: G loss: 37.045185 | D loss: 1.444864\n",
            "Step 1977: G loss: 38.249969 | D loss: 1.441955\n",
            "Step 1978: G loss: 29.390757 | D loss: 1.443211\n",
            "Step 1979: G loss: 29.491390 | D loss: 1.454262\n",
            "Step 1980: G loss: 29.157600 | D loss: 1.440383\n",
            "Step 1981: G loss: 34.904137 | D loss: 1.464422\n",
            "Step 1982: G loss: 46.165070 | D loss: 1.433191\n",
            "Step 1983: G loss: 35.060074 | D loss: 1.438467\n",
            "Step 1984: G loss: 38.876839 | D loss: 1.433252\n",
            "Step 1985: G loss: 39.885941 | D loss: 1.437626\n",
            "Step 1986: G loss: 27.737417 | D loss: 1.455842\n",
            "Step 1987: G loss: 29.408937 | D loss: 1.452778\n",
            "Step 1988: G loss: 33.367699 | D loss: 1.441214\n",
            "Step 1989: G loss: 35.111931 | D loss: 1.453835\n",
            "Step 1990: G loss: 27.063820 | D loss: 1.459199\n",
            "Step 1991: G loss: 37.322403 | D loss: 1.453151\n",
            "Step 1992: G loss: 44.195316 | D loss: 1.443809\n",
            "Step 1993: G loss: 25.815748 | D loss: 1.428967\n",
            "Step 1994: G loss: 27.207405 | D loss: 1.443032\n",
            "Step 1995: G loss: 22.556087 | D loss: 1.435124\n",
            "Step 1996: G loss: 27.130604 | D loss: 1.433686\n",
            "Step 1997: G loss: 23.780254 | D loss: 1.426257\n",
            "Step 1998: G loss: 32.473362 | D loss: 1.443206\n",
            "Step 1999: G loss: 52.548546 | D loss: 1.436906\n",
            "Step 2000: G loss: 33.430191 | D loss: 1.455189\n",
            "Step 2001: G loss: 29.921537 | D loss: 1.457823\n",
            "Step 2002: G loss: 31.260658 | D loss: 1.449041\n",
            "Step 2003: G loss: 33.415485 | D loss: 1.450200\n",
            "Step 2004: G loss: 39.720787 | D loss: 1.436485\n",
            "Step 2005: G loss: 24.357637 | D loss: 1.439883\n",
            "Step 2006: G loss: 24.258419 | D loss: 1.464058\n",
            "Step 2007: G loss: 47.744907 | D loss: 1.474028\n",
            "Step 2008: G loss: 25.350725 | D loss: 1.461704\n",
            "Step 2009: G loss: 30.786064 | D loss: 1.463890\n",
            "Step 2010: G loss: 30.974026 | D loss: 1.457945\n",
            "Step 2011: G loss: 24.398581 | D loss: 1.438336\n",
            "Step 2012: G loss: 23.071886 | D loss: 1.452889\n",
            "Step 2013: G loss: 31.387222 | D loss: 1.472772\n",
            "Step 2014: G loss: 29.045084 | D loss: 1.453716\n",
            "Step 2015: G loss: 39.016201 | D loss: 1.454370\n",
            "Step 2016: G loss: 35.747467 | D loss: 1.447560\n",
            "Step 2017: G loss: 37.541061 | D loss: 1.447295\n",
            "Step 2018: G loss: 26.188076 | D loss: 1.444818\n",
            "Step 2019: G loss: 33.522354 | D loss: 1.439395\n",
            "Step 2020: G loss: 28.485308 | D loss: 1.451790\n",
            "Step 2021: G loss: 36.522717 | D loss: 1.458019\n",
            "Step 2022: G loss: 39.814507 | D loss: 1.427351\n",
            "Step 2023: G loss: 36.587612 | D loss: 1.452536\n",
            "Step 2024: G loss: 25.465691 | D loss: 1.448020\n",
            "Step 2025: G loss: 22.811659 | D loss: 1.442274\n",
            "Step 2026: G loss: 34.226562 | D loss: 1.426158\n",
            "Step 2027: G loss: 29.593521 | D loss: 1.435622\n",
            "Step 2028: G loss: 25.359503 | D loss: 1.427169\n",
            "Step 2029: G loss: 32.592091 | D loss: 1.454784\n",
            "Step 2030: G loss: 35.099266 | D loss: 1.435339\n",
            "Step 2031: G loss: 34.235168 | D loss: 1.456653\n",
            "Step 2032: G loss: 38.870419 | D loss: 1.433492\n",
            "Step 2033: G loss: 38.545483 | D loss: 1.444926\n",
            "Step 2034: G loss: 20.276718 | D loss: 1.429027\n",
            "Step 2035: G loss: 40.089024 | D loss: 1.448184\n",
            "Step 2036: G loss: 42.521591 | D loss: 1.439070\n",
            "Step 2037: G loss: 32.156612 | D loss: 1.442459\n",
            "Step 2038: G loss: 28.637074 | D loss: 1.457943\n",
            "Step 2039: G loss: 41.311901 | D loss: 1.456652\n",
            "Step 2040: G loss: 26.713346 | D loss: 1.444443\n",
            "Step 2041: G loss: 27.569300 | D loss: 1.431455\n",
            "Step 2042: G loss: 23.883501 | D loss: 1.443751\n",
            "Step 2043: G loss: 22.281382 | D loss: 1.463054\n",
            "Step 2044: G loss: 24.463339 | D loss: 1.433869\n",
            "Step 2045: G loss: 33.352036 | D loss: 1.427845\n",
            "Step 2046: G loss: 29.718615 | D loss: 1.458563\n",
            "Step 2047: G loss: 30.518221 | D loss: 1.439797\n",
            "Step 2048: G loss: 41.501324 | D loss: 1.472603\n",
            "Step 2049: G loss: 26.722427 | D loss: 1.431131\n",
            "Step 2050: G loss: 39.264626 | D loss: 1.440250\n",
            "Step 2051: G loss: 31.617838 | D loss: 1.448488\n",
            "Step 2052: G loss: 42.197876 | D loss: 1.457454\n",
            "Step 2053: G loss: 36.312859 | D loss: 1.460208\n",
            "Step 2054: G loss: 42.284718 | D loss: 1.454078\n",
            "Step 2055: G loss: 30.444334 | D loss: 1.434509\n",
            "Step 2056: G loss: 31.121269 | D loss: 1.455514\n",
            "Step 2057: G loss: 39.596748 | D loss: 1.452878\n",
            "Step 2058: G loss: 34.998741 | D loss: 1.434379\n",
            "Step 2059: G loss: 42.372837 | D loss: 1.453835\n",
            "Step 2060: G loss: 26.388273 | D loss: 1.457425\n",
            "Step 2061: G loss: 42.989155 | D loss: 1.452107\n",
            "Step 2062: G loss: 18.734016 | D loss: 1.444820\n",
            "Step 2063: G loss: 23.854029 | D loss: 1.431993\n",
            "Step 2064: G loss: 41.071606 | D loss: 1.443925\n",
            "Step 2065: G loss: 35.765644 | D loss: 1.439924\n",
            "Step 2066: G loss: 40.551014 | D loss: 1.458069\n",
            "Step 2067: G loss: 32.706440 | D loss: 1.428322\n",
            "Step 2068: G loss: 24.196190 | D loss: 1.428320\n",
            "Step 2069: G loss: 36.933434 | D loss: 1.424889\n",
            "Step 2070: G loss: 38.862228 | D loss: 1.441556\n",
            "Step 2071: G loss: 37.167850 | D loss: 1.440606\n",
            "Step 2072: G loss: 28.146824 | D loss: 1.449335\n",
            "Step 2073: G loss: 28.207758 | D loss: 1.425907\n",
            "Step 2074: G loss: 27.314892 | D loss: 1.449182\n",
            "Step 2075: G loss: 28.203197 | D loss: 1.447072\n",
            "Step 2076: G loss: 32.586807 | D loss: 1.444402\n",
            "Step 2077: G loss: 24.138466 | D loss: 1.426180\n",
            "Step 2078: G loss: 44.671093 | D loss: 1.448115\n",
            "Step 2079: G loss: 30.556749 | D loss: 1.449598\n",
            "Step 2080: G loss: 41.651703 | D loss: 1.454743\n",
            "Step 2081: G loss: 25.887510 | D loss: 1.453400\n",
            "Step 2082: G loss: 29.618679 | D loss: 1.425063\n",
            "Step 2083: G loss: 38.167305 | D loss: 1.467861\n",
            "Step 2084: G loss: 42.247868 | D loss: 1.448358\n",
            "Step 2085: G loss: 35.517654 | D loss: 1.457849\n",
            "Step 2086: G loss: 24.622860 | D loss: 1.427348\n",
            "Step 2087: G loss: 19.748569 | D loss: 1.427130\n",
            "Step 2088: G loss: 38.233345 | D loss: 1.428379\n",
            "Step 2089: G loss: 34.519180 | D loss: 1.441571\n",
            "Step 2090: G loss: 44.587124 | D loss: 1.424695\n",
            "Step 2091: G loss: 39.624371 | D loss: 1.436994\n",
            "Step 2092: G loss: 43.307800 | D loss: 1.425389\n",
            "Step 2093: G loss: 31.229725 | D loss: 1.426665\n",
            "Step 2094: G loss: 39.959484 | D loss: 1.425268\n",
            "Step 2095: G loss: 31.677942 | D loss: 1.439334\n",
            "Step 2096: G loss: 25.426622 | D loss: 1.431362\n",
            "Step 2097: G loss: 46.030422 | D loss: 1.445013\n",
            "Step 2098: G loss: 42.151848 | D loss: 1.449118\n",
            "Step 2099: G loss: 32.071888 | D loss: 1.432580\n",
            "Step 2100: G loss: 22.395428 | D loss: 1.437873\n",
            "Step 2101: G loss: 22.702396 | D loss: 1.447519\n",
            "Step 2102: G loss: 40.297623 | D loss: 1.428619\n",
            "Step 2103: G loss: 35.081181 | D loss: 1.449798\n",
            "Step 2104: G loss: 49.003548 | D loss: 1.431784\n",
            "Step 2105: G loss: 23.967196 | D loss: 1.455929\n",
            "Step 2106: G loss: 27.473845 | D loss: 1.430350\n",
            "Step 2107: G loss: 29.943510 | D loss: 1.450373\n",
            "Step 2108: G loss: 26.833906 | D loss: 1.436944\n",
            "Step 2109: G loss: 29.608471 | D loss: 1.439444\n",
            "Step 2110: G loss: 37.438873 | D loss: 1.448563\n",
            "Step 2111: G loss: 28.649529 | D loss: 1.441500\n",
            "Step 2112: G loss: 26.946409 | D loss: 1.434751\n",
            "Step 2113: G loss: 29.961302 | D loss: 1.425669\n",
            "Step 2114: G loss: 16.517326 | D loss: 1.436367\n",
            "Step 2115: G loss: 26.988150 | D loss: 1.446255\n",
            "Step 2116: G loss: 38.501911 | D loss: 1.449237\n",
            "Step 2117: G loss: 28.346506 | D loss: 1.431945\n",
            "Step 2118: G loss: 29.367216 | D loss: 1.450303\n",
            "Step 2119: G loss: 46.765896 | D loss: 1.443942\n",
            "Step 2120: G loss: 32.161236 | D loss: 1.429405\n",
            "Step 2121: G loss: 24.309011 | D loss: 1.445842\n",
            "Step 2122: G loss: 31.927492 | D loss: 1.445501\n",
            "Step 2123: G loss: 28.900126 | D loss: 1.438051\n",
            "Step 2124: G loss: 26.908918 | D loss: 1.435837\n",
            "Step 2125: G loss: 31.481598 | D loss: 1.444968\n",
            "Step 2126: G loss: 27.536234 | D loss: 1.456286\n",
            "Step 2127: G loss: 22.990791 | D loss: 1.444109\n",
            "Step 2128: G loss: 30.253321 | D loss: 1.442723\n",
            "Step 2129: G loss: 31.169651 | D loss: 1.451589\n",
            "Step 2130: G loss: 21.962772 | D loss: 1.446404\n",
            "Step 2131: G loss: 23.685511 | D loss: 1.441306\n",
            "Step 2132: G loss: 41.751209 | D loss: 1.433993\n",
            "Step 2133: G loss: 25.952667 | D loss: 1.425486\n",
            "Step 2134: G loss: 28.466499 | D loss: 1.458097\n",
            "Step 2135: G loss: 28.268192 | D loss: 1.434499\n",
            "Step 2136: G loss: 37.382362 | D loss: 1.446994\n",
            "Step 2137: G loss: 30.497120 | D loss: 1.439973\n",
            "Step 2138: G loss: 34.724388 | D loss: 1.439747\n",
            "Step 2139: G loss: 26.590088 | D loss: 1.441248\n",
            "Step 2140: G loss: 22.228424 | D loss: 1.441304\n",
            "Step 2141: G loss: 29.918770 | D loss: 1.447294\n",
            "Step 2142: G loss: 30.480282 | D loss: 1.435885\n",
            "Step 2143: G loss: 46.319630 | D loss: 1.424296\n",
            "Step 2144: G loss: 23.664499 | D loss: 1.431827\n",
            "Step 2145: G loss: 27.828556 | D loss: 1.433505\n",
            "Step 2146: G loss: 47.416073 | D loss: 1.443070\n",
            "Step 2147: G loss: 26.730616 | D loss: 1.443151\n",
            "Step 2148: G loss: 35.065224 | D loss: 1.424629\n",
            "Step 2149: G loss: 38.646950 | D loss: 1.425015\n",
            "Step 2150: G loss: 27.816832 | D loss: 1.427302\n",
            "Step 2151: G loss: 38.399860 | D loss: 1.447281\n",
            "Step 2152: G loss: 31.711485 | D loss: 1.436726\n",
            "Step 2153: G loss: 27.393538 | D loss: 1.429794\n",
            "Step 2154: G loss: 25.994616 | D loss: 1.446797\n",
            "Step 2155: G loss: 35.706593 | D loss: 1.442373\n",
            "Step 2156: G loss: 32.779121 | D loss: 1.437150\n",
            "Step 2157: G loss: 31.853989 | D loss: 1.433033\n",
            "Step 2158: G loss: 47.540955 | D loss: 1.434423\n",
            "Step 2159: G loss: 25.400801 | D loss: 1.437489\n",
            "Step 2160: G loss: 26.152586 | D loss: 1.447224\n",
            "Step 2161: G loss: 46.215611 | D loss: 1.435707\n",
            "Step 2162: G loss: 31.412781 | D loss: 1.438988\n",
            "Step 2163: G loss: 38.122272 | D loss: 1.436716\n",
            "Step 2164: G loss: 26.160877 | D loss: 1.426570\n",
            "Step 2165: G loss: 32.204788 | D loss: 1.454223\n",
            "Step 2166: G loss: 29.933554 | D loss: 1.438736\n",
            "Step 2167: G loss: 27.380934 | D loss: 1.443579\n",
            "Step 2168: G loss: 19.071043 | D loss: 1.437913\n",
            "Step 2169: G loss: 37.911125 | D loss: 1.431615\n",
            "Step 2170: G loss: 38.936901 | D loss: 1.441851\n",
            "Step 2171: G loss: 22.783895 | D loss: 1.449048\n",
            "Step 2172: G loss: 35.767185 | D loss: 1.432625\n",
            "Step 2173: G loss: 29.226118 | D loss: 1.434636\n",
            "Step 2174: G loss: 34.989288 | D loss: 1.446195\n",
            "Step 2175: G loss: 27.313328 | D loss: 1.425450\n",
            "Step 2176: G loss: 25.333286 | D loss: 1.445499\n",
            "Step 2177: G loss: 33.131660 | D loss: 1.444102\n",
            "Step 2178: G loss: 29.930643 | D loss: 1.442112\n",
            "Step 2179: G loss: 26.841557 | D loss: 1.459393\n",
            "Step 2180: G loss: 38.616959 | D loss: 1.441972\n",
            "Step 2181: G loss: 33.940495 | D loss: 1.443469\n",
            "Step 2182: G loss: 32.859116 | D loss: 1.427795\n",
            "Step 2183: G loss: 30.391005 | D loss: 1.424808\n",
            "Step 2184: G loss: 20.932703 | D loss: 1.439485\n",
            "Step 2185: G loss: 22.205809 | D loss: 1.468069\n",
            "Step 2186: G loss: 24.308914 | D loss: 1.475772\n",
            "Step 2187: G loss: 42.457489 | D loss: 1.432738\n",
            "Step 2188: G loss: 36.896389 | D loss: 1.431606\n",
            "Step 2189: G loss: 37.186398 | D loss: 1.438767\n",
            "Step 2190: G loss: 31.279268 | D loss: 1.458314\n",
            "Step 2191: G loss: 39.740406 | D loss: 1.442748\n",
            "Step 2192: G loss: 44.750679 | D loss: 1.449853\n",
            "Step 2193: G loss: 38.826096 | D loss: 1.454819\n",
            "Step 2194: G loss: 31.766459 | D loss: 1.427084\n",
            "Step 2195: G loss: 31.549450 | D loss: 1.448579\n",
            "Step 2196: G loss: 28.064810 | D loss: 1.439885\n",
            "Step 2197: G loss: 44.227470 | D loss: 1.431315\n",
            "Step 2198: G loss: 45.494320 | D loss: 1.441674\n",
            "Step 2199: G loss: 31.684711 | D loss: 1.438524\n",
            "Step 2200: G loss: 32.171658 | D loss: 1.436633\n",
            "Step 2201: G loss: 35.709023 | D loss: 1.454579\n",
            "Step 2202: G loss: 39.601299 | D loss: 1.444775\n",
            "Step 2203: G loss: 24.824066 | D loss: 1.430236\n",
            "Step 2204: G loss: 35.392536 | D loss: 1.433529\n",
            "Step 2205: G loss: 40.772491 | D loss: 1.447058\n",
            "Step 2206: G loss: 20.320272 | D loss: 1.454331\n",
            "Step 2207: G loss: 36.630085 | D loss: 1.435768\n",
            "Step 2208: G loss: 25.202610 | D loss: 1.460071\n",
            "Step 2209: G loss: 35.737350 | D loss: 1.440043\n",
            "Step 2210: G loss: 27.835863 | D loss: 1.438636\n",
            "Step 2211: G loss: 27.973291 | D loss: 1.460719\n",
            "Step 2212: G loss: 24.141438 | D loss: 1.432505\n",
            "Step 2213: G loss: 28.799093 | D loss: 1.441818\n",
            "Step 2214: G loss: 28.783073 | D loss: 1.441234\n",
            "Step 2215: G loss: 23.705587 | D loss: 1.439118\n",
            "Step 2216: G loss: 31.632820 | D loss: 1.444690\n",
            "Step 2217: G loss: 39.943794 | D loss: 1.425651\n",
            "Step 2218: G loss: 21.653883 | D loss: 1.436014\n",
            "Step 2219: G loss: 39.589157 | D loss: 1.434139\n",
            "Step 2220: G loss: 39.831837 | D loss: 1.426492\n",
            "Step 2221: G loss: 29.459522 | D loss: 1.424566\n",
            "Step 2222: G loss: 25.889750 | D loss: 1.426647\n",
            "Step 2223: G loss: 28.567476 | D loss: 1.425498\n",
            "Step 2224: G loss: 26.181753 | D loss: 1.424834\n",
            "Step 2225: G loss: 32.738247 | D loss: 1.425918\n",
            "Step 2226: G loss: 30.782093 | D loss: 1.437900\n",
            "Step 2227: G loss: 29.449543 | D loss: 1.443815\n",
            "Step 2228: G loss: 24.863848 | D loss: 1.463339\n",
            "Step 2229: G loss: 27.745628 | D loss: 1.425184\n",
            "Step 2230: G loss: 38.656246 | D loss: 1.426295\n",
            "Step 2231: G loss: 24.331606 | D loss: 1.438757\n",
            "Step 2232: G loss: 41.720177 | D loss: 1.434944\n",
            "Step 2233: G loss: 23.766598 | D loss: 1.424007\n",
            "Step 2234: G loss: 32.903770 | D loss: 1.424566\n",
            "Step 2235: G loss: 20.278862 | D loss: 1.453798\n",
            "Step 2236: G loss: 28.884083 | D loss: 1.424480\n",
            "Step 2237: G loss: 29.108538 | D loss: 1.437279\n",
            "Step 2238: G loss: 27.596611 | D loss: 1.441245\n",
            "Step 2239: G loss: 31.688473 | D loss: 1.431143\n",
            "Step 2240: G loss: 31.349606 | D loss: 1.425759\n",
            "Step 2241: G loss: 28.736856 | D loss: 1.424206\n",
            "Step 2242: G loss: 25.631388 | D loss: 1.432821\n",
            "Step 2243: G loss: 32.578396 | D loss: 1.450941\n",
            "Step 2244: G loss: 37.632828 | D loss: 1.450392\n",
            "Step 2245: G loss: 26.915325 | D loss: 1.436930\n",
            "Step 2246: G loss: 40.831520 | D loss: 1.426836\n",
            "Step 2247: G loss: 34.968937 | D loss: 1.428133\n",
            "Step 2248: G loss: 37.774670 | D loss: 1.440786\n",
            "Step 2249: G loss: 28.995518 | D loss: 1.455960\n",
            "Step 2250: G loss: 38.668266 | D loss: 1.448878\n",
            "Step 2251: G loss: 46.092514 | D loss: 1.433915\n",
            "Step 2252: G loss: 29.787155 | D loss: 1.437853\n",
            "Step 2253: G loss: 34.932568 | D loss: 1.444644\n",
            "Step 2254: G loss: 38.896358 | D loss: 1.438712\n",
            "Step 2255: G loss: 27.027431 | D loss: 1.442356\n",
            "Step 2256: G loss: 34.310108 | D loss: 1.437751\n",
            "Step 2257: G loss: 27.913670 | D loss: 1.424125\n",
            "Step 2258: G loss: 32.034634 | D loss: 1.444934\n",
            "Step 2259: G loss: 28.301716 | D loss: 1.455600\n",
            "Step 2260: G loss: 34.521416 | D loss: 1.441539\n",
            "Step 2261: G loss: 38.322693 | D loss: 1.441664\n",
            "Step 2262: G loss: 28.041279 | D loss: 1.443646\n",
            "Step 2263: G loss: 51.223896 | D loss: 1.430392\n",
            "Step 2264: G loss: 29.000626 | D loss: 1.447263\n",
            "Step 2265: G loss: 23.569714 | D loss: 1.438604\n",
            "Step 2266: G loss: 33.432827 | D loss: 1.426409\n",
            "Step 2267: G loss: 25.149290 | D loss: 1.437780\n",
            "Step 2268: G loss: 27.863075 | D loss: 1.428067\n",
            "Step 2269: G loss: 26.490269 | D loss: 1.424754\n",
            "Step 2270: G loss: 34.372196 | D loss: 1.431171\n",
            "Step 2271: G loss: 28.244415 | D loss: 1.454976\n",
            "Step 2272: G loss: 27.754002 | D loss: 1.423712\n",
            "Step 2273: G loss: 19.319168 | D loss: 1.424908\n",
            "Step 2274: G loss: 34.286572 | D loss: 1.433673\n",
            "Step 2275: G loss: 33.244877 | D loss: 1.436389\n",
            "Step 2276: G loss: 29.283173 | D loss: 1.431152\n",
            "Step 2277: G loss: 29.265215 | D loss: 1.429851\n",
            "Step 2278: G loss: 24.248459 | D loss: 1.435659\n",
            "Step 2279: G loss: 24.444057 | D loss: 1.422997\n",
            "Step 2280: G loss: 22.433556 | D loss: 1.438556\n",
            "Step 2281: G loss: 26.644081 | D loss: 1.447644\n",
            "Step 2282: G loss: 38.694695 | D loss: 1.426093\n",
            "Step 2283: G loss: 26.031992 | D loss: 1.439324\n",
            "Step 2284: G loss: 39.473156 | D loss: 1.431299\n",
            "Step 2285: G loss: 33.551613 | D loss: 1.433476\n",
            "Step 2286: G loss: 33.398357 | D loss: 1.423077\n",
            "Step 2287: G loss: 31.001404 | D loss: 1.426065\n",
            "Step 2288: G loss: 28.204031 | D loss: 1.442665\n",
            "Step 2289: G loss: 31.884790 | D loss: 1.440392\n",
            "Step 2290: G loss: 27.175314 | D loss: 1.455329\n",
            "Step 2291: G loss: 21.996050 | D loss: 1.460147\n",
            "Step 2292: G loss: 20.141378 | D loss: 1.434255\n",
            "Step 2293: G loss: 44.711067 | D loss: 1.452718\n",
            "Step 2294: G loss: 34.922043 | D loss: 1.437909\n",
            "Step 2295: G loss: 22.640728 | D loss: 1.436881\n",
            "Step 2296: G loss: 20.183136 | D loss: 1.441100\n",
            "Step 2297: G loss: 37.764645 | D loss: 1.423255\n",
            "Step 2298: G loss: 25.634132 | D loss: 1.423436\n",
            "Step 2299: G loss: 41.792526 | D loss: 1.431827\n",
            "Step 2300: G loss: 26.213585 | D loss: 1.422918\n",
            "Step 2301: G loss: 27.777079 | D loss: 1.481543\n",
            "Step 2302: G loss: 24.108438 | D loss: 1.427683\n",
            "Step 2303: G loss: 40.935406 | D loss: 1.426309\n",
            "Step 2304: G loss: 33.734562 | D loss: 1.442534\n",
            "Step 2305: G loss: 47.011269 | D loss: 1.432063\n",
            "Step 2306: G loss: 31.747911 | D loss: 1.438196\n",
            "Step 2307: G loss: 33.194180 | D loss: 1.435561\n",
            "Step 2308: G loss: 29.397051 | D loss: 1.427516\n",
            "Step 2309: G loss: 34.234726 | D loss: 1.456513\n",
            "Step 2310: G loss: 38.901672 | D loss: 1.434338\n",
            "Step 2311: G loss: 23.745275 | D loss: 1.438261\n",
            "Step 2312: G loss: 30.454849 | D loss: 1.433244\n",
            "Step 2313: G loss: 27.803431 | D loss: 1.425364\n",
            "Step 2314: G loss: 25.672600 | D loss: 1.440858\n",
            "Step 2315: G loss: 36.238712 | D loss: 1.422835\n",
            "Step 2316: G loss: 25.539585 | D loss: 1.435457\n",
            "Step 2317: G loss: 32.097061 | D loss: 1.423795\n",
            "Step 2318: G loss: 25.338106 | D loss: 1.424877\n",
            "Step 2319: G loss: 31.025322 | D loss: 1.434333\n",
            "Step 2320: G loss: 28.319771 | D loss: 1.422808\n",
            "Step 2321: G loss: 27.007408 | D loss: 1.427578\n",
            "Step 2322: G loss: 31.867607 | D loss: 1.439003\n",
            "Step 2323: G loss: 25.372524 | D loss: 1.435312\n",
            "Step 2324: G loss: 25.848862 | D loss: 1.442445\n",
            "Step 2325: G loss: 40.864834 | D loss: 1.445853\n",
            "Step 2326: G loss: 32.769463 | D loss: 1.442243\n",
            "Step 2327: G loss: 30.674288 | D loss: 1.444623\n",
            "Step 2328: G loss: 42.097145 | D loss: 1.422677\n",
            "Step 2329: G loss: 27.495775 | D loss: 1.422759\n",
            "Step 2330: G loss: 39.297405 | D loss: 1.437373\n",
            "Step 2331: G loss: 32.446236 | D loss: 1.447892\n",
            "Step 2332: G loss: 21.412537 | D loss: 1.423574\n",
            "Step 2333: G loss: 24.914318 | D loss: 1.438982\n",
            "Step 2334: G loss: 29.321205 | D loss: 1.422526\n",
            "Step 2335: G loss: 30.590834 | D loss: 1.423239\n",
            "Step 2336: G loss: 26.615622 | D loss: 1.431514\n",
            "Step 2337: G loss: 34.727673 | D loss: 1.422704\n",
            "Step 2338: G loss: 42.433949 | D loss: 1.430029\n",
            "Step 2339: G loss: 30.800232 | D loss: 1.439302\n",
            "Step 2340: G loss: 30.298599 | D loss: 1.425982\n",
            "Step 2341: G loss: 32.033142 | D loss: 1.422560\n",
            "Step 2342: G loss: 29.053844 | D loss: 1.447718\n",
            "Step 2343: G loss: 31.128071 | D loss: 1.422782\n",
            "Step 2344: G loss: 42.731640 | D loss: 1.423360\n",
            "Step 2345: G loss: 22.404171 | D loss: 1.430302\n",
            "Step 2346: G loss: 28.173155 | D loss: 1.434451\n",
            "Step 2347: G loss: 46.621407 | D loss: 1.423666\n",
            "Step 2348: G loss: 23.222553 | D loss: 1.437045\n",
            "Step 2349: G loss: 34.501778 | D loss: 1.423443\n",
            "Step 2350: G loss: 24.278116 | D loss: 1.427912\n",
            "Step 2351: G loss: 32.402973 | D loss: 1.423563\n",
            "Step 2352: G loss: 47.761349 | D loss: 1.435763\n",
            "Step 2353: G loss: 28.122892 | D loss: 1.434491\n",
            "Step 2354: G loss: 37.547352 | D loss: 1.438153\n",
            "Step 2355: G loss: 38.738319 | D loss: 1.435423\n",
            "Step 2356: G loss: 29.971325 | D loss: 1.432945\n",
            "Step 2357: G loss: 29.191219 | D loss: 1.448671\n",
            "Step 2358: G loss: 28.736158 | D loss: 1.434526\n",
            "Step 2359: G loss: 34.308468 | D loss: 1.426656\n",
            "Step 2360: G loss: 44.444481 | D loss: 1.447518\n",
            "Step 2361: G loss: 32.824749 | D loss: 1.428077\n",
            "Step 2362: G loss: 38.354424 | D loss: 1.426895\n",
            "Step 2363: G loss: 37.498932 | D loss: 1.424178\n",
            "Step 2364: G loss: 26.414110 | D loss: 1.436208\n",
            "Step 2365: G loss: 29.099190 | D loss: 1.440160\n",
            "Step 2366: G loss: 33.239864 | D loss: 1.446811\n",
            "Step 2367: G loss: 34.213547 | D loss: 1.435614\n",
            "Step 2368: G loss: 26.309732 | D loss: 1.438653\n",
            "Step 2369: G loss: 36.974140 | D loss: 1.445309\n",
            "Step 2370: G loss: 41.615582 | D loss: 1.432902\n",
            "Step 2371: G loss: 25.553057 | D loss: 1.431766\n",
            "Step 2372: G loss: 27.198769 | D loss: 1.430387\n",
            "Step 2373: G loss: 23.029285 | D loss: 1.430852\n",
            "Step 2374: G loss: 26.219559 | D loss: 1.423817\n",
            "Step 2375: G loss: 23.722656 | D loss: 1.423349\n",
            "Step 2376: G loss: 31.678440 | D loss: 1.432865\n",
            "Step 2377: G loss: 54.230217 | D loss: 1.434829\n",
            "Step 2378: G loss: 32.887470 | D loss: 1.432574\n",
            "Step 2379: G loss: 29.463718 | D loss: 1.443544\n",
            "Step 2380: G loss: 30.635923 | D loss: 1.451676\n",
            "Step 2381: G loss: 31.503153 | D loss: 1.439114\n",
            "Step 2382: G loss: 38.493477 | D loss: 1.430915\n",
            "Step 2383: G loss: 24.412203 | D loss: 1.435719\n",
            "Step 2384: G loss: 24.101322 | D loss: 1.462023\n",
            "Step 2385: G loss: 48.454487 | D loss: 1.433557\n",
            "Step 2386: G loss: 24.826834 | D loss: 1.455493\n",
            "Step 2387: G loss: 30.303585 | D loss: 1.435540\n",
            "Step 2388: G loss: 30.157265 | D loss: 1.440710\n",
            "Step 2389: G loss: 23.742411 | D loss: 1.422685\n",
            "Step 2390: G loss: 23.378799 | D loss: 1.432572\n",
            "Step 2391: G loss: 30.473589 | D loss: 1.450546\n",
            "Step 2392: G loss: 29.854202 | D loss: 1.442789\n",
            "Step 2393: G loss: 39.318508 | D loss: 1.439667\n",
            "Step 2394: G loss: 34.840691 | D loss: 1.430872\n",
            "Step 2395: G loss: 38.909401 | D loss: 1.426469\n",
            "Step 2396: G loss: 24.730064 | D loss: 1.423500\n",
            "Step 2397: G loss: 33.008705 | D loss: 1.426693\n",
            "Step 2398: G loss: 27.381969 | D loss: 1.438375\n",
            "Step 2399: G loss: 36.077919 | D loss: 1.446033\n",
            "Step 2400: G loss: 40.201252 | D loss: 1.422227\n",
            "Step 2401: G loss: 35.878437 | D loss: 1.434030\n",
            "Step 2402: G loss: 25.978960 | D loss: 1.436573\n",
            "Step 2403: G loss: 22.816547 | D loss: 1.431142\n",
            "Step 2404: G loss: 33.745209 | D loss: 1.422866\n",
            "Step 2405: G loss: 28.573494 | D loss: 1.449482\n",
            "Step 2406: G loss: 25.325893 | D loss: 1.427166\n",
            "Step 2407: G loss: 32.717888 | D loss: 1.452840\n",
            "Step 2408: G loss: 34.240433 | D loss: 1.456447\n",
            "Step 2409: G loss: 33.440948 | D loss: 1.450719\n",
            "Step 2410: G loss: 38.152752 | D loss: 1.422405\n",
            "Step 2411: G loss: 37.078403 | D loss: 1.437295\n",
            "Step 2412: G loss: 19.992859 | D loss: 1.427104\n",
            "Step 2413: G loss: 39.962391 | D loss: 1.441413\n",
            "Step 2414: G loss: 41.801888 | D loss: 1.435615\n",
            "Step 2415: G loss: 31.340073 | D loss: 1.444774\n",
            "Step 2416: G loss: 28.449064 | D loss: 1.433237\n",
            "Step 2417: G loss: 39.750038 | D loss: 1.449983\n",
            "Step 2418: G loss: 26.416584 | D loss: 1.435064\n",
            "Step 2419: G loss: 27.656975 | D loss: 1.424605\n",
            "Step 2420: G loss: 23.245539 | D loss: 1.444427\n",
            "Step 2421: G loss: 22.435085 | D loss: 1.432838\n",
            "Step 2422: G loss: 24.945452 | D loss: 1.424059\n",
            "Step 2423: G loss: 32.492607 | D loss: 1.421906\n",
            "Step 2424: G loss: 29.709011 | D loss: 1.429100\n",
            "Step 2425: G loss: 29.884438 | D loss: 1.426810\n",
            "Step 2426: G loss: 40.830425 | D loss: 1.426021\n",
            "Step 2427: G loss: 26.789402 | D loss: 1.422395\n",
            "Step 2428: G loss: 38.826160 | D loss: 1.429997\n",
            "Step 2429: G loss: 31.262888 | D loss: 1.441075\n",
            "Step 2430: G loss: 41.688480 | D loss: 1.437106\n",
            "Step 2431: G loss: 36.213181 | D loss: 1.438992\n",
            "Step 2432: G loss: 42.178410 | D loss: 1.432841\n",
            "Step 2433: G loss: 30.013454 | D loss: 1.428803\n",
            "Step 2434: G loss: 30.241915 | D loss: 1.448552\n",
            "Step 2435: G loss: 39.295834 | D loss: 1.449332\n",
            "Step 2436: G loss: 33.995308 | D loss: 1.430820\n",
            "Step 2437: G loss: 40.937504 | D loss: 1.444563\n",
            "Step 2438: G loss: 26.382057 | D loss: 1.450534\n",
            "Step 2439: G loss: 41.895123 | D loss: 1.447189\n",
            "Step 2440: G loss: 18.539003 | D loss: 1.448319\n",
            "Step 2441: G loss: 22.955814 | D loss: 1.427702\n",
            "Step 2442: G loss: 39.965473 | D loss: 1.437531\n",
            "Step 2443: G loss: 35.713997 | D loss: 1.429200\n",
            "Step 2444: G loss: 39.753647 | D loss: 1.446065\n",
            "Step 2445: G loss: 33.232040 | D loss: 1.429556\n",
            "Step 2446: G loss: 21.683451 | D loss: 1.422578\n",
            "Step 2447: G loss: 35.789707 | D loss: 1.421401\n",
            "Step 2448: G loss: 37.623386 | D loss: 1.448885\n",
            "Step 2449: G loss: 36.622620 | D loss: 1.439469\n",
            "Step 2450: G loss: 28.652594 | D loss: 1.445813\n",
            "Step 2451: G loss: 27.789310 | D loss: 1.421570\n",
            "Step 2452: G loss: 26.082373 | D loss: 1.444049\n",
            "Step 2453: G loss: 27.690323 | D loss: 1.441072\n",
            "Step 2454: G loss: 31.800077 | D loss: 1.442635\n",
            "Step 2455: G loss: 24.026644 | D loss: 1.422704\n",
            "Step 2456: G loss: 44.387600 | D loss: 1.435396\n",
            "Step 2457: G loss: 30.829575 | D loss: 1.445907\n",
            "Step 2458: G loss: 40.991722 | D loss: 1.443214\n",
            "Step 2459: G loss: 25.510958 | D loss: 1.448553\n",
            "Step 2460: G loss: 29.496447 | D loss: 1.421521\n",
            "Step 2461: G loss: 38.667500 | D loss: 1.449062\n",
            "Step 2462: G loss: 41.527626 | D loss: 1.440775\n",
            "Step 2463: G loss: 35.272758 | D loss: 1.445760\n",
            "Step 2464: G loss: 24.398544 | D loss: 1.421585\n",
            "Step 2465: G loss: 19.827291 | D loss: 1.424201\n",
            "Step 2466: G loss: 37.222141 | D loss: 1.421596\n",
            "Step 2467: G loss: 34.456272 | D loss: 1.441103\n",
            "Step 2468: G loss: 44.441463 | D loss: 1.421317\n",
            "Step 2469: G loss: 39.113117 | D loss: 1.422882\n",
            "Step 2470: G loss: 42.428493 | D loss: 1.436963\n",
            "Step 2471: G loss: 30.658669 | D loss: 1.422326\n",
            "Step 2472: G loss: 37.653080 | D loss: 1.426876\n",
            "Step 2473: G loss: 32.273094 | D loss: 1.429467\n",
            "Step 2474: G loss: 24.880461 | D loss: 1.430846\n",
            "Step 2475: G loss: 45.217663 | D loss: 1.438141\n",
            "Step 2476: G loss: 41.815697 | D loss: 1.446743\n",
            "Step 2477: G loss: 31.162939 | D loss: 1.421522\n",
            "Step 2478: G loss: 22.483345 | D loss: 1.431851\n",
            "Step 2479: G loss: 21.748335 | D loss: 1.438797\n",
            "Step 2480: G loss: 39.127136 | D loss: 1.431188\n",
            "Step 2481: G loss: 34.112110 | D loss: 1.444972\n",
            "Step 2482: G loss: 49.548573 | D loss: 1.431679\n",
            "Step 2483: G loss: 23.714468 | D loss: 1.435712\n",
            "Step 2484: G loss: 26.844944 | D loss: 1.423606\n",
            "Step 2485: G loss: 30.042923 | D loss: 1.439228\n",
            "Step 2486: G loss: 26.270811 | D loss: 1.430639\n",
            "Step 2487: G loss: 29.266724 | D loss: 1.437637\n",
            "Step 2488: G loss: 36.062237 | D loss: 1.431681\n",
            "Step 2489: G loss: 28.222900 | D loss: 1.436007\n",
            "Step 2490: G loss: 27.452419 | D loss: 1.426906\n",
            "Step 2491: G loss: 29.150089 | D loss: 1.426341\n",
            "Step 2492: G loss: 16.478518 | D loss: 1.429810\n",
            "Step 2493: G loss: 25.981888 | D loss: 1.441376\n",
            "Step 2494: G loss: 37.806709 | D loss: 1.451343\n",
            "Step 2495: G loss: 27.835203 | D loss: 1.425649\n",
            "Step 2496: G loss: 29.388212 | D loss: 1.427036\n",
            "Step 2497: G loss: 46.209919 | D loss: 1.431963\n",
            "Step 2498: G loss: 32.299801 | D loss: 1.424761\n",
            "Step 2499: G loss: 23.780682 | D loss: 1.437230\n",
            "Step 2500: G loss: 29.139875 | D loss: 1.462549\n",
            "Step 2501: G loss: 29.214699 | D loss: 1.432681\n",
            "Step 2502: G loss: 27.092096 | D loss: 1.423923\n",
            "Step 2503: G loss: 29.979063 | D loss: 1.431462\n",
            "Step 2504: G loss: 25.697588 | D loss: 1.432743\n",
            "Step 2505: G loss: 23.668629 | D loss: 1.424876\n",
            "Step 2506: G loss: 29.411011 | D loss: 1.447362\n",
            "Step 2507: G loss: 30.614246 | D loss: 1.438749\n",
            "Step 2508: G loss: 21.537813 | D loss: 1.441361\n",
            "Step 2509: G loss: 23.577145 | D loss: 1.440630\n",
            "Step 2510: G loss: 41.804821 | D loss: 1.452992\n",
            "Step 2511: G loss: 25.981575 | D loss: 1.424357\n",
            "Step 2512: G loss: 28.086851 | D loss: 1.451396\n",
            "Step 2513: G loss: 27.050997 | D loss: 1.425387\n",
            "Step 2514: G loss: 37.291027 | D loss: 1.438405\n",
            "Step 2515: G loss: 29.244164 | D loss: 1.433826\n",
            "Step 2516: G loss: 33.701153 | D loss: 1.430495\n",
            "Step 2517: G loss: 26.502558 | D loss: 1.441861\n",
            "Step 2518: G loss: 21.821079 | D loss: 1.431972\n",
            "Step 2519: G loss: 29.278728 | D loss: 1.441940\n",
            "Step 2520: G loss: 30.812469 | D loss: 1.427734\n",
            "Step 2521: G loss: 45.319443 | D loss: 1.420638\n",
            "Step 2522: G loss: 22.749390 | D loss: 1.424564\n",
            "Step 2523: G loss: 27.240763 | D loss: 1.430672\n",
            "Step 2524: G loss: 46.760319 | D loss: 1.431314\n",
            "Step 2525: G loss: 26.172613 | D loss: 1.434675\n",
            "Step 2526: G loss: 34.000015 | D loss: 1.420765\n",
            "Step 2527: G loss: 38.750870 | D loss: 1.421218\n",
            "Step 2528: G loss: 27.407349 | D loss: 1.422171\n",
            "Step 2529: G loss: 37.530151 | D loss: 1.435315\n",
            "Step 2530: G loss: 31.358839 | D loss: 1.431502\n",
            "Step 2531: G loss: 27.306549 | D loss: 1.424686\n",
            "Step 2532: G loss: 24.995987 | D loss: 1.441251\n",
            "Step 2533: G loss: 35.153397 | D loss: 1.436063\n",
            "Step 2534: G loss: 31.608006 | D loss: 1.432180\n",
            "Step 2535: G loss: 31.897038 | D loss: 1.428262\n",
            "Step 2536: G loss: 47.238239 | D loss: 1.430329\n",
            "Step 2537: G loss: 25.327532 | D loss: 1.431742\n",
            "Step 2538: G loss: 25.580273 | D loss: 1.422287\n",
            "Step 2539: G loss: 46.028488 | D loss: 1.430797\n",
            "Step 2540: G loss: 30.483433 | D loss: 1.432902\n",
            "Step 2541: G loss: 38.096970 | D loss: 1.427908\n",
            "Step 2542: G loss: 26.543842 | D loss: 1.421281\n",
            "Step 2543: G loss: 31.283825 | D loss: 1.442630\n",
            "Step 2544: G loss: 29.359255 | D loss: 1.433007\n",
            "Step 2545: G loss: 27.068089 | D loss: 1.433263\n",
            "Step 2546: G loss: 19.148748 | D loss: 1.432062\n",
            "Step 2547: G loss: 37.290154 | D loss: 1.425738\n",
            "Step 2548: G loss: 38.523216 | D loss: 1.431166\n",
            "Step 2549: G loss: 22.183111 | D loss: 1.429957\n",
            "Step 2550: G loss: 35.948807 | D loss: 1.427913\n",
            "Step 2551: G loss: 28.374647 | D loss: 1.432577\n",
            "Step 2552: G loss: 34.734440 | D loss: 1.448972\n",
            "Step 2553: G loss: 26.545626 | D loss: 1.421696\n",
            "Step 2554: G loss: 24.788626 | D loss: 1.440798\n",
            "Step 2555: G loss: 31.594450 | D loss: 1.436908\n",
            "Step 2556: G loss: 29.459095 | D loss: 1.435250\n",
            "Step 2557: G loss: 26.498554 | D loss: 1.449817\n",
            "Step 2558: G loss: 38.943790 | D loss: 1.432410\n",
            "Step 2559: G loss: 34.000580 | D loss: 1.438202\n",
            "Step 2560: G loss: 32.919643 | D loss: 1.423425\n",
            "Step 2561: G loss: 29.920630 | D loss: 1.420989\n",
            "Step 2562: G loss: 20.612715 | D loss: 1.426835\n",
            "Step 2563: G loss: 20.793093 | D loss: 1.424072\n",
            "Step 2564: G loss: 24.408661 | D loss: 1.443559\n",
            "Step 2565: G loss: 41.882656 | D loss: 1.421599\n",
            "Step 2566: G loss: 35.980984 | D loss: 1.422140\n",
            "Step 2567: G loss: 36.049034 | D loss: 1.422373\n",
            "Step 2568: G loss: 30.738558 | D loss: 1.436840\n",
            "Step 2569: G loss: 38.904816 | D loss: 1.433446\n",
            "Step 2570: G loss: 44.957390 | D loss: 1.433886\n",
            "Step 2571: G loss: 37.643707 | D loss: 1.442769\n",
            "Step 2572: G loss: 30.754028 | D loss: 1.421551\n",
            "Step 2573: G loss: 30.534014 | D loss: 1.434398\n",
            "Step 2574: G loss: 27.788921 | D loss: 1.432951\n",
            "Step 2575: G loss: 42.837185 | D loss: 1.423155\n",
            "Step 2576: G loss: 44.340385 | D loss: 1.425251\n",
            "Step 2577: G loss: 31.144827 | D loss: 1.427082\n",
            "Step 2578: G loss: 30.255238 | D loss: 1.430723\n",
            "Step 2579: G loss: 34.262154 | D loss: 1.449525\n",
            "Step 2580: G loss: 38.166660 | D loss: 1.439447\n",
            "Step 2581: G loss: 24.609505 | D loss: 1.438598\n",
            "Step 2582: G loss: 33.929714 | D loss: 1.430227\n",
            "Step 2583: G loss: 38.959991 | D loss: 1.425600\n",
            "Step 2584: G loss: 20.307148 | D loss: 1.436598\n",
            "Step 2585: G loss: 34.783493 | D loss: 1.435138\n",
            "Step 2586: G loss: 24.609165 | D loss: 1.444128\n",
            "Step 2587: G loss: 34.791809 | D loss: 1.434115\n",
            "Step 2588: G loss: 27.410496 | D loss: 1.432678\n",
            "Step 2589: G loss: 26.288174 | D loss: 1.450689\n",
            "Step 2590: G loss: 25.163641 | D loss: 1.426319\n",
            "Step 2591: G loss: 27.025459 | D loss: 1.442548\n",
            "Step 2592: G loss: 28.956247 | D loss: 1.435276\n",
            "Step 2593: G loss: 23.547174 | D loss: 1.437230\n",
            "Step 2594: G loss: 30.979937 | D loss: 1.436283\n",
            "Step 2595: G loss: 38.556633 | D loss: 1.421822\n",
            "Step 2596: G loss: 18.655935 | D loss: 1.431165\n",
            "Step 2597: G loss: 37.433205 | D loss: 1.432501\n",
            "Step 2598: G loss: 39.373409 | D loss: 1.425562\n",
            "Step 2599: G loss: 28.892899 | D loss: 1.420144\n",
            "Step 2600: G loss: 26.008368 | D loss: 1.430223\n",
            "Step 2601: G loss: 29.116402 | D loss: 1.421474\n",
            "Step 2602: G loss: 26.605440 | D loss: 1.424979\n",
            "Step 2603: G loss: 32.803993 | D loss: 1.429904\n",
            "Step 2604: G loss: 32.984997 | D loss: 1.422345\n",
            "Step 2605: G loss: 28.821976 | D loss: 1.436830\n",
            "Step 2606: G loss: 23.721798 | D loss: 1.453833\n",
            "Step 2607: G loss: 26.610123 | D loss: 1.420634\n",
            "Step 2608: G loss: 38.900558 | D loss: 1.424291\n",
            "Step 2609: G loss: 23.697853 | D loss: 1.420081\n",
            "Step 2610: G loss: 40.942841 | D loss: 1.423360\n",
            "Step 2611: G loss: 24.157888 | D loss: 1.420345\n",
            "Step 2612: G loss: 31.698944 | D loss: 1.421377\n",
            "Step 2613: G loss: 20.186083 | D loss: 1.444983\n",
            "Step 2614: G loss: 27.937607 | D loss: 1.421214\n",
            "Step 2615: G loss: 27.086433 | D loss: 1.431515\n",
            "Step 2616: G loss: 26.819647 | D loss: 1.431891\n",
            "Step 2617: G loss: 31.463013 | D loss: 1.428638\n",
            "Step 2618: G loss: 30.992371 | D loss: 1.432181\n",
            "Step 2619: G loss: 28.435566 | D loss: 1.421651\n",
            "Step 2620: G loss: 25.315639 | D loss: 1.423944\n",
            "Step 2621: G loss: 31.212620 | D loss: 1.447375\n",
            "Step 2622: G loss: 37.626987 | D loss: 1.448054\n",
            "Step 2623: G loss: 24.935862 | D loss: 1.432150\n",
            "Step 2624: G loss: 40.055668 | D loss: 1.422252\n",
            "Step 2625: G loss: 32.739277 | D loss: 1.430794\n",
            "Step 2626: G loss: 36.333637 | D loss: 1.426909\n",
            "Step 2627: G loss: 28.455811 | D loss: 1.431866\n",
            "Step 2628: G loss: 38.037182 | D loss: 1.438629\n",
            "Step 2629: G loss: 45.290356 | D loss: 1.427477\n",
            "Step 2630: G loss: 29.131384 | D loss: 1.440076\n",
            "Step 2631: G loss: 34.254688 | D loss: 1.429559\n",
            "Step 2632: G loss: 38.769157 | D loss: 1.430150\n",
            "Step 2633: G loss: 26.500830 | D loss: 1.430527\n",
            "Step 2634: G loss: 32.964970 | D loss: 1.428584\n",
            "Step 2635: G loss: 28.241421 | D loss: 1.419811\n",
            "Step 2636: G loss: 31.859035 | D loss: 1.432106\n",
            "Step 2637: G loss: 28.123472 | D loss: 1.440211\n",
            "Step 2638: G loss: 33.128948 | D loss: 1.434217\n",
            "Step 2639: G loss: 37.783237 | D loss: 1.434831\n",
            "Step 2640: G loss: 26.851656 | D loss: 1.436406\n",
            "Step 2641: G loss: 49.806595 | D loss: 1.427060\n",
            "Step 2642: G loss: 28.774212 | D loss: 1.441714\n",
            "Step 2643: G loss: 23.657022 | D loss: 1.434166\n",
            "Step 2644: G loss: 32.208015 | D loss: 1.422230\n",
            "Step 2645: G loss: 24.788528 | D loss: 1.426205\n",
            "Step 2646: G loss: 27.914408 | D loss: 1.423475\n",
            "Step 2647: G loss: 26.007936 | D loss: 1.420327\n",
            "Step 2648: G loss: 33.679482 | D loss: 1.421512\n",
            "Step 2649: G loss: 26.714855 | D loss: 1.440736\n",
            "Step 2650: G loss: 27.547291 | D loss: 1.420122\n",
            "Step 2651: G loss: 18.783432 | D loss: 1.420692\n",
            "Step 2652: G loss: 33.102959 | D loss: 1.428246\n",
            "Step 2653: G loss: 32.692036 | D loss: 1.432354\n",
            "Step 2654: G loss: 30.097086 | D loss: 1.427560\n",
            "Step 2655: G loss: 29.113871 | D loss: 1.432038\n",
            "Step 2656: G loss: 24.026636 | D loss: 1.426413\n",
            "Step 2657: G loss: 23.173399 | D loss: 1.419938\n",
            "Step 2658: G loss: 22.696699 | D loss: 1.432351\n",
            "Step 2659: G loss: 26.863150 | D loss: 1.435552\n",
            "Step 2660: G loss: 37.535507 | D loss: 1.422717\n",
            "Step 2661: G loss: 26.552505 | D loss: 1.432093\n",
            "Step 2662: G loss: 38.048534 | D loss: 1.421922\n",
            "Step 2663: G loss: 33.198120 | D loss: 1.427412\n",
            "Step 2664: G loss: 33.197716 | D loss: 1.419433\n",
            "Step 2665: G loss: 29.589092 | D loss: 1.422009\n",
            "Step 2666: G loss: 27.864208 | D loss: 1.430734\n",
            "Step 2667: G loss: 30.908169 | D loss: 1.442685\n",
            "Step 2668: G loss: 26.821663 | D loss: 1.444332\n",
            "Step 2669: G loss: 22.260433 | D loss: 1.445112\n",
            "Step 2670: G loss: 20.428438 | D loss: 1.426680\n",
            "Step 2671: G loss: 43.833340 | D loss: 1.436295\n",
            "Step 2672: G loss: 34.238556 | D loss: 1.430803\n",
            "Step 2673: G loss: 21.217464 | D loss: 1.430290\n",
            "Step 2674: G loss: 19.673532 | D loss: 1.434848\n",
            "Step 2675: G loss: 36.878597 | D loss: 1.419767\n",
            "Step 2676: G loss: 25.301243 | D loss: 1.420056\n",
            "Step 2677: G loss: 39.128525 | D loss: 1.421618\n",
            "Step 2678: G loss: 26.371902 | D loss: 1.419458\n",
            "Step 2679: G loss: 27.250566 | D loss: 1.458306\n",
            "Step 2680: G loss: 24.291874 | D loss: 1.429179\n",
            "Step 2681: G loss: 41.513680 | D loss: 1.419636\n",
            "Step 2682: G loss: 32.417694 | D loss: 1.429132\n",
            "Step 2683: G loss: 45.074505 | D loss: 1.429259\n",
            "Step 2684: G loss: 30.243181 | D loss: 1.438775\n",
            "Step 2685: G loss: 31.918577 | D loss: 1.436723\n",
            "Step 2686: G loss: 29.759956 | D loss: 1.419966\n",
            "Step 2687: G loss: 34.436916 | D loss: 1.445717\n",
            "Step 2688: G loss: 38.533863 | D loss: 1.427795\n",
            "Step 2689: G loss: 24.298479 | D loss: 1.435509\n",
            "Step 2690: G loss: 30.049633 | D loss: 1.426268\n",
            "Step 2691: G loss: 27.802595 | D loss: 1.419624\n",
            "Step 2692: G loss: 24.666916 | D loss: 1.429412\n",
            "Step 2693: G loss: 35.822582 | D loss: 1.419194\n",
            "Step 2694: G loss: 25.191898 | D loss: 1.429121\n",
            "Step 2695: G loss: 32.045742 | D loss: 1.420578\n",
            "Step 2696: G loss: 25.110212 | D loss: 1.420401\n",
            "Step 2697: G loss: 30.892757 | D loss: 1.431533\n",
            "Step 2698: G loss: 27.487385 | D loss: 1.419222\n",
            "Step 2699: G loss: 25.984205 | D loss: 1.423302\n",
            "Step 2700: G loss: 31.215431 | D loss: 1.433465\n",
            "Step 2701: G loss: 24.671902 | D loss: 1.432186\n",
            "Step 2702: G loss: 25.910019 | D loss: 1.435790\n",
            "Step 2703: G loss: 40.738274 | D loss: 1.435888\n",
            "Step 2704: G loss: 33.037231 | D loss: 1.434713\n",
            "Step 2705: G loss: 29.838940 | D loss: 1.436647\n",
            "Step 2706: G loss: 41.348099 | D loss: 1.419539\n",
            "Step 2707: G loss: 27.358557 | D loss: 1.419938\n",
            "Step 2708: G loss: 38.292732 | D loss: 1.434358\n",
            "Step 2709: G loss: 32.236008 | D loss: 1.440021\n",
            "Step 2710: G loss: 20.680592 | D loss: 1.419315\n",
            "Step 2711: G loss: 23.465919 | D loss: 1.431913\n",
            "Step 2712: G loss: 25.538570 | D loss: 1.419021\n",
            "Step 2713: G loss: 29.723860 | D loss: 1.419648\n",
            "Step 2714: G loss: 25.131607 | D loss: 1.429492\n",
            "Step 2715: G loss: 33.393688 | D loss: 1.418970\n",
            "Step 2716: G loss: 38.951294 | D loss: 1.421549\n",
            "Step 2717: G loss: 31.995445 | D loss: 1.430651\n",
            "Step 2718: G loss: 29.626060 | D loss: 1.423480\n",
            "Step 2719: G loss: 32.079037 | D loss: 1.418936\n",
            "Step 2720: G loss: 28.472456 | D loss: 1.435224\n",
            "Step 2721: G loss: 30.521841 | D loss: 1.419398\n",
            "Step 2722: G loss: 39.566505 | D loss: 1.419750\n",
            "Step 2723: G loss: 22.557892 | D loss: 1.426576\n",
            "Step 2724: G loss: 27.757936 | D loss: 1.429526\n",
            "Step 2725: G loss: 46.669331 | D loss: 1.420153\n",
            "Step 2726: G loss: 23.516109 | D loss: 1.424891\n",
            "Step 2727: G loss: 33.474052 | D loss: 1.419227\n",
            "Step 2728: G loss: 25.082703 | D loss: 1.424218\n",
            "Step 2729: G loss: 32.489601 | D loss: 1.420678\n",
            "Step 2730: G loss: 45.071083 | D loss: 1.426804\n",
            "Step 2731: G loss: 27.647251 | D loss: 1.428904\n",
            "Step 2732: G loss: 37.238785 | D loss: 1.432535\n",
            "Step 2733: G loss: 38.473389 | D loss: 1.433858\n",
            "Step 2734: G loss: 28.215117 | D loss: 1.423722\n",
            "Step 2735: G loss: 30.057215 | D loss: 1.436093\n",
            "Step 2736: G loss: 28.733994 | D loss: 1.426899\n",
            "Step 2737: G loss: 34.714703 | D loss: 1.419851\n",
            "Step 2738: G loss: 44.847012 | D loss: 1.429583\n",
            "Step 2739: G loss: 31.937870 | D loss: 1.422744\n",
            "Step 2740: G loss: 37.876953 | D loss: 1.419682\n",
            "Step 2741: G loss: 38.081326 | D loss: 1.420911\n",
            "Step 2742: G loss: 25.605055 | D loss: 1.429763\n",
            "Step 2743: G loss: 29.127342 | D loss: 1.432589\n",
            "Step 2744: G loss: 34.603561 | D loss: 1.435735\n",
            "Step 2745: G loss: 33.791931 | D loss: 1.427068\n",
            "Step 2746: G loss: 25.443695 | D loss: 1.430078\n",
            "Step 2747: G loss: 37.027542 | D loss: 1.431391\n",
            "Step 2748: G loss: 42.218060 | D loss: 1.426869\n",
            "Step 2749: G loss: 25.664461 | D loss: 1.428912\n",
            "Step 2750: G loss: 28.543610 | D loss: 1.430810\n",
            "Step 2751: G loss: 23.888823 | D loss: 1.425853\n",
            "Step 2752: G loss: 25.495638 | D loss: 1.418883\n",
            "Step 2753: G loss: 24.127213 | D loss: 1.420540\n",
            "Step 2754: G loss: 31.189302 | D loss: 1.427640\n",
            "Step 2755: G loss: 52.134644 | D loss: 1.425114\n",
            "Step 2756: G loss: 31.875927 | D loss: 1.425994\n",
            "Step 2757: G loss: 29.040281 | D loss: 1.431137\n",
            "Step 2758: G loss: 29.677444 | D loss: 1.454276\n",
            "Step 2759: G loss: 30.938324 | D loss: 1.429973\n",
            "Step 2760: G loss: 37.439651 | D loss: 1.422757\n",
            "Step 2761: G loss: 24.625692 | D loss: 1.427672\n",
            "Step 2762: G loss: 23.470728 | D loss: 1.449975\n",
            "Step 2763: G loss: 46.898468 | D loss: 1.420845\n",
            "Step 2764: G loss: 24.450447 | D loss: 1.437481\n",
            "Step 2765: G loss: 30.688723 | D loss: 1.425960\n",
            "Step 2766: G loss: 29.764927 | D loss: 1.435409\n",
            "Step 2767: G loss: 22.652662 | D loss: 1.418645\n",
            "Step 2768: G loss: 22.671343 | D loss: 1.427078\n",
            "Step 2769: G loss: 29.504204 | D loss: 1.440828\n",
            "Step 2770: G loss: 29.338818 | D loss: 1.432755\n",
            "Step 2771: G loss: 39.996899 | D loss: 1.434336\n",
            "Step 2772: G loss: 33.544815 | D loss: 1.422078\n",
            "Step 2773: G loss: 38.712364 | D loss: 1.420878\n",
            "Step 2774: G loss: 26.484947 | D loss: 1.419707\n",
            "Step 2775: G loss: 32.118607 | D loss: 1.419940\n",
            "Step 2776: G loss: 26.815668 | D loss: 1.433072\n",
            "Step 2777: G loss: 36.245285 | D loss: 1.436963\n",
            "Step 2778: G loss: 40.037983 | D loss: 1.418777\n",
            "Step 2779: G loss: 36.269268 | D loss: 1.428138\n",
            "Step 2780: G loss: 25.972233 | D loss: 1.426580\n",
            "Step 2781: G loss: 22.021589 | D loss: 1.428148\n",
            "Step 2782: G loss: 32.878639 | D loss: 1.418776\n",
            "Step 2783: G loss: 27.742121 | D loss: 1.434187\n",
            "Step 2784: G loss: 25.897408 | D loss: 1.422633\n",
            "Step 2785: G loss: 31.659229 | D loss: 1.440738\n",
            "Step 2786: G loss: 33.747452 | D loss: 1.449219\n",
            "Step 2787: G loss: 33.554176 | D loss: 1.455571\n",
            "Step 2788: G loss: 38.802292 | D loss: 1.419254\n",
            "Step 2789: G loss: 37.361610 | D loss: 1.433131\n",
            "Step 2790: G loss: 20.204357 | D loss: 1.431058\n",
            "Step 2791: G loss: 39.657852 | D loss: 1.422831\n",
            "Step 2792: G loss: 41.973274 | D loss: 1.432883\n",
            "Step 2793: G loss: 30.507641 | D loss: 1.432334\n",
            "Step 2794: G loss: 27.983145 | D loss: 1.425095\n",
            "Step 2795: G loss: 38.073883 | D loss: 1.445015\n",
            "Step 2796: G loss: 26.018888 | D loss: 1.420447\n",
            "Step 2797: G loss: 26.524681 | D loss: 1.420200\n",
            "Step 2798: G loss: 22.848743 | D loss: 1.426144\n",
            "Step 2799: G loss: 21.397676 | D loss: 1.419551\n",
            "Step 2800: G loss: 25.426022 | D loss: 1.418552\n",
            "Step 2801: G loss: 32.681385 | D loss: 1.418165\n",
            "Step 2802: G loss: 29.146482 | D loss: 1.425520\n",
            "Step 2803: G loss: 29.644188 | D loss: 1.418352\n",
            "Step 2804: G loss: 40.100178 | D loss: 1.422596\n",
            "Step 2805: G loss: 27.163071 | D loss: 1.418246\n",
            "Step 2806: G loss: 38.443096 | D loss: 1.424534\n",
            "Step 2807: G loss: 30.622232 | D loss: 1.430060\n",
            "Step 2808: G loss: 40.425270 | D loss: 1.442003\n",
            "Step 2809: G loss: 36.653091 | D loss: 1.441610\n",
            "Step 2810: G loss: 42.647133 | D loss: 1.431993\n",
            "Step 2811: G loss: 29.357998 | D loss: 1.430098\n",
            "Step 2812: G loss: 29.596605 | D loss: 1.444068\n",
            "Step 2813: G loss: 39.777908 | D loss: 1.430556\n",
            "Step 2814: G loss: 32.276421 | D loss: 1.426419\n",
            "Step 2815: G loss: 40.860794 | D loss: 1.437485\n",
            "Step 2816: G loss: 26.424791 | D loss: 1.440399\n",
            "Step 2817: G loss: 40.874882 | D loss: 1.429061\n",
            "Step 2818: G loss: 18.732691 | D loss: 1.431647\n",
            "Step 2819: G loss: 22.149414 | D loss: 1.419039\n",
            "Step 2820: G loss: 38.432281 | D loss: 1.429597\n",
            "Step 2821: G loss: 34.737587 | D loss: 1.433897\n",
            "Step 2822: G loss: 38.558197 | D loss: 1.428468\n",
            "Step 2823: G loss: 32.708130 | D loss: 1.430254\n",
            "Step 2824: G loss: 22.582336 | D loss: 1.437318\n",
            "Step 2825: G loss: 35.268700 | D loss: 1.418501\n",
            "Step 2826: G loss: 36.511974 | D loss: 1.425661\n",
            "Step 2827: G loss: 36.391857 | D loss: 1.428434\n",
            "Step 2828: G loss: 28.918037 | D loss: 1.430409\n",
            "Step 2829: G loss: 27.279840 | D loss: 1.429001\n",
            "Step 2830: G loss: 25.253313 | D loss: 1.434821\n",
            "Step 2831: G loss: 26.915154 | D loss: 1.421595\n",
            "Step 2832: G loss: 30.005268 | D loss: 1.439010\n",
            "Step 2833: G loss: 23.333176 | D loss: 1.418146\n",
            "Step 2834: G loss: 45.484447 | D loss: 1.429218\n",
            "Step 2835: G loss: 30.928633 | D loss: 1.432945\n",
            "Step 2836: G loss: 39.130207 | D loss: 1.433253\n",
            "Step 2837: G loss: 25.158556 | D loss: 1.435272\n",
            "Step 2838: G loss: 29.650713 | D loss: 1.418663\n",
            "Step 2839: G loss: 38.331741 | D loss: 1.442779\n",
            "Step 2840: G loss: 41.522217 | D loss: 1.438168\n",
            "Step 2841: G loss: 35.466602 | D loss: 1.430339\n",
            "Step 2842: G loss: 23.752903 | D loss: 1.429716\n",
            "Step 2843: G loss: 19.827997 | D loss: 1.420010\n",
            "Step 2844: G loss: 36.543869 | D loss: 1.423909\n",
            "Step 2845: G loss: 34.326366 | D loss: 1.435328\n",
            "Step 2846: G loss: 44.062820 | D loss: 1.417663\n",
            "Step 2847: G loss: 38.658348 | D loss: 1.424842\n",
            "Step 2848: G loss: 40.046921 | D loss: 1.419420\n",
            "Step 2849: G loss: 29.568649 | D loss: 1.420589\n",
            "Step 2850: G loss: 35.567970 | D loss: 1.418653\n",
            "Step 2851: G loss: 32.615238 | D loss: 1.422493\n",
            "Step 2852: G loss: 24.419626 | D loss: 1.422954\n",
            "Step 2853: G loss: 45.156502 | D loss: 1.433694\n",
            "Step 2854: G loss: 41.181900 | D loss: 1.426263\n",
            "Step 2855: G loss: 31.211506 | D loss: 1.417759\n",
            "Step 2856: G loss: 23.089973 | D loss: 1.423304\n",
            "Step 2857: G loss: 21.423994 | D loss: 1.424898\n",
            "Step 2858: G loss: 38.352093 | D loss: 1.428738\n",
            "Step 2859: G loss: 33.550865 | D loss: 1.432303\n",
            "Step 2860: G loss: 50.357750 | D loss: 1.425370\n",
            "Step 2861: G loss: 23.365953 | D loss: 1.434191\n",
            "Step 2862: G loss: 26.945276 | D loss: 1.418517\n",
            "Step 2863: G loss: 29.975523 | D loss: 1.442607\n",
            "Step 2864: G loss: 26.035898 | D loss: 1.424312\n",
            "Step 2865: G loss: 28.684277 | D loss: 1.427659\n",
            "Step 2866: G loss: 35.410618 | D loss: 1.420930\n",
            "Step 2867: G loss: 27.728247 | D loss: 1.427868\n",
            "Step 2868: G loss: 26.966801 | D loss: 1.427542\n",
            "Step 2869: G loss: 29.274782 | D loss: 1.423704\n",
            "Step 2870: G loss: 16.511168 | D loss: 1.419782\n",
            "Step 2871: G loss: 25.060175 | D loss: 1.432075\n",
            "Step 2872: G loss: 37.054363 | D loss: 1.430305\n",
            "Step 2873: G loss: 27.310341 | D loss: 1.422150\n",
            "Step 2874: G loss: 29.023197 | D loss: 1.426230\n",
            "Step 2875: G loss: 45.630169 | D loss: 1.423176\n",
            "Step 2876: G loss: 31.703915 | D loss: 1.420659\n",
            "Step 2877: G loss: 23.234430 | D loss: 1.424056\n",
            "Step 2878: G loss: 27.881014 | D loss: 1.440079\n",
            "Step 2879: G loss: 29.735352 | D loss: 1.425264\n",
            "Step 2880: G loss: 26.998766 | D loss: 1.423657\n",
            "Step 2881: G loss: 27.133478 | D loss: 1.439734\n",
            "Step 2882: G loss: 26.077726 | D loss: 1.438124\n",
            "Step 2883: G loss: 23.152084 | D loss: 1.430640\n",
            "Step 2884: G loss: 29.029255 | D loss: 1.432269\n",
            "Step 2885: G loss: 29.842155 | D loss: 1.435111\n",
            "Step 2886: G loss: 20.972216 | D loss: 1.432044\n",
            "Step 2887: G loss: 24.124729 | D loss: 1.434063\n",
            "Step 2888: G loss: 41.296753 | D loss: 1.422371\n",
            "Step 2889: G loss: 25.074289 | D loss: 1.420887\n",
            "Step 2890: G loss: 27.585711 | D loss: 1.433249\n",
            "Step 2891: G loss: 25.689550 | D loss: 1.426891\n",
            "Step 2892: G loss: 36.701260 | D loss: 1.432818\n",
            "Step 2893: G loss: 28.350708 | D loss: 1.425387\n",
            "Step 2894: G loss: 32.512138 | D loss: 1.425173\n",
            "Step 2895: G loss: 26.456551 | D loss: 1.429516\n",
            "Step 2896: G loss: 21.764671 | D loss: 1.424538\n",
            "Step 2897: G loss: 28.686083 | D loss: 1.433270\n",
            "Step 2898: G loss: 30.303658 | D loss: 1.422136\n",
            "Step 2899: G loss: 44.025692 | D loss: 1.417226\n",
            "Step 2900: G loss: 21.120733 | D loss: 1.419393\n",
            "Step 2901: G loss: 27.230206 | D loss: 1.428432\n",
            "Step 2902: G loss: 45.896709 | D loss: 1.419843\n",
            "Step 2903: G loss: 26.005386 | D loss: 1.426671\n",
            "Step 2904: G loss: 33.207428 | D loss: 1.417684\n",
            "Step 2905: G loss: 39.438873 | D loss: 1.418455\n",
            "Step 2906: G loss: 26.877230 | D loss: 1.420172\n",
            "Step 2907: G loss: 37.078697 | D loss: 1.434383\n",
            "Step 2908: G loss: 31.896105 | D loss: 1.426795\n",
            "Step 2909: G loss: 26.789473 | D loss: 1.417452\n",
            "Step 2910: G loss: 23.723978 | D loss: 1.426098\n",
            "Step 2911: G loss: 35.845783 | D loss: 1.429364\n",
            "Step 2912: G loss: 31.654823 | D loss: 1.425239\n",
            "Step 2913: G loss: 31.384163 | D loss: 1.420247\n",
            "Step 2914: G loss: 46.766277 | D loss: 1.423407\n",
            "Step 2915: G loss: 25.054129 | D loss: 1.427053\n",
            "Step 2916: G loss: 25.728020 | D loss: 1.421452\n",
            "Step 2917: G loss: 45.899734 | D loss: 1.426110\n",
            "Step 2918: G loss: 29.797194 | D loss: 1.425285\n",
            "Step 2919: G loss: 37.551777 | D loss: 1.423404\n",
            "Step 2920: G loss: 26.291309 | D loss: 1.420078\n",
            "Step 2921: G loss: 30.902592 | D loss: 1.437966\n",
            "Step 2922: G loss: 29.114395 | D loss: 1.427850\n",
            "Step 2923: G loss: 27.325603 | D loss: 1.425309\n",
            "Step 2924: G loss: 19.482523 | D loss: 1.426617\n",
            "Step 2925: G loss: 36.837326 | D loss: 1.420231\n",
            "Step 2926: G loss: 37.483505 | D loss: 1.429974\n",
            "Step 2927: G loss: 21.662868 | D loss: 1.422557\n",
            "Step 2928: G loss: 35.459713 | D loss: 1.423180\n",
            "Step 2929: G loss: 27.758781 | D loss: 1.418621\n",
            "Step 2930: G loss: 34.621387 | D loss: 1.431782\n",
            "Step 2931: G loss: 26.739195 | D loss: 1.418596\n",
            "Step 2932: G loss: 24.440449 | D loss: 1.431907\n",
            "Step 2933: G loss: 30.929466 | D loss: 1.426083\n",
            "Step 2934: G loss: 29.304789 | D loss: 1.429106\n",
            "Step 2935: G loss: 26.152918 | D loss: 1.438580\n",
            "Step 2936: G loss: 38.671417 | D loss: 1.425732\n",
            "Step 2937: G loss: 33.720627 | D loss: 1.431480\n",
            "Step 2938: G loss: 31.936731 | D loss: 1.417733\n",
            "Step 2939: G loss: 29.693621 | D loss: 1.416800\n",
            "Step 2940: G loss: 19.822809 | D loss: 1.423651\n",
            "Step 2941: G loss: 20.538744 | D loss: 1.430557\n",
            "Step 2942: G loss: 24.519501 | D loss: 1.433560\n",
            "Step 2943: G loss: 41.658390 | D loss: 1.422760\n",
            "Step 2944: G loss: 35.445637 | D loss: 1.420671\n",
            "Step 2945: G loss: 34.996223 | D loss: 1.417731\n",
            "Step 2946: G loss: 29.838928 | D loss: 1.436789\n",
            "Step 2947: G loss: 36.746166 | D loss: 1.425032\n",
            "Step 2948: G loss: 45.110794 | D loss: 1.427407\n",
            "Step 2949: G loss: 37.717777 | D loss: 1.435249\n",
            "Step 2950: G loss: 30.276978 | D loss: 1.424905\n",
            "Step 2951: G loss: 29.176718 | D loss: 1.429017\n",
            "Step 2952: G loss: 28.324352 | D loss: 1.426557\n",
            "Step 2953: G loss: 41.461002 | D loss: 1.426796\n",
            "Step 2954: G loss: 43.764725 | D loss: 1.418556\n",
            "Step 2955: G loss: 30.931257 | D loss: 1.423595\n",
            "Step 2956: G loss: 27.467085 | D loss: 1.425814\n",
            "Step 2957: G loss: 33.239811 | D loss: 1.439615\n",
            "Step 2958: G loss: 37.627911 | D loss: 1.437817\n",
            "Step 2959: G loss: 24.640083 | D loss: 1.421926\n",
            "Step 2960: G loss: 32.800835 | D loss: 1.419662\n",
            "Step 2961: G loss: 38.261703 | D loss: 1.417850\n",
            "Step 2962: G loss: 21.665440 | D loss: 1.441008\n",
            "Step 2963: G loss: 32.554474 | D loss: 1.421647\n",
            "Step 2964: G loss: 25.540468 | D loss: 1.428066\n",
            "Step 2965: G loss: 33.727596 | D loss: 1.426503\n",
            "Step 2966: G loss: 28.094324 | D loss: 1.426307\n",
            "Step 2967: G loss: 25.895050 | D loss: 1.441642\n",
            "Step 2968: G loss: 23.632305 | D loss: 1.417449\n",
            "Step 2969: G loss: 25.459970 | D loss: 1.424759\n",
            "Step 2970: G loss: 29.157053 | D loss: 1.425838\n",
            "Step 2971: G loss: 22.480024 | D loss: 1.426737\n",
            "Step 2972: G loss: 31.208370 | D loss: 1.430117\n",
            "Step 2973: G loss: 37.556351 | D loss: 1.416690\n",
            "Step 2974: G loss: 18.138451 | D loss: 1.426065\n",
            "Step 2975: G loss: 36.306976 | D loss: 1.424292\n",
            "Step 2976: G loss: 38.030262 | D loss: 1.417836\n",
            "Step 2977: G loss: 28.330090 | D loss: 1.416722\n",
            "Step 2978: G loss: 25.448149 | D loss: 1.420771\n",
            "Step 2979: G loss: 29.279385 | D loss: 1.417487\n",
            "Step 2980: G loss: 26.707872 | D loss: 1.416691\n",
            "Step 2981: G loss: 32.455967 | D loss: 1.417567\n",
            "Step 2982: G loss: 31.478205 | D loss: 1.419974\n",
            "Step 2983: G loss: 28.535688 | D loss: 1.429154\n",
            "Step 2984: G loss: 24.122009 | D loss: 1.439901\n",
            "Step 2985: G loss: 25.767153 | D loss: 1.421576\n",
            "Step 2986: G loss: 39.683147 | D loss: 1.417974\n",
            "Step 2987: G loss: 23.240463 | D loss: 1.417289\n",
            "Step 2988: G loss: 40.955494 | D loss: 1.418190\n",
            "Step 2989: G loss: 23.010744 | D loss: 1.416355\n",
            "Step 2990: G loss: 31.763002 | D loss: 1.416684\n",
            "Step 2991: G loss: 20.734968 | D loss: 1.436555\n",
            "Step 2992: G loss: 28.794464 | D loss: 1.422779\n",
            "Step 2993: G loss: 27.324644 | D loss: 1.425329\n",
            "Step 2994: G loss: 25.909443 | D loss: 1.427622\n",
            "Step 2995: G loss: 31.474449 | D loss: 1.422461\n",
            "Step 2996: G loss: 29.241243 | D loss: 1.424072\n",
            "Step 2997: G loss: 28.533785 | D loss: 1.417455\n",
            "Step 2998: G loss: 24.455868 | D loss: 1.419028\n",
            "Step 2999: G loss: 30.777075 | D loss: 1.432363\n",
            "Step 3000: G loss: 36.902508 | D loss: 1.423377\n",
            "Model saved in file: /content/models/model.ckpt\n",
            "Step 3001: G loss: 24.788656 | D loss: 1.425316\n",
            "Step 3002: G loss: 37.536613 | D loss: 1.416444\n",
            "Step 3003: G loss: 31.446270 | D loss: 1.419028\n",
            "Step 3004: G loss: 36.713947 | D loss: 1.416880\n",
            "Step 3005: G loss: 27.570635 | D loss: 1.418804\n",
            "Step 3006: G loss: 41.140694 | D loss: 1.430841\n",
            "Step 3007: G loss: 43.576935 | D loss: 1.416863\n",
            "Step 3008: G loss: 28.517750 | D loss: 1.422171\n",
            "Step 3009: G loss: 34.013252 | D loss: 1.417941\n",
            "Step 3010: G loss: 38.032207 | D loss: 1.424684\n",
            "Step 3011: G loss: 25.765314 | D loss: 1.423011\n",
            "Step 3012: G loss: 31.334536 | D loss: 1.421040\n",
            "Step 3013: G loss: 28.666454 | D loss: 1.416175\n",
            "Step 3014: G loss: 31.934137 | D loss: 1.429317\n",
            "Step 3015: G loss: 28.051792 | D loss: 1.420618\n",
            "Step 3016: G loss: 32.496918 | D loss: 1.420610\n",
            "Step 3017: G loss: 37.391106 | D loss: 1.424841\n",
            "Step 3018: G loss: 25.518085 | D loss: 1.427299\n",
            "Step 3019: G loss: 48.971485 | D loss: 1.420903\n",
            "Step 3020: G loss: 28.321142 | D loss: 1.434801\n",
            "Step 3021: G loss: 24.222281 | D loss: 1.426866\n",
            "Step 3022: G loss: 30.957211 | D loss: 1.416949\n",
            "Step 3023: G loss: 23.689508 | D loss: 1.419226\n",
            "Step 3024: G loss: 27.793327 | D loss: 1.417900\n",
            "Step 3025: G loss: 25.822145 | D loss: 1.416748\n",
            "Step 3026: G loss: 33.128674 | D loss: 1.416801\n",
            "Step 3027: G loss: 25.555563 | D loss: 1.436994\n",
            "Step 3028: G loss: 26.116735 | D loss: 1.416488\n",
            "Step 3029: G loss: 20.414183 | D loss: 1.416800\n",
            "Step 3030: G loss: 30.765314 | D loss: 1.423428\n",
            "Step 3031: G loss: 31.501520 | D loss: 1.425232\n",
            "Step 3032: G loss: 28.503233 | D loss: 1.424238\n",
            "Step 3033: G loss: 29.190578 | D loss: 1.430748\n",
            "Step 3034: G loss: 24.209890 | D loss: 1.428262\n",
            "Step 3035: G loss: 22.300085 | D loss: 1.417097\n",
            "Step 3036: G loss: 22.243675 | D loss: 1.427025\n",
            "Step 3037: G loss: 26.955936 | D loss: 1.433300\n",
            "Step 3038: G loss: 38.129539 | D loss: 1.420026\n",
            "Step 3039: G loss: 26.795603 | D loss: 1.426874\n",
            "Step 3040: G loss: 37.930374 | D loss: 1.418501\n",
            "Step 3041: G loss: 31.722973 | D loss: 1.421926\n",
            "Step 3042: G loss: 33.067142 | D loss: 1.415811\n",
            "Step 3043: G loss: 29.266365 | D loss: 1.417749\n",
            "Step 3044: G loss: 27.441872 | D loss: 1.422970\n",
            "Step 3045: G loss: 29.958838 | D loss: 1.423233\n",
            "Step 3046: G loss: 27.155174 | D loss: 1.429939\n",
            "Step 3047: G loss: 21.201792 | D loss: 1.438966\n",
            "Step 3048: G loss: 20.660261 | D loss: 1.420713\n",
            "Step 3049: G loss: 43.702995 | D loss: 1.427774\n",
            "Step 3050: G loss: 33.649044 | D loss: 1.424038\n",
            "Step 3051: G loss: 21.278288 | D loss: 1.424849\n",
            "Step 3052: G loss: 18.659994 | D loss: 1.430801\n",
            "Step 3053: G loss: 36.642246 | D loss: 1.415883\n",
            "Step 3054: G loss: 23.909678 | D loss: 1.415954\n",
            "Step 3055: G loss: 37.486736 | D loss: 1.418905\n",
            "Step 3056: G loss: 25.935328 | D loss: 1.415775\n",
            "Step 3057: G loss: 27.082285 | D loss: 1.448048\n",
            "Step 3058: G loss: 24.399101 | D loss: 1.420647\n",
            "Step 3059: G loss: 41.467968 | D loss: 1.416128\n",
            "Step 3060: G loss: 31.655987 | D loss: 1.424084\n",
            "Step 3061: G loss: 42.276169 | D loss: 1.424345\n",
            "Step 3062: G loss: 30.344913 | D loss: 1.425879\n",
            "Step 3063: G loss: 30.523664 | D loss: 1.426225\n",
            "Step 3064: G loss: 28.592619 | D loss: 1.416329\n",
            "Step 3065: G loss: 34.457485 | D loss: 1.435589\n",
            "Step 3066: G loss: 38.485764 | D loss: 1.421329\n",
            "Step 3067: G loss: 24.360195 | D loss: 1.424655\n",
            "Step 3068: G loss: 30.605347 | D loss: 1.420917\n",
            "Step 3069: G loss: 27.362621 | D loss: 1.416036\n",
            "Step 3070: G loss: 24.450882 | D loss: 1.420199\n",
            "Step 3071: G loss: 36.646305 | D loss: 1.415572\n",
            "Step 3072: G loss: 23.813570 | D loss: 1.423772\n",
            "Step 3073: G loss: 31.127319 | D loss: 1.416694\n",
            "Step 3074: G loss: 24.643593 | D loss: 1.416583\n",
            "Step 3075: G loss: 31.229357 | D loss: 1.424972\n",
            "Step 3076: G loss: 26.685244 | D loss: 1.415537\n",
            "Step 3077: G loss: 27.386131 | D loss: 1.419975\n",
            "Step 3078: G loss: 31.531828 | D loss: 1.428656\n",
            "Step 3079: G loss: 23.724758 | D loss: 1.426332\n",
            "Step 3080: G loss: 26.367952 | D loss: 1.428829\n",
            "Step 3081: G loss: 41.186916 | D loss: 1.428122\n",
            "Step 3082: G loss: 32.156963 | D loss: 1.425519\n",
            "Step 3083: G loss: 29.739840 | D loss: 1.427854\n",
            "Step 3084: G loss: 41.737061 | D loss: 1.415770\n",
            "Step 3085: G loss: 28.071630 | D loss: 1.416329\n",
            "Step 3086: G loss: 38.108971 | D loss: 1.426024\n",
            "Step 3087: G loss: 32.057674 | D loss: 1.432706\n",
            "Step 3088: G loss: 20.647104 | D loss: 1.415559\n",
            "Step 3089: G loss: 23.509607 | D loss: 1.423085\n",
            "Step 3090: G loss: 23.824039 | D loss: 1.415515\n",
            "Step 3091: G loss: 28.691751 | D loss: 1.416266\n",
            "Step 3092: G loss: 25.879318 | D loss: 1.422189\n",
            "Step 3093: G loss: 31.536440 | D loss: 1.415490\n",
            "Step 3094: G loss: 36.811707 | D loss: 1.415907\n",
            "Step 3095: G loss: 30.946630 | D loss: 1.424380\n",
            "Step 3096: G loss: 29.315712 | D loss: 1.419466\n",
            "Step 3097: G loss: 32.905396 | D loss: 1.415492\n",
            "Step 3098: G loss: 27.953810 | D loss: 1.426440\n",
            "Step 3099: G loss: 30.411282 | D loss: 1.415973\n",
            "Step 3100: G loss: 37.831589 | D loss: 1.416513\n",
            "Step 3101: G loss: 21.867714 | D loss: 1.420275\n",
            "Step 3102: G loss: 27.508617 | D loss: 1.423712\n",
            "Step 3103: G loss: 46.032795 | D loss: 1.416368\n",
            "Step 3104: G loss: 22.354895 | D loss: 1.423892\n",
            "Step 3105: G loss: 33.720520 | D loss: 1.415417\n",
            "Step 3106: G loss: 25.534918 | D loss: 1.417596\n",
            "Step 3107: G loss: 32.382565 | D loss: 1.415687\n",
            "Step 3108: G loss: 43.723171 | D loss: 1.424321\n",
            "Step 3109: G loss: 25.667480 | D loss: 1.423739\n",
            "Step 3110: G loss: 35.893066 | D loss: 1.421838\n",
            "Step 3111: G loss: 38.456188 | D loss: 1.426478\n",
            "Step 3112: G loss: 30.477901 | D loss: 1.418581\n",
            "Step 3113: G loss: 30.557922 | D loss: 1.427905\n",
            "Step 3114: G loss: 28.643930 | D loss: 1.434894\n",
            "Step 3115: G loss: 33.684055 | D loss: 1.417804\n",
            "Step 3116: G loss: 42.265049 | D loss: 1.422664\n",
            "Step 3117: G loss: 30.502148 | D loss: 1.417852\n",
            "Step 3118: G loss: 39.043808 | D loss: 1.415716\n",
            "Step 3119: G loss: 35.689724 | D loss: 1.416491\n",
            "Step 3120: G loss: 25.131187 | D loss: 1.423682\n",
            "Step 3121: G loss: 27.912575 | D loss: 1.426812\n",
            "Step 3122: G loss: 30.416498 | D loss: 1.428568\n",
            "Step 3123: G loss: 33.847961 | D loss: 1.419607\n",
            "Step 3124: G loss: 25.316290 | D loss: 1.425335\n",
            "Step 3125: G loss: 36.492893 | D loss: 1.418569\n",
            "Step 3126: G loss: 37.891644 | D loss: 1.420916\n",
            "Step 3127: G loss: 25.511427 | D loss: 1.419757\n",
            "Step 3128: G loss: 28.315212 | D loss: 1.418819\n",
            "Step 3129: G loss: 23.395662 | D loss: 1.418496\n",
            "Step 3130: G loss: 24.522865 | D loss: 1.415162\n",
            "Step 3131: G loss: 23.175705 | D loss: 1.415628\n",
            "Step 3132: G loss: 31.158621 | D loss: 1.419737\n",
            "Step 3133: G loss: 50.522610 | D loss: 1.426882\n",
            "Step 3134: G loss: 32.164200 | D loss: 1.419935\n",
            "Step 3135: G loss: 29.250620 | D loss: 1.438555\n",
            "Step 3136: G loss: 28.762899 | D loss: 1.428751\n",
            "Step 3137: G loss: 30.494511 | D loss: 1.417998\n",
            "Step 3138: G loss: 35.947483 | D loss: 1.419142\n",
            "Step 3139: G loss: 24.769505 | D loss: 1.423532\n",
            "Step 3140: G loss: 22.785007 | D loss: 1.443005\n",
            "Step 3141: G loss: 47.070473 | D loss: 1.418490\n",
            "Step 3142: G loss: 24.535282 | D loss: 1.425931\n",
            "Step 3143: G loss: 29.550261 | D loss: 1.421663\n",
            "Step 3144: G loss: 29.680990 | D loss: 1.422066\n",
            "Step 3145: G loss: 22.406357 | D loss: 1.415163\n",
            "Step 3146: G loss: 21.252928 | D loss: 1.418847\n",
            "Step 3147: G loss: 28.692114 | D loss: 1.431186\n",
            "Step 3148: G loss: 28.915182 | D loss: 1.425830\n",
            "Step 3149: G loss: 39.811123 | D loss: 1.424593\n",
            "Step 3150: G loss: 32.207661 | D loss: 1.430109\n",
            "Step 3151: G loss: 37.584820 | D loss: 1.431440\n",
            "Step 3152: G loss: 22.493025 | D loss: 1.421905\n",
            "Step 3153: G loss: 31.980713 | D loss: 1.419521\n",
            "Step 3154: G loss: 25.731941 | D loss: 1.430633\n",
            "Step 3155: G loss: 35.991550 | D loss: 1.430582\n",
            "Step 3156: G loss: 39.539879 | D loss: 1.415952\n",
            "Step 3157: G loss: 35.080975 | D loss: 1.424922\n",
            "Step 3158: G loss: 24.212252 | D loss: 1.425837\n",
            "Step 3159: G loss: 21.649010 | D loss: 1.424383\n",
            "Step 3160: G loss: 31.248405 | D loss: 1.414992\n",
            "Step 3161: G loss: 27.484903 | D loss: 1.418508\n",
            "Step 3162: G loss: 26.082304 | D loss: 1.414934\n",
            "Step 3163: G loss: 30.823839 | D loss: 1.430850\n",
            "Step 3164: G loss: 33.248684 | D loss: 1.423653\n",
            "Step 3165: G loss: 33.595478 | D loss: 1.431422\n",
            "Step 3166: G loss: 37.529762 | D loss: 1.415044\n",
            "Step 3167: G loss: 35.104801 | D loss: 1.424347\n",
            "Step 3168: G loss: 20.246569 | D loss: 1.419769\n",
            "Step 3169: G loss: 38.087498 | D loss: 1.427774\n",
            "Step 3170: G loss: 40.646946 | D loss: 1.424339\n",
            "Step 3171: G loss: 28.630642 | D loss: 1.428146\n",
            "Step 3172: G loss: 27.534046 | D loss: 1.418726\n",
            "Step 3173: G loss: 36.542007 | D loss: 1.432372\n",
            "Step 3174: G loss: 25.900331 | D loss: 1.415537\n",
            "Step 3175: G loss: 26.683357 | D loss: 1.416085\n",
            "Step 3176: G loss: 22.750500 | D loss: 1.419678\n",
            "Step 3177: G loss: 20.247009 | D loss: 1.416258\n",
            "Step 3178: G loss: 25.029474 | D loss: 1.414751\n",
            "Step 3179: G loss: 31.892292 | D loss: 1.414557\n",
            "Step 3180: G loss: 27.059370 | D loss: 1.418980\n",
            "Step 3181: G loss: 29.821959 | D loss: 1.414702\n",
            "Step 3182: G loss: 38.528442 | D loss: 1.415813\n",
            "Step 3183: G loss: 27.705797 | D loss: 1.414509\n",
            "Step 3184: G loss: 38.289726 | D loss: 1.418898\n",
            "Step 3185: G loss: 30.133116 | D loss: 1.424237\n",
            "Step 3186: G loss: 38.779404 | D loss: 1.428420\n",
            "Step 3187: G loss: 36.254791 | D loss: 1.427139\n",
            "Step 3188: G loss: 39.472473 | D loss: 1.422792\n",
            "Step 3189: G loss: 27.649277 | D loss: 1.422244\n",
            "Step 3190: G loss: 29.672821 | D loss: 1.444352\n",
            "Step 3191: G loss: 39.223682 | D loss: 1.425773\n",
            "Step 3192: G loss: 32.545467 | D loss: 1.421326\n",
            "Step 3193: G loss: 40.749691 | D loss: 1.435344\n",
            "Step 3194: G loss: 26.599239 | D loss: 1.434083\n",
            "Step 3195: G loss: 40.615963 | D loss: 1.426694\n",
            "Step 3196: G loss: 19.521639 | D loss: 1.430670\n",
            "Step 3197: G loss: 23.119595 | D loss: 1.417337\n",
            "Step 3198: G loss: 39.161690 | D loss: 1.424728\n",
            "Step 3199: G loss: 34.001484 | D loss: 1.428122\n",
            "Step 3200: G loss: 36.757786 | D loss: 1.429356\n",
            "Step 3201: G loss: 33.232498 | D loss: 1.420781\n",
            "Step 3202: G loss: 21.329098 | D loss: 1.417820\n",
            "Step 3203: G loss: 34.772861 | D loss: 1.414357\n",
            "Step 3204: G loss: 35.605606 | D loss: 1.419276\n",
            "Step 3205: G loss: 35.970837 | D loss: 1.427588\n",
            "Step 3206: G loss: 29.118149 | D loss: 1.426947\n",
            "Step 3207: G loss: 27.396809 | D loss: 1.414594\n",
            "Step 3208: G loss: 24.682858 | D loss: 1.429659\n",
            "Step 3209: G loss: 26.350454 | D loss: 1.424181\n",
            "Step 3210: G loss: 28.920996 | D loss: 1.425249\n",
            "Step 3211: G loss: 23.498674 | D loss: 1.414437\n",
            "Step 3212: G loss: 44.861053 | D loss: 1.426920\n",
            "Step 3213: G loss: 30.361151 | D loss: 1.428647\n",
            "Step 3214: G loss: 37.792175 | D loss: 1.422145\n",
            "Step 3215: G loss: 25.441935 | D loss: 1.426577\n",
            "Step 3216: G loss: 29.591242 | D loss: 1.414221\n",
            "Step 3217: G loss: 38.865742 | D loss: 1.429187\n",
            "Step 3218: G loss: 40.857716 | D loss: 1.434159\n",
            "Step 3219: G loss: 33.651073 | D loss: 1.430008\n",
            "Step 3220: G loss: 23.254129 | D loss: 1.415740\n",
            "Step 3221: G loss: 19.822533 | D loss: 1.414889\n",
            "Step 3222: G loss: 36.537609 | D loss: 1.416089\n",
            "Step 3223: G loss: 35.176922 | D loss: 1.424038\n",
            "Step 3224: G loss: 44.375458 | D loss: 1.414017\n",
            "Step 3225: G loss: 38.138229 | D loss: 1.417499\n",
            "Step 3226: G loss: 37.963547 | D loss: 1.415060\n",
            "Step 3227: G loss: 29.021748 | D loss: 1.414500\n",
            "Step 3228: G loss: 33.938576 | D loss: 1.414690\n",
            "Step 3229: G loss: 31.951529 | D loss: 1.418834\n",
            "Step 3230: G loss: 24.315283 | D loss: 1.418408\n",
            "Step 3231: G loss: 45.345253 | D loss: 1.416215\n",
            "Step 3232: G loss: 40.079411 | D loss: 1.426075\n",
            "Step 3233: G loss: 30.382843 | D loss: 1.414091\n",
            "Step 3234: G loss: 23.282810 | D loss: 1.421985\n",
            "Step 3235: G loss: 20.264240 | D loss: 1.421048\n",
            "Step 3236: G loss: 37.751919 | D loss: 1.416108\n",
            "Step 3237: G loss: 32.043789 | D loss: 1.418596\n",
            "Step 3238: G loss: 51.138981 | D loss: 1.416788\n",
            "Step 3239: G loss: 23.246580 | D loss: 1.439790\n",
            "Step 3240: G loss: 26.742390 | D loss: 1.414295\n",
            "Step 3241: G loss: 29.092926 | D loss: 1.429781\n",
            "Step 3242: G loss: 25.004704 | D loss: 1.419802\n",
            "Step 3243: G loss: 27.741106 | D loss: 1.422025\n",
            "Step 3244: G loss: 33.875443 | D loss: 1.423821\n",
            "Step 3245: G loss: 27.580324 | D loss: 1.422605\n",
            "Step 3246: G loss: 27.349085 | D loss: 1.421508\n",
            "Step 3247: G loss: 28.305786 | D loss: 1.415934\n",
            "Step 3248: G loss: 17.965485 | D loss: 1.414045\n",
            "Step 3249: G loss: 25.157393 | D loss: 1.425771\n",
            "Step 3250: G loss: 36.553787 | D loss: 1.427531\n",
            "Step 3251: G loss: 27.133224 | D loss: 1.415592\n",
            "Step 3252: G loss: 28.552988 | D loss: 1.417150\n",
            "Step 3253: G loss: 45.025726 | D loss: 1.417571\n",
            "Step 3254: G loss: 31.057516 | D loss: 1.415164\n",
            "Step 3255: G loss: 23.057125 | D loss: 1.418529\n",
            "Step 3256: G loss: 27.161116 | D loss: 1.420424\n",
            "Step 3257: G loss: 29.778881 | D loss: 1.419434\n",
            "Step 3258: G loss: 26.530682 | D loss: 1.419247\n",
            "Step 3259: G loss: 25.774530 | D loss: 1.428231\n",
            "Step 3260: G loss: 25.637398 | D loss: 1.437329\n",
            "Step 3261: G loss: 23.321331 | D loss: 1.424650\n",
            "Step 3262: G loss: 28.191244 | D loss: 1.432071\n",
            "Step 3263: G loss: 28.377550 | D loss: 1.436320\n",
            "Step 3264: G loss: 20.950726 | D loss: 1.422772\n",
            "Step 3265: G loss: 23.500959 | D loss: 1.429502\n",
            "Step 3266: G loss: 41.129875 | D loss: 1.414117\n",
            "Step 3267: G loss: 24.549255 | D loss: 1.416454\n",
            "Step 3268: G loss: 27.258184 | D loss: 1.426808\n",
            "Step 3269: G loss: 24.854374 | D loss: 1.421967\n",
            "Step 3270: G loss: 34.911278 | D loss: 1.425526\n",
            "Step 3271: G loss: 28.135244 | D loss: 1.419784\n",
            "Step 3272: G loss: 31.285238 | D loss: 1.419212\n",
            "Step 3273: G loss: 25.829557 | D loss: 1.423669\n",
            "Step 3274: G loss: 21.440805 | D loss: 1.419767\n",
            "Step 3275: G loss: 26.836411 | D loss: 1.425214\n",
            "Step 3276: G loss: 29.853827 | D loss: 1.416400\n",
            "Step 3277: G loss: 43.071396 | D loss: 1.413530\n",
            "Step 3278: G loss: 20.135342 | D loss: 1.413716\n",
            "Step 3279: G loss: 27.625566 | D loss: 1.422388\n",
            "Step 3280: G loss: 45.901489 | D loss: 1.416117\n",
            "Step 3281: G loss: 24.807154 | D loss: 1.422005\n",
            "Step 3282: G loss: 32.145218 | D loss: 1.413669\n",
            "Step 3283: G loss: 39.170540 | D loss: 1.414893\n",
            "Step 3284: G loss: 27.523718 | D loss: 1.414437\n",
            "Step 3285: G loss: 36.566486 | D loss: 1.424761\n",
            "Step 3286: G loss: 31.080982 | D loss: 1.421553\n",
            "Step 3287: G loss: 26.877535 | D loss: 1.413621\n",
            "Step 3288: G loss: 23.821970 | D loss: 1.420683\n",
            "Step 3289: G loss: 35.120762 | D loss: 1.423026\n",
            "Step 3290: G loss: 29.477945 | D loss: 1.419977\n",
            "Step 3291: G loss: 30.863205 | D loss: 1.415513\n",
            "Step 3292: G loss: 46.074112 | D loss: 1.419915\n",
            "Step 3293: G loss: 23.857046 | D loss: 1.421814\n",
            "Step 3294: G loss: 23.465916 | D loss: 1.414422\n",
            "Step 3295: G loss: 44.643684 | D loss: 1.419549\n",
            "Step 3296: G loss: 29.501314 | D loss: 1.419959\n",
            "Step 3297: G loss: 37.586422 | D loss: 1.416119\n",
            "Step 3298: G loss: 26.118402 | D loss: 1.413620\n",
            "Step 3299: G loss: 31.123833 | D loss: 1.430049\n",
            "Step 3300: G loss: 28.709164 | D loss: 1.422789\n",
            "Step 3301: G loss: 27.599474 | D loss: 1.420827\n",
            "Step 3302: G loss: 19.809196 | D loss: 1.421325\n",
            "Step 3303: G loss: 36.509525 | D loss: 1.414544\n",
            "Step 3304: G loss: 37.674202 | D loss: 1.419596\n",
            "Step 3305: G loss: 20.857891 | D loss: 1.414780\n",
            "Step 3306: G loss: 35.202534 | D loss: 1.416590\n",
            "Step 3307: G loss: 27.354090 | D loss: 1.414444\n",
            "Step 3308: G loss: 33.449574 | D loss: 1.417954\n",
            "Step 3309: G loss: 26.186136 | D loss: 1.414954\n",
            "Step 3310: G loss: 23.614532 | D loss: 1.422455\n",
            "Step 3311: G loss: 29.695278 | D loss: 1.416430\n",
            "Step 3312: G loss: 29.368565 | D loss: 1.423113\n",
            "Step 3313: G loss: 25.808189 | D loss: 1.429207\n",
            "Step 3314: G loss: 38.746689 | D loss: 1.420195\n",
            "Step 3315: G loss: 32.922859 | D loss: 1.424863\n",
            "Step 3316: G loss: 30.956028 | D loss: 1.413581\n",
            "Step 3317: G loss: 27.860987 | D loss: 1.413153\n",
            "Step 3318: G loss: 19.866972 | D loss: 1.417644\n",
            "Step 3319: G loss: 20.893560 | D loss: 1.420122\n",
            "Step 3320: G loss: 24.355724 | D loss: 1.418905\n",
            "Step 3321: G loss: 39.783718 | D loss: 1.417209\n",
            "Step 3322: G loss: 34.448299 | D loss: 1.414661\n",
            "Step 3323: G loss: 33.332001 | D loss: 1.413900\n",
            "Step 3324: G loss: 29.775887 | D loss: 1.430125\n",
            "Step 3325: G loss: 33.312191 | D loss: 1.418129\n",
            "Step 3326: G loss: 45.364685 | D loss: 1.421598\n",
            "Step 3327: G loss: 36.730061 | D loss: 1.424927\n",
            "Step 3328: G loss: 29.151028 | D loss: 1.418279\n",
            "Step 3329: G loss: 28.013390 | D loss: 1.421497\n",
            "Step 3330: G loss: 28.204462 | D loss: 1.420804\n",
            "Step 3331: G loss: 39.692337 | D loss: 1.418651\n",
            "Step 3332: G loss: 42.760612 | D loss: 1.413445\n",
            "Step 3333: G loss: 32.005978 | D loss: 1.417516\n",
            "Step 3334: G loss: 26.739832 | D loss: 1.420423\n",
            "Step 3335: G loss: 31.809601 | D loss: 1.427762\n",
            "Step 3336: G loss: 39.129520 | D loss: 1.427170\n",
            "Step 3337: G loss: 25.256218 | D loss: 1.416664\n",
            "Step 3338: G loss: 32.380829 | D loss: 1.415376\n",
            "Step 3339: G loss: 35.722263 | D loss: 1.415704\n",
            "Step 3340: G loss: 22.126951 | D loss: 1.430377\n",
            "Step 3341: G loss: 31.568661 | D loss: 1.416573\n",
            "Step 3342: G loss: 24.066259 | D loss: 1.432456\n",
            "Step 3343: G loss: 33.403000 | D loss: 1.424266\n",
            "Step 3344: G loss: 26.518833 | D loss: 1.425271\n",
            "Step 3345: G loss: 26.887232 | D loss: 1.430695\n",
            "Step 3346: G loss: 23.618887 | D loss: 1.415811\n",
            "Step 3347: G loss: 25.157516 | D loss: 1.425262\n",
            "Step 3348: G loss: 28.886198 | D loss: 1.420976\n",
            "Step 3349: G loss: 23.211685 | D loss: 1.426918\n",
            "Step 3350: G loss: 30.673887 | D loss: 1.425226\n",
            "Step 3351: G loss: 39.409389 | D loss: 1.413283\n",
            "Step 3352: G loss: 17.366293 | D loss: 1.420782\n",
            "Step 3353: G loss: 36.005875 | D loss: 1.419214\n",
            "Step 3354: G loss: 37.513840 | D loss: 1.415056\n",
            "Step 3355: G loss: 29.393541 | D loss: 1.412849\n",
            "Step 3356: G loss: 26.120708 | D loss: 1.418600\n",
            "Step 3357: G loss: 29.294506 | D loss: 1.413656\n",
            "Step 3358: G loss: 28.383781 | D loss: 1.412942\n",
            "Step 3359: G loss: 32.846653 | D loss: 1.417881\n",
            "Step 3360: G loss: 29.747841 | D loss: 1.414328\n",
            "Step 3361: G loss: 29.189676 | D loss: 1.422451\n",
            "Step 3362: G loss: 23.386538 | D loss: 1.433987\n",
            "Step 3363: G loss: 24.774040 | D loss: 1.413361\n",
            "Step 3364: G loss: 40.211468 | D loss: 1.413019\n",
            "Step 3365: G loss: 23.578556 | D loss: 1.413136\n",
            "Step 3366: G loss: 39.925396 | D loss: 1.414110\n",
            "Step 3367: G loss: 22.177893 | D loss: 1.412699\n",
            "Step 3368: G loss: 31.850388 | D loss: 1.413163\n",
            "Step 3369: G loss: 20.776463 | D loss: 1.426990\n",
            "Step 3370: G loss: 27.742487 | D loss: 1.415415\n",
            "Step 3371: G loss: 27.366783 | D loss: 1.419204\n",
            "Step 3372: G loss: 26.603615 | D loss: 1.420618\n",
            "Step 3373: G loss: 31.242016 | D loss: 1.416998\n",
            "Step 3374: G loss: 28.554916 | D loss: 1.418087\n",
            "Step 3375: G loss: 27.229517 | D loss: 1.413160\n",
            "Step 3376: G loss: 23.941347 | D loss: 1.413801\n",
            "Step 3377: G loss: 31.290518 | D loss: 1.423120\n",
            "Step 3378: G loss: 37.533104 | D loss: 1.420792\n",
            "Step 3379: G loss: 23.465347 | D loss: 1.420651\n",
            "Step 3380: G loss: 37.196751 | D loss: 1.412798\n",
            "Step 3381: G loss: 30.897942 | D loss: 1.414123\n",
            "Step 3382: G loss: 36.855141 | D loss: 1.414224\n",
            "Step 3383: G loss: 27.137632 | D loss: 1.414133\n",
            "Step 3384: G loss: 37.028812 | D loss: 1.422219\n",
            "Step 3385: G loss: 44.774590 | D loss: 1.413477\n",
            "Step 3386: G loss: 29.029966 | D loss: 1.416729\n",
            "Step 3387: G loss: 31.614790 | D loss: 1.414923\n",
            "Step 3388: G loss: 38.222191 | D loss: 1.419611\n",
            "Step 3389: G loss: 24.147488 | D loss: 1.418978\n",
            "Step 3390: G loss: 31.979860 | D loss: 1.416462\n",
            "Step 3391: G loss: 28.640816 | D loss: 1.412615\n",
            "Step 3392: G loss: 32.204735 | D loss: 1.419472\n",
            "Step 3393: G loss: 27.237801 | D loss: 1.416472\n",
            "Step 3394: G loss: 30.685703 | D loss: 1.415031\n",
            "Step 3395: G loss: 37.030804 | D loss: 1.419645\n",
            "Step 3396: G loss: 25.212751 | D loss: 1.422279\n",
            "Step 3397: G loss: 47.770466 | D loss: 1.413281\n",
            "Step 3398: G loss: 27.611221 | D loss: 1.426137\n",
            "Step 3399: G loss: 23.539780 | D loss: 1.421618\n",
            "Step 3400: G loss: 31.051924 | D loss: 1.413146\n",
            "Step 3401: G loss: 22.909956 | D loss: 1.418117\n",
            "Step 3402: G loss: 27.587963 | D loss: 1.412750\n",
            "Step 3403: G loss: 25.857960 | D loss: 1.412500\n",
            "Step 3404: G loss: 32.846249 | D loss: 1.412770\n",
            "Step 3405: G loss: 25.057508 | D loss: 1.426989\n",
            "Step 3406: G loss: 25.080023 | D loss: 1.412558\n",
            "Step 3407: G loss: 20.121687 | D loss: 1.412359\n",
            "Step 3408: G loss: 31.149530 | D loss: 1.417557\n",
            "Step 3409: G loss: 31.111692 | D loss: 1.420423\n",
            "Step 3410: G loss: 25.970367 | D loss: 1.416363\n",
            "Step 3411: G loss: 28.502558 | D loss: 1.413328\n",
            "Step 3412: G loss: 25.177280 | D loss: 1.417008\n",
            "Step 3413: G loss: 21.672497 | D loss: 1.412234\n",
            "Step 3414: G loss: 22.288607 | D loss: 1.420382\n",
            "Step 3415: G loss: 27.063438 | D loss: 1.424235\n",
            "Step 3416: G loss: 36.571304 | D loss: 1.415672\n",
            "Step 3417: G loss: 24.965508 | D loss: 1.420354\n",
            "Step 3418: G loss: 36.526257 | D loss: 1.413289\n",
            "Step 3419: G loss: 31.566610 | D loss: 1.416720\n",
            "Step 3420: G loss: 32.284912 | D loss: 1.412345\n",
            "Step 3421: G loss: 28.025387 | D loss: 1.413500\n",
            "Step 3422: G loss: 26.931107 | D loss: 1.415822\n",
            "Step 3423: G loss: 29.100571 | D loss: 1.416649\n",
            "Step 3424: G loss: 26.441172 | D loss: 1.424224\n",
            "Step 3425: G loss: 21.167355 | D loss: 1.429652\n",
            "Step 3426: G loss: 21.108175 | D loss: 1.415775\n",
            "Step 3427: G loss: 41.356956 | D loss: 1.420059\n",
            "Step 3428: G loss: 32.546463 | D loss: 1.417991\n",
            "Step 3429: G loss: 20.451942 | D loss: 1.418886\n",
            "Step 3430: G loss: 18.076942 | D loss: 1.421947\n",
            "Step 3431: G loss: 35.395889 | D loss: 1.412080\n",
            "Step 3432: G loss: 25.159248 | D loss: 1.412155\n",
            "Step 3433: G loss: 37.846287 | D loss: 1.417065\n",
            "Step 3434: G loss: 25.589478 | D loss: 1.412790\n",
            "Step 3435: G loss: 28.169842 | D loss: 1.437253\n",
            "Step 3436: G loss: 24.401276 | D loss: 1.419283\n",
            "Step 3437: G loss: 40.914993 | D loss: 1.413252\n",
            "Step 3438: G loss: 30.928932 | D loss: 1.418967\n",
            "Step 3439: G loss: 41.770966 | D loss: 1.419333\n",
            "Step 3440: G loss: 30.012468 | D loss: 1.418316\n",
            "Step 3441: G loss: 29.574110 | D loss: 1.419933\n",
            "Step 3442: G loss: 29.435978 | D loss: 1.412269\n",
            "Step 3443: G loss: 34.519135 | D loss: 1.433233\n",
            "Step 3444: G loss: 38.408428 | D loss: 1.415932\n",
            "Step 3445: G loss: 24.262241 | D loss: 1.418615\n",
            "Step 3446: G loss: 28.942255 | D loss: 1.415909\n",
            "Step 3447: G loss: 26.949806 | D loss: 1.412937\n",
            "Step 3448: G loss: 23.800049 | D loss: 1.416654\n",
            "Step 3449: G loss: 36.866554 | D loss: 1.411924\n",
            "Step 3450: G loss: 23.636660 | D loss: 1.418414\n",
            "Step 3451: G loss: 29.670656 | D loss: 1.412595\n",
            "Step 3452: G loss: 24.168358 | D loss: 1.412425\n",
            "Step 3453: G loss: 31.119667 | D loss: 1.418841\n",
            "Step 3454: G loss: 25.962608 | D loss: 1.411864\n",
            "Step 3455: G loss: 24.497419 | D loss: 1.412707\n",
            "Step 3456: G loss: 30.013977 | D loss: 1.420910\n",
            "Step 3457: G loss: 24.135378 | D loss: 1.418961\n",
            "Step 3458: G loss: 26.438690 | D loss: 1.421886\n",
            "Step 3459: G loss: 40.436092 | D loss: 1.420643\n",
            "Step 3460: G loss: 32.327156 | D loss: 1.419153\n",
            "Step 3461: G loss: 28.708445 | D loss: 1.424392\n",
            "Step 3462: G loss: 39.741867 | D loss: 1.412606\n",
            "Step 3463: G loss: 27.531322 | D loss: 1.413659\n",
            "Step 3464: G loss: 36.201214 | D loss: 1.425942\n",
            "Step 3465: G loss: 32.259682 | D loss: 1.427947\n",
            "Step 3466: G loss: 19.846613 | D loss: 1.415381\n",
            "Step 3467: G loss: 22.598070 | D loss: 1.419024\n",
            "Step 3468: G loss: 22.876492 | D loss: 1.411687\n",
            "Step 3469: G loss: 26.832323 | D loss: 1.412238\n",
            "Step 3470: G loss: 24.105152 | D loss: 1.417400\n",
            "Step 3471: G loss: 28.119799 | D loss: 1.411719\n",
            "Step 3472: G loss: 34.907906 | D loss: 1.412403\n",
            "Step 3473: G loss: 31.598724 | D loss: 1.420477\n",
            "Step 3474: G loss: 29.265499 | D loss: 1.415695\n",
            "Step 3475: G loss: 32.991768 | D loss: 1.411614\n",
            "Step 3476: G loss: 26.228727 | D loss: 1.420772\n",
            "Step 3477: G loss: 29.426950 | D loss: 1.411820\n",
            "Step 3478: G loss: 36.357140 | D loss: 1.412055\n",
            "Step 3479: G loss: 21.568476 | D loss: 1.413882\n",
            "Step 3480: G loss: 27.165257 | D loss: 1.418468\n",
            "Step 3481: G loss: 45.346371 | D loss: 1.412136\n",
            "Step 3482: G loss: 21.881966 | D loss: 1.419716\n",
            "Step 3483: G loss: 33.388432 | D loss: 1.411789\n",
            "Step 3484: G loss: 25.248783 | D loss: 1.412944\n",
            "Step 3485: G loss: 31.957439 | D loss: 1.412014\n",
            "Step 3486: G loss: 42.339756 | D loss: 1.418793\n",
            "Step 3487: G loss: 24.459158 | D loss: 1.418502\n",
            "Step 3488: G loss: 36.088665 | D loss: 1.418790\n",
            "Step 3489: G loss: 34.584969 | D loss: 1.419332\n",
            "Step 3490: G loss: 28.948677 | D loss: 1.414548\n",
            "Step 3491: G loss: 29.031185 | D loss: 1.418885\n",
            "Step 3492: G loss: 28.137974 | D loss: 1.425881\n",
            "Step 3493: G loss: 31.347731 | D loss: 1.414266\n",
            "Step 3494: G loss: 41.166473 | D loss: 1.423350\n",
            "Step 3495: G loss: 30.706993 | D loss: 1.413356\n",
            "Step 3496: G loss: 37.832745 | D loss: 1.411892\n",
            "Step 3497: G loss: 35.411057 | D loss: 1.414319\n",
            "Step 3498: G loss: 25.421579 | D loss: 1.418340\n",
            "Step 3499: G loss: 26.981915 | D loss: 1.420511\n",
            "Step 3500: G loss: 29.885876 | D loss: 1.418102\n",
            "Step 3501: G loss: 33.018223 | D loss: 1.414587\n",
            "Step 3502: G loss: 24.531103 | D loss: 1.416572\n",
            "Step 3503: G loss: 36.192451 | D loss: 1.421141\n",
            "Step 3504: G loss: 37.598347 | D loss: 1.416459\n",
            "Step 3505: G loss: 25.361645 | D loss: 1.417057\n",
            "Step 3506: G loss: 29.236258 | D loss: 1.416237\n",
            "Step 3507: G loss: 23.686348 | D loss: 1.414272\n",
            "Step 3508: G loss: 24.620144 | D loss: 1.411490\n",
            "Step 3509: G loss: 22.411997 | D loss: 1.411661\n",
            "Step 3510: G loss: 30.520008 | D loss: 1.416674\n",
            "Step 3511: G loss: 47.339344 | D loss: 1.414387\n",
            "Step 3512: G loss: 31.483490 | D loss: 1.416316\n",
            "Step 3513: G loss: 28.916071 | D loss: 1.415275\n",
            "Step 3514: G loss: 28.009190 | D loss: 1.423880\n",
            "Step 3515: G loss: 30.566429 | D loss: 1.412174\n",
            "Step 3516: G loss: 35.966328 | D loss: 1.412628\n",
            "Step 3517: G loss: 24.998020 | D loss: 1.417568\n",
            "Step 3518: G loss: 22.936193 | D loss: 1.426229\n",
            "Step 3519: G loss: 45.833107 | D loss: 1.411915\n",
            "Step 3520: G loss: 24.208147 | D loss: 1.420204\n",
            "Step 3521: G loss: 28.637566 | D loss: 1.416088\n",
            "Step 3522: G loss: 30.875818 | D loss: 1.420575\n",
            "Step 3523: G loss: 21.918512 | D loss: 1.411196\n",
            "Step 3524: G loss: 20.882650 | D loss: 1.415846\n",
            "Step 3525: G loss: 27.527145 | D loss: 1.418796\n",
            "Step 3526: G loss: 28.928522 | D loss: 1.417007\n",
            "Step 3527: G loss: 41.046261 | D loss: 1.421352\n",
            "Step 3528: G loss: 30.955078 | D loss: 1.414798\n",
            "Step 3529: G loss: 38.843601 | D loss: 1.411776\n",
            "Step 3530: G loss: 22.116144 | D loss: 1.411245\n",
            "Step 3531: G loss: 31.589657 | D loss: 1.411232\n",
            "Step 3532: G loss: 25.052197 | D loss: 1.424723\n",
            "Step 3533: G loss: 35.771893 | D loss: 1.420623\n",
            "Step 3534: G loss: 38.903259 | D loss: 1.411163\n",
            "Step 3535: G loss: 34.318523 | D loss: 1.416442\n",
            "Step 3536: G loss: 24.271294 | D loss: 1.412258\n",
            "Step 3537: G loss: 21.821447 | D loss: 1.417633\n",
            "Step 3538: G loss: 28.593374 | D loss: 1.411119\n",
            "Step 3539: G loss: 26.690905 | D loss: 1.412367\n",
            "Step 3540: G loss: 26.104689 | D loss: 1.411092\n",
            "Step 3541: G loss: 30.778568 | D loss: 1.421886\n",
            "Step 3542: G loss: 31.884666 | D loss: 1.417741\n",
            "Step 3543: G loss: 33.035946 | D loss: 1.422683\n",
            "Step 3544: G loss: 36.576752 | D loss: 1.411135\n",
            "Step 3545: G loss: 33.802021 | D loss: 1.419865\n",
            "Step 3546: G loss: 20.783363 | D loss: 1.418578\n",
            "Step 3547: G loss: 36.473545 | D loss: 1.413133\n",
            "Step 3548: G loss: 39.145210 | D loss: 1.418829\n",
            "Step 3549: G loss: 27.924385 | D loss: 1.423317\n",
            "Step 3550: G loss: 26.255049 | D loss: 1.414369\n",
            "Step 3551: G loss: 34.697414 | D loss: 1.421284\n",
            "Step 3552: G loss: 26.431215 | D loss: 1.411364\n",
            "Step 3553: G loss: 25.786314 | D loss: 1.411471\n",
            "Step 3554: G loss: 22.239655 | D loss: 1.412276\n",
            "Step 3555: G loss: 20.467587 | D loss: 1.411448\n",
            "Step 3556: G loss: 25.794773 | D loss: 1.411041\n",
            "Step 3557: G loss: 32.064899 | D loss: 1.410830\n",
            "Step 3558: G loss: 26.362942 | D loss: 1.413333\n",
            "Step 3559: G loss: 28.371458 | D loss: 1.410899\n",
            "Step 3560: G loss: 37.871223 | D loss: 1.411918\n",
            "Step 3561: G loss: 27.860216 | D loss: 1.410801\n",
            "Step 3562: G loss: 37.420071 | D loss: 1.413233\n",
            "Step 3563: G loss: 30.443531 | D loss: 1.418080\n",
            "Step 3564: G loss: 36.603054 | D loss: 1.425013\n",
            "Step 3565: G loss: 36.163479 | D loss: 1.419694\n",
            "Step 3566: G loss: 38.756516 | D loss: 1.427664\n",
            "Step 3567: G loss: 28.365858 | D loss: 1.424362\n",
            "Step 3568: G loss: 28.718184 | D loss: 1.434801\n",
            "Step 3569: G loss: 37.583115 | D loss: 1.414183\n",
            "Step 3570: G loss: 30.632725 | D loss: 1.416366\n",
            "Step 3571: G loss: 35.818733 | D loss: 1.423427\n",
            "Step 3572: G loss: 26.269207 | D loss: 1.425629\n",
            "Step 3573: G loss: 38.594406 | D loss: 1.417198\n",
            "Step 3574: G loss: 20.232908 | D loss: 1.418737\n",
            "Step 3575: G loss: 23.387852 | D loss: 1.411301\n",
            "Step 3576: G loss: 35.432701 | D loss: 1.417786\n",
            "Step 3577: G loss: 32.930084 | D loss: 1.420616\n",
            "Step 3578: G loss: 34.897789 | D loss: 1.420840\n",
            "Step 3579: G loss: 32.055775 | D loss: 1.419409\n",
            "Step 3580: G loss: 20.309776 | D loss: 1.417216\n",
            "Step 3581: G loss: 33.521378 | D loss: 1.410596\n",
            "Step 3582: G loss: 34.044018 | D loss: 1.413181\n",
            "Step 3583: G loss: 32.637428 | D loss: 1.418745\n",
            "Step 3584: G loss: 29.324778 | D loss: 1.416335\n",
            "Step 3585: G loss: 26.426477 | D loss: 1.415209\n",
            "Step 3586: G loss: 23.632492 | D loss: 1.421115\n",
            "Step 3587: G loss: 25.108850 | D loss: 1.411044\n",
            "Step 3588: G loss: 27.081169 | D loss: 1.419345\n",
            "Step 3589: G loss: 22.122032 | D loss: 1.410547\n",
            "Step 3590: G loss: 45.976379 | D loss: 1.419032\n",
            "Step 3591: G loss: 31.040836 | D loss: 1.421132\n",
            "Step 3592: G loss: 37.398079 | D loss: 1.418525\n",
            "Step 3593: G loss: 25.856188 | D loss: 1.420591\n",
            "Step 3594: G loss: 28.394793 | D loss: 1.410525\n",
            "Step 3595: G loss: 36.448490 | D loss: 1.418042\n",
            "Step 3596: G loss: 40.836422 | D loss: 1.424940\n",
            "Step 3597: G loss: 32.169613 | D loss: 1.427280\n",
            "Step 3598: G loss: 23.117481 | D loss: 1.414305\n",
            "Step 3599: G loss: 21.731575 | D loss: 1.412990\n",
            "Step 3600: G loss: 36.558891 | D loss: 1.411081\n",
            "Step 3601: G loss: 32.343094 | D loss: 1.420355\n",
            "Step 3602: G loss: 44.432503 | D loss: 1.410339\n",
            "Step 3603: G loss: 36.526272 | D loss: 1.411093\n",
            "Step 3604: G loss: 35.235661 | D loss: 1.410436\n",
            "Step 3605: G loss: 31.487282 | D loss: 1.410565\n",
            "Step 3606: G loss: 31.803785 | D loss: 1.410460\n",
            "Step 3607: G loss: 31.313866 | D loss: 1.416219\n",
            "Step 3608: G loss: 24.260740 | D loss: 1.413016\n",
            "Step 3609: G loss: 41.368420 | D loss: 1.414051\n",
            "Step 3610: G loss: 38.537212 | D loss: 1.414101\n",
            "Step 3611: G loss: 30.364214 | D loss: 1.411737\n",
            "Step 3612: G loss: 23.144855 | D loss: 1.415706\n",
            "Step 3613: G loss: 19.447605 | D loss: 1.410617\n",
            "Step 3614: G loss: 38.248943 | D loss: 1.410835\n",
            "Step 3615: G loss: 31.052017 | D loss: 1.419591\n",
            "Step 3616: G loss: 51.946270 | D loss: 1.413730\n",
            "Step 3617: G loss: 22.481842 | D loss: 1.423171\n",
            "Step 3618: G loss: 26.770519 | D loss: 1.410439\n",
            "Step 3619: G loss: 30.637760 | D loss: 1.426826\n",
            "Step 3620: G loss: 25.053009 | D loss: 1.413863\n",
            "Step 3621: G loss: 27.094612 | D loss: 1.416831\n",
            "Step 3622: G loss: 32.302990 | D loss: 1.411401\n",
            "Step 3623: G loss: 25.662500 | D loss: 1.416939\n",
            "Step 3624: G loss: 27.515301 | D loss: 1.417313\n",
            "Step 3625: G loss: 28.203249 | D loss: 1.414611\n",
            "Step 3626: G loss: 17.390448 | D loss: 1.410974\n",
            "Step 3627: G loss: 23.982780 | D loss: 1.418856\n",
            "Step 3628: G loss: 36.713070 | D loss: 1.416847\n",
            "Step 3629: G loss: 26.669184 | D loss: 1.412562\n",
            "Step 3630: G loss: 28.033672 | D loss: 1.412077\n",
            "Step 3631: G loss: 42.603725 | D loss: 1.414325\n",
            "Step 3632: G loss: 29.291595 | D loss: 1.411081\n",
            "Step 3633: G loss: 22.833143 | D loss: 1.412370\n",
            "Step 3634: G loss: 28.423687 | D loss: 1.414699\n",
            "Step 3635: G loss: 29.515009 | D loss: 1.413047\n",
            "Step 3636: G loss: 26.168564 | D loss: 1.411401\n",
            "Step 3637: G loss: 24.065666 | D loss: 1.419044\n",
            "Step 3638: G loss: 24.650463 | D loss: 1.421851\n",
            "Step 3639: G loss: 22.241880 | D loss: 1.414099\n",
            "Step 3640: G loss: 28.743235 | D loss: 1.418799\n",
            "Step 3641: G loss: 27.824484 | D loss: 1.411310\n",
            "Step 3642: G loss: 20.743288 | D loss: 1.414353\n",
            "Step 3643: G loss: 24.299986 | D loss: 1.415808\n",
            "Step 3644: G loss: 38.329082 | D loss: 1.410536\n",
            "Step 3645: G loss: 23.226635 | D loss: 1.410989\n",
            "Step 3646: G loss: 25.922752 | D loss: 1.417201\n",
            "Step 3647: G loss: 25.149063 | D loss: 1.416633\n",
            "Step 3648: G loss: 32.264393 | D loss: 1.421283\n",
            "Step 3649: G loss: 27.118744 | D loss: 1.415369\n",
            "Step 3650: G loss: 30.698774 | D loss: 1.414083\n",
            "Step 3651: G loss: 25.540915 | D loss: 1.417427\n",
            "Step 3652: G loss: 21.043726 | D loss: 1.413737\n",
            "Step 3653: G loss: 26.281078 | D loss: 1.417741\n",
            "Step 3654: G loss: 28.839031 | D loss: 1.411549\n",
            "Step 3655: G loss: 42.302650 | D loss: 1.409835\n",
            "Step 3656: G loss: 18.735022 | D loss: 1.410183\n",
            "Step 3657: G loss: 27.775391 | D loss: 1.415484\n",
            "Step 3658: G loss: 44.802353 | D loss: 1.410510\n",
            "Step 3659: G loss: 23.609909 | D loss: 1.411849\n",
            "Step 3660: G loss: 31.999706 | D loss: 1.409857\n",
            "Step 3661: G loss: 38.437046 | D loss: 1.411067\n",
            "Step 3662: G loss: 26.277494 | D loss: 1.410315\n",
            "Step 3663: G loss: 36.008610 | D loss: 1.413537\n",
            "Step 3664: G loss: 31.121756 | D loss: 1.415706\n",
            "Step 3665: G loss: 26.208204 | D loss: 1.409800\n",
            "Step 3666: G loss: 22.299057 | D loss: 1.413597\n",
            "Step 3667: G loss: 34.198170 | D loss: 1.413109\n",
            "Step 3668: G loss: 27.390079 | D loss: 1.413162\n",
            "Step 3669: G loss: 30.211714 | D loss: 1.411392\n",
            "Step 3670: G loss: 44.903950 | D loss: 1.413657\n",
            "Step 3671: G loss: 24.476801 | D loss: 1.417060\n",
            "Step 3672: G loss: 24.396276 | D loss: 1.411033\n",
            "Step 3673: G loss: 43.518669 | D loss: 1.413869\n",
            "Step 3674: G loss: 28.283220 | D loss: 1.410728\n",
            "Step 3675: G loss: 38.116650 | D loss: 1.412611\n",
            "Step 3676: G loss: 26.830984 | D loss: 1.410324\n",
            "Step 3677: G loss: 29.690685 | D loss: 1.421065\n",
            "Step 3678: G loss: 27.644072 | D loss: 1.415553\n",
            "Step 3679: G loss: 25.891289 | D loss: 1.415652\n",
            "Step 3680: G loss: 20.310371 | D loss: 1.415622\n",
            "Step 3681: G loss: 35.970596 | D loss: 1.422330\n",
            "Step 3682: G loss: 36.564667 | D loss: 1.422592\n",
            "Step 3683: G loss: 20.245699 | D loss: 1.411025\n",
            "Step 3684: G loss: 34.003174 | D loss: 1.413141\n",
            "Step 3685: G loss: 26.319557 | D loss: 1.410122\n",
            "Step 3686: G loss: 33.026482 | D loss: 1.415531\n",
            "Step 3687: G loss: 25.599022 | D loss: 1.409688\n",
            "Step 3688: G loss: 22.349878 | D loss: 1.419468\n",
            "Step 3689: G loss: 28.172724 | D loss: 1.414806\n",
            "Step 3690: G loss: 28.519609 | D loss: 1.416265\n",
            "Step 3691: G loss: 25.426310 | D loss: 1.423854\n",
            "Step 3692: G loss: 38.845097 | D loss: 1.416432\n",
            "Step 3693: G loss: 32.011868 | D loss: 1.412800\n",
            "Step 3694: G loss: 30.545675 | D loss: 1.409818\n",
            "Step 3695: G loss: 26.596642 | D loss: 1.409439\n",
            "Step 3696: G loss: 19.709787 | D loss: 1.413604\n",
            "Step 3697: G loss: 19.207706 | D loss: 1.418852\n",
            "Step 3698: G loss: 24.233662 | D loss: 1.422087\n",
            "Step 3699: G loss: 39.299210 | D loss: 1.412238\n",
            "Step 3700: G loss: 33.459377 | D loss: 1.410252\n",
            "Step 3701: G loss: 31.901875 | D loss: 1.410487\n",
            "Step 3702: G loss: 28.472240 | D loss: 1.421283\n",
            "Step 3703: G loss: 31.992085 | D loss: 1.415656\n",
            "Step 3704: G loss: 46.145386 | D loss: 1.417339\n",
            "Step 3705: G loss: 36.497356 | D loss: 1.418994\n",
            "Step 3706: G loss: 28.851818 | D loss: 1.411787\n",
            "Step 3707: G loss: 27.111347 | D loss: 1.417219\n",
            "Step 3708: G loss: 27.850986 | D loss: 1.415625\n",
            "Step 3709: G loss: 37.746708 | D loss: 1.412642\n",
            "Step 3710: G loss: 40.332348 | D loss: 1.409803\n",
            "Step 3711: G loss: 29.939087 | D loss: 1.411487\n",
            "Step 3712: G loss: 24.304251 | D loss: 1.415379\n",
            "Step 3713: G loss: 30.684237 | D loss: 1.421261\n",
            "Step 3714: G loss: 36.354099 | D loss: 1.412977\n",
            "Step 3715: G loss: 24.678198 | D loss: 1.409992\n",
            "Step 3716: G loss: 30.140757 | D loss: 1.409906\n",
            "Step 3717: G loss: 39.016468 | D loss: 1.410413\n",
            "Step 3718: G loss: 20.192665 | D loss: 1.424908\n",
            "Step 3719: G loss: 31.110613 | D loss: 1.410224\n",
            "Step 3720: G loss: 23.529011 | D loss: 1.413061\n",
            "Step 3721: G loss: 32.328499 | D loss: 1.413934\n",
            "Step 3722: G loss: 27.920975 | D loss: 1.414854\n",
            "Step 3723: G loss: 25.464874 | D loss: 1.421021\n",
            "Step 3724: G loss: 22.142500 | D loss: 1.409356\n",
            "Step 3725: G loss: 23.754629 | D loss: 1.414276\n",
            "Step 3726: G loss: 28.744005 | D loss: 1.412845\n",
            "Step 3727: G loss: 24.301712 | D loss: 1.415767\n",
            "Step 3728: G loss: 29.455399 | D loss: 1.414539\n",
            "Step 3729: G loss: 35.855106 | D loss: 1.409240\n",
            "Step 3730: G loss: 19.196030 | D loss: 1.415321\n",
            "Step 3731: G loss: 34.268806 | D loss: 1.416520\n",
            "Step 3732: G loss: 36.043144 | D loss: 1.409214\n",
            "Step 3733: G loss: 27.736570 | D loss: 1.409469\n",
            "Step 3734: G loss: 27.174519 | D loss: 1.414516\n",
            "Step 3735: G loss: 29.395132 | D loss: 1.409465\n",
            "Step 3736: G loss: 26.771843 | D loss: 1.409413\n",
            "Step 3737: G loss: 33.075436 | D loss: 1.412580\n",
            "Step 3738: G loss: 30.923040 | D loss: 1.410053\n",
            "Step 3739: G loss: 28.780413 | D loss: 1.416117\n",
            "Step 3740: G loss: 22.894241 | D loss: 1.420779\n",
            "Step 3741: G loss: 24.179441 | D loss: 1.413585\n",
            "Step 3742: G loss: 40.858719 | D loss: 1.410297\n",
            "Step 3743: G loss: 23.856730 | D loss: 1.409566\n",
            "Step 3744: G loss: 40.067142 | D loss: 1.409484\n",
            "Step 3745: G loss: 22.963383 | D loss: 1.409155\n",
            "Step 3746: G loss: 30.020979 | D loss: 1.409686\n",
            "Step 3747: G loss: 20.338226 | D loss: 1.419667\n",
            "Step 3748: G loss: 25.569370 | D loss: 1.412966\n",
            "Step 3749: G loss: 27.158607 | D loss: 1.413847\n",
            "Step 3750: G loss: 26.368553 | D loss: 1.415721\n",
            "Step 3751: G loss: 31.318443 | D loss: 1.412128\n",
            "Step 3752: G loss: 30.199112 | D loss: 1.410384\n",
            "Step 3753: G loss: 26.768446 | D loss: 1.409069\n",
            "Step 3754: G loss: 22.768366 | D loss: 1.409646\n",
            "Step 3755: G loss: 29.375650 | D loss: 1.420384\n",
            "Step 3756: G loss: 36.039555 | D loss: 1.413682\n",
            "Step 3757: G loss: 22.589739 | D loss: 1.415180\n",
            "Step 3758: G loss: 35.265148 | D loss: 1.408911\n",
            "Step 3759: G loss: 28.248989 | D loss: 1.409190\n",
            "Step 3760: G loss: 37.241318 | D loss: 1.409366\n",
            "Step 3761: G loss: 26.759241 | D loss: 1.409474\n",
            "Step 3762: G loss: 36.120876 | D loss: 1.414050\n",
            "Step 3763: G loss: 40.032681 | D loss: 1.408879\n",
            "Step 3764: G loss: 28.444885 | D loss: 1.411163\n",
            "Step 3765: G loss: 31.274593 | D loss: 1.411182\n",
            "Step 3766: G loss: 37.097858 | D loss: 1.414654\n",
            "Step 3767: G loss: 22.739727 | D loss: 1.413378\n",
            "Step 3768: G loss: 29.141146 | D loss: 1.410203\n",
            "Step 3769: G loss: 28.782944 | D loss: 1.408713\n",
            "Step 3770: G loss: 32.268539 | D loss: 1.413644\n",
            "Step 3771: G loss: 26.670509 | D loss: 1.413494\n",
            "Step 3772: G loss: 30.398411 | D loss: 1.409510\n",
            "Step 3773: G loss: 35.903542 | D loss: 1.412629\n",
            "Step 3774: G loss: 24.215155 | D loss: 1.416687\n",
            "Step 3775: G loss: 45.580063 | D loss: 1.408985\n",
            "Step 3776: G loss: 26.894442 | D loss: 1.419186\n",
            "Step 3777: G loss: 23.985538 | D loss: 1.412000\n",
            "Step 3778: G loss: 29.931692 | D loss: 1.409186\n",
            "Step 3779: G loss: 22.430758 | D loss: 1.428086\n",
            "Step 3780: G loss: 25.187164 | D loss: 1.411310\n",
            "Step 3781: G loss: 26.122715 | D loss: 1.409038\n",
            "Step 3782: G loss: 31.608810 | D loss: 1.411785\n",
            "Step 3783: G loss: 24.151659 | D loss: 1.423493\n",
            "Step 3784: G loss: 24.827566 | D loss: 1.408918\n",
            "Step 3785: G loss: 18.994347 | D loss: 1.408628\n",
            "Step 3786: G loss: 27.424255 | D loss: 1.412662\n",
            "Step 3787: G loss: 30.190847 | D loss: 1.414849\n",
            "Step 3788: G loss: 25.308567 | D loss: 1.410919\n",
            "Step 3789: G loss: 26.098516 | D loss: 1.409786\n",
            "Step 3790: G loss: 25.819777 | D loss: 1.410504\n",
            "Step 3791: G loss: 20.713598 | D loss: 1.408518\n",
            "Step 3792: G loss: 21.994110 | D loss: 1.415012\n",
            "Step 3793: G loss: 27.727695 | D loss: 1.417418\n",
            "Step 3794: G loss: 35.977684 | D loss: 1.414327\n",
            "Step 3795: G loss: 24.091625 | D loss: 1.417192\n",
            "Step 3796: G loss: 34.751469 | D loss: 1.413970\n",
            "Step 3797: G loss: 32.280159 | D loss: 1.413706\n",
            "Step 3798: G loss: 30.968821 | D loss: 1.409289\n",
            "Step 3799: G loss: 28.445730 | D loss: 1.409543\n",
            "Step 3800: G loss: 25.766788 | D loss: 1.412631\n",
            "Step 3801: G loss: 28.199961 | D loss: 1.414346\n",
            "Step 3802: G loss: 25.591743 | D loss: 1.418317\n",
            "Step 3803: G loss: 20.011654 | D loss: 1.422231\n",
            "Step 3804: G loss: 21.355732 | D loss: 1.411373\n",
            "Step 3805: G loss: 39.867092 | D loss: 1.414932\n",
            "Step 3806: G loss: 31.575657 | D loss: 1.413012\n",
            "Step 3807: G loss: 19.493065 | D loss: 1.413551\n",
            "Step 3808: G loss: 17.443016 | D loss: 1.413358\n",
            "Step 3809: G loss: 32.396606 | D loss: 1.408347\n",
            "Step 3810: G loss: 22.811249 | D loss: 1.408440\n",
            "Step 3811: G loss: 34.214249 | D loss: 1.415271\n",
            "Step 3812: G loss: 24.018248 | D loss: 1.408593\n",
            "Step 3813: G loss: 25.531294 | D loss: 1.427110\n",
            "Step 3814: G loss: 23.804741 | D loss: 1.415517\n",
            "Step 3815: G loss: 39.779293 | D loss: 1.409233\n",
            "Step 3816: G loss: 30.566513 | D loss: 1.413603\n",
            "Step 3817: G loss: 38.569427 | D loss: 1.413908\n",
            "Step 3818: G loss: 28.297291 | D loss: 1.413083\n",
            "Step 3819: G loss: 28.110229 | D loss: 1.413809\n",
            "Step 3820: G loss: 29.028925 | D loss: 1.408730\n",
            "Step 3821: G loss: 33.598305 | D loss: 1.423223\n",
            "Step 3822: G loss: 37.965672 | D loss: 1.410658\n",
            "Step 3823: G loss: 24.009274 | D loss: 1.412382\n",
            "Step 3824: G loss: 28.894161 | D loss: 1.411234\n",
            "Step 3825: G loss: 25.590405 | D loss: 1.409212\n",
            "Step 3826: G loss: 23.543951 | D loss: 1.411551\n",
            "Step 3827: G loss: 34.346561 | D loss: 1.408135\n",
            "Step 3828: G loss: 22.715969 | D loss: 1.412773\n",
            "Step 3829: G loss: 30.932295 | D loss: 1.408504\n",
            "Step 3830: G loss: 23.478807 | D loss: 1.408542\n",
            "Step 3831: G loss: 28.584517 | D loss: 1.414006\n",
            "Step 3832: G loss: 25.304657 | D loss: 1.408103\n",
            "Step 3833: G loss: 25.740686 | D loss: 1.408563\n",
            "Step 3834: G loss: 30.431925 | D loss: 1.415018\n",
            "Step 3835: G loss: 24.310860 | D loss: 1.413759\n",
            "Step 3836: G loss: 27.301178 | D loss: 1.413654\n",
            "Step 3837: G loss: 40.693439 | D loss: 1.412926\n",
            "Step 3838: G loss: 31.520658 | D loss: 1.412455\n",
            "Step 3839: G loss: 27.945295 | D loss: 1.415678\n",
            "Step 3840: G loss: 39.686291 | D loss: 1.408279\n",
            "Step 3841: G loss: 27.630562 | D loss: 1.408575\n",
            "Step 3842: G loss: 34.989368 | D loss: 1.416963\n",
            "Step 3843: G loss: 31.203182 | D loss: 1.419726\n",
            "Step 3844: G loss: 20.846556 | D loss: 1.409156\n",
            "Step 3845: G loss: 22.950558 | D loss: 1.412647\n",
            "Step 3846: G loss: 21.207209 | D loss: 1.408019\n",
            "Step 3847: G loss: 27.335293 | D loss: 1.408271\n",
            "Step 3848: G loss: 23.573799 | D loss: 1.413118\n",
            "Step 3849: G loss: 27.391424 | D loss: 1.407935\n",
            "Step 3850: G loss: 34.337914 | D loss: 1.408555\n",
            "Step 3851: G loss: 31.123602 | D loss: 1.414286\n",
            "Step 3852: G loss: 28.905535 | D loss: 1.408974\n",
            "Step 3853: G loss: 34.776505 | D loss: 1.407848\n",
            "Step 3854: G loss: 26.006084 | D loss: 1.414915\n",
            "Step 3855: G loss: 28.828932 | D loss: 1.407970\n",
            "Step 3856: G loss: 34.923077 | D loss: 1.408051\n",
            "Step 3857: G loss: 21.156733 | D loss: 1.411128\n",
            "Step 3858: G loss: 26.857424 | D loss: 1.413167\n",
            "Step 3859: G loss: 44.877178 | D loss: 1.408060\n",
            "Step 3860: G loss: 21.748838 | D loss: 1.409299\n",
            "Step 3861: G loss: 32.882618 | D loss: 1.407892\n",
            "Step 3862: G loss: 24.771044 | D loss: 1.412031\n",
            "Step 3863: G loss: 30.964464 | D loss: 1.408088\n",
            "Step 3864: G loss: 41.578743 | D loss: 1.413206\n",
            "Step 3865: G loss: 23.904633 | D loss: 1.413849\n",
            "Step 3866: G loss: 35.186108 | D loss: 1.414653\n",
            "Step 3867: G loss: 31.281963 | D loss: 1.416859\n",
            "Step 3868: G loss: 28.564997 | D loss: 1.410781\n",
            "Step 3869: G loss: 28.287682 | D loss: 1.416451\n",
            "Step 3870: G loss: 27.122179 | D loss: 1.409739\n",
            "Step 3871: G loss: 31.374205 | D loss: 1.407912\n",
            "Step 3872: G loss: 44.038364 | D loss: 1.409970\n",
            "Step 3873: G loss: 30.877203 | D loss: 1.408885\n",
            "Step 3874: G loss: 37.534267 | D loss: 1.407771\n",
            "Step 3875: G loss: 34.301670 | D loss: 1.407805\n",
            "Step 3876: G loss: 24.033266 | D loss: 1.413171\n",
            "Step 3877: G loss: 28.339584 | D loss: 1.414105\n",
            "Step 3878: G loss: 28.674477 | D loss: 1.415328\n",
            "Step 3879: G loss: 31.475248 | D loss: 1.408578\n",
            "Step 3880: G loss: 24.877127 | D loss: 1.412360\n",
            "Step 3881: G loss: 34.765987 | D loss: 1.411257\n",
            "Step 3882: G loss: 34.520660 | D loss: 1.410289\n",
            "Step 3883: G loss: 23.670433 | D loss: 1.409291\n",
            "Step 3884: G loss: 27.736750 | D loss: 1.409749\n",
            "Step 3885: G loss: 23.147638 | D loss: 1.408664\n",
            "Step 3886: G loss: 25.189144 | D loss: 1.407661\n",
            "Step 3887: G loss: 21.448437 | D loss: 1.407624\n",
            "Step 3888: G loss: 30.256220 | D loss: 1.409098\n",
            "Step 3889: G loss: 46.367104 | D loss: 1.412489\n",
            "Step 3890: G loss: 30.482805 | D loss: 1.410207\n",
            "Step 3891: G loss: 28.832804 | D loss: 1.408518\n",
            "Step 3892: G loss: 27.817696 | D loss: 1.422017\n",
            "Step 3893: G loss: 29.269583 | D loss: 1.408626\n",
            "Step 3894: G loss: 33.719028 | D loss: 1.409359\n",
            "Step 3895: G loss: 24.190638 | D loss: 1.412302\n",
            "Step 3896: G loss: 23.915020 | D loss: 1.417129\n",
            "Step 3897: G loss: 41.949699 | D loss: 1.409229\n",
            "Step 3898: G loss: 24.328466 | D loss: 1.413229\n",
            "Step 3899: G loss: 25.891129 | D loss: 1.408696\n",
            "Step 3900: G loss: 31.553909 | D loss: 1.410515\n",
            "Step 3901: G loss: 21.719610 | D loss: 1.407532\n",
            "Step 3902: G loss: 19.957348 | D loss: 1.411039\n",
            "Step 3903: G loss: 25.806250 | D loss: 1.414856\n",
            "Step 3904: G loss: 27.554817 | D loss: 1.414654\n",
            "Step 3905: G loss: 39.828197 | D loss: 1.412872\n",
            "Step 3906: G loss: 30.378462 | D loss: 1.409419\n",
            "Step 3907: G loss: 40.021275 | D loss: 1.409858\n",
            "Step 3908: G loss: 18.944889 | D loss: 1.407561\n",
            "Step 3909: G loss: 31.142382 | D loss: 1.407527\n",
            "Step 3910: G loss: 24.593163 | D loss: 1.411874\n",
            "Step 3911: G loss: 35.009899 | D loss: 1.415589\n",
            "Step 3912: G loss: 38.400482 | D loss: 1.407320\n",
            "Step 3913: G loss: 33.798058 | D loss: 1.411194\n",
            "Step 3914: G loss: 21.137724 | D loss: 1.407891\n",
            "Step 3915: G loss: 22.828892 | D loss: 1.411170\n",
            "Step 3916: G loss: 28.197258 | D loss: 1.407367\n",
            "Step 3917: G loss: 26.543558 | D loss: 1.411313\n",
            "Step 3918: G loss: 26.298153 | D loss: 1.407297\n",
            "Step 3919: G loss: 29.624290 | D loss: 1.416080\n",
            "Step 3920: G loss: 31.434837 | D loss: 1.412011\n",
            "Step 3921: G loss: 31.639713 | D loss: 1.418329\n",
            "Step 3922: G loss: 37.296143 | D loss: 1.407412\n",
            "Step 3923: G loss: 32.896229 | D loss: 1.413826\n",
            "Step 3924: G loss: 19.635830 | D loss: 1.411830\n",
            "Step 3925: G loss: 34.450218 | D loss: 1.411425\n",
            "Step 3926: G loss: 38.688244 | D loss: 1.412848\n",
            "Step 3927: G loss: 28.020159 | D loss: 1.413183\n",
            "Step 3928: G loss: 25.591721 | D loss: 1.409763\n",
            "Step 3929: G loss: 35.488728 | D loss: 1.413900\n",
            "Step 3930: G loss: 26.060289 | D loss: 1.407480\n",
            "Step 3931: G loss: 26.589298 | D loss: 1.407430\n",
            "Step 3932: G loss: 22.254854 | D loss: 1.408411\n",
            "Step 3933: G loss: 20.719307 | D loss: 1.407570\n",
            "Step 3934: G loss: 26.122284 | D loss: 1.407157\n",
            "Step 3935: G loss: 31.739479 | D loss: 1.407081\n",
            "Step 3936: G loss: 25.211565 | D loss: 1.407987\n",
            "Step 3937: G loss: 27.466621 | D loss: 1.407091\n",
            "Step 3938: G loss: 36.373962 | D loss: 1.408051\n",
            "Step 3939: G loss: 27.587505 | D loss: 1.407070\n",
            "Step 3940: G loss: 36.253063 | D loss: 1.407960\n",
            "Step 3941: G loss: 30.443878 | D loss: 1.412959\n",
            "Step 3942: G loss: 36.486839 | D loss: 1.410690\n",
            "Step 3943: G loss: 35.782101 | D loss: 1.411799\n",
            "Step 3944: G loss: 37.176800 | D loss: 1.419901\n",
            "Step 3945: G loss: 27.034702 | D loss: 1.413550\n",
            "Step 3946: G loss: 32.872482 | D loss: 1.419808\n",
            "Step 3947: G loss: 35.505070 | D loss: 1.410187\n",
            "Step 3948: G loss: 28.463184 | D loss: 1.410831\n",
            "Step 3949: G loss: 35.365925 | D loss: 1.414323\n",
            "Step 3950: G loss: 24.150719 | D loss: 1.417888\n",
            "Step 3951: G loss: 38.425377 | D loss: 1.411144\n",
            "Step 3952: G loss: 19.456860 | D loss: 1.412585\n",
            "Step 3953: G loss: 23.005234 | D loss: 1.407227\n",
            "Step 3954: G loss: 32.869312 | D loss: 1.412500\n",
            "Step 3955: G loss: 32.352322 | D loss: 1.414853\n",
            "Step 3956: G loss: 35.686611 | D loss: 1.414193\n",
            "Step 3957: G loss: 31.747110 | D loss: 1.411981\n",
            "Step 3958: G loss: 20.477631 | D loss: 1.408543\n",
            "Step 3959: G loss: 32.738575 | D loss: 1.406850\n",
            "Step 3960: G loss: 33.368587 | D loss: 1.407410\n",
            "Step 3961: G loss: 31.031404 | D loss: 1.412898\n",
            "Step 3962: G loss: 29.495567 | D loss: 1.410669\n",
            "Step 3963: G loss: 26.521881 | D loss: 1.409266\n",
            "Step 3964: G loss: 23.844511 | D loss: 1.414706\n",
            "Step 3965: G loss: 25.713564 | D loss: 1.407232\n",
            "Step 3966: G loss: 24.926689 | D loss: 1.411856\n",
            "Step 3967: G loss: 21.820635 | D loss: 1.406831\n",
            "Step 3968: G loss: 44.896832 | D loss: 1.413751\n",
            "Step 3969: G loss: 28.772305 | D loss: 1.414492\n",
            "Step 3970: G loss: 35.399818 | D loss: 1.411125\n",
            "Step 3971: G loss: 24.993391 | D loss: 1.413821\n",
            "Step 3972: G loss: 29.943605 | D loss: 1.406785\n",
            "Step 3973: G loss: 35.105595 | D loss: 1.410563\n",
            "Step 3974: G loss: 40.518566 | D loss: 1.416011\n",
            "Step 3975: G loss: 31.079321 | D loss: 1.414321\n",
            "Step 3976: G loss: 22.835215 | D loss: 1.411056\n",
            "Step 3977: G loss: 18.967804 | D loss: 1.407371\n",
            "Step 3978: G loss: 35.576717 | D loss: 1.407467\n",
            "Step 3979: G loss: 31.601185 | D loss: 1.413633\n",
            "Step 3980: G loss: 43.464550 | D loss: 1.406575\n",
            "Step 3981: G loss: 36.799782 | D loss: 1.409710\n",
            "Step 3982: G loss: 34.360126 | D loss: 1.406849\n",
            "Step 3983: G loss: 26.740921 | D loss: 1.406932\n",
            "Step 3984: G loss: 29.523657 | D loss: 1.407037\n",
            "Step 3985: G loss: 29.454334 | D loss: 1.409852\n",
            "Step 3986: G loss: 23.817070 | D loss: 1.407714\n",
            "Step 3987: G loss: 42.120888 | D loss: 1.409592\n",
            "Step 3988: G loss: 38.045349 | D loss: 1.410349\n",
            "Step 3989: G loss: 30.523849 | D loss: 1.407616\n",
            "Step 3990: G loss: 23.890301 | D loss: 1.409375\n",
            "Step 3991: G loss: 18.376286 | D loss: 1.406639\n",
            "Step 3992: G loss: 36.323761 | D loss: 1.407552\n",
            "Step 3993: G loss: 30.172493 | D loss: 1.407600\n",
            "Step 3994: G loss: 52.480000 | D loss: 1.408614\n",
            "Step 3995: G loss: 23.527985 | D loss: 1.408952\n",
            "Step 3996: G loss: 27.225702 | D loss: 1.406477\n",
            "Step 3997: G loss: 28.434359 | D loss: 1.415039\n",
            "Step 3998: G loss: 23.789537 | D loss: 1.412782\n",
            "Step 3999: G loss: 26.961781 | D loss: 1.410065\n",
            "Step 4000: G loss: 30.609306 | D loss: 1.406980\n",
            "Step 4001: G loss: 24.760626 | D loss: 1.411599\n",
            "Step 4002: G loss: 27.716320 | D loss: 1.414469\n",
            "Step 4003: G loss: 28.045635 | D loss: 1.413516\n",
            "Step 4004: G loss: 16.906700 | D loss: 1.406514\n",
            "Step 4005: G loss: 23.276991 | D loss: 1.412600\n",
            "Step 4006: G loss: 36.153008 | D loss: 1.410227\n",
            "Step 4007: G loss: 25.533785 | D loss: 1.406735\n",
            "Step 4008: G loss: 27.361530 | D loss: 1.408223\n",
            "Step 4009: G loss: 40.672165 | D loss: 1.408548\n",
            "Step 4010: G loss: 27.366936 | D loss: 1.407300\n",
            "Step 4011: G loss: 23.279762 | D loss: 1.408358\n",
            "Step 4012: G loss: 25.577763 | D loss: 1.410498\n",
            "Step 4013: G loss: 29.745266 | D loss: 1.408317\n",
            "Step 4014: G loss: 25.198223 | D loss: 1.407368\n",
            "Step 4015: G loss: 23.017014 | D loss: 1.410302\n",
            "Step 4016: G loss: 24.179682 | D loss: 1.413003\n",
            "Step 4017: G loss: 21.348434 | D loss: 1.408930\n",
            "Step 4018: G loss: 27.810062 | D loss: 1.408904\n",
            "Step 4019: G loss: 26.823843 | D loss: 1.407284\n",
            "Step 4020: G loss: 19.303255 | D loss: 1.408075\n",
            "Step 4021: G loss: 23.716747 | D loss: 1.408989\n",
            "Step 4022: G loss: 36.841599 | D loss: 1.406467\n",
            "Step 4023: G loss: 23.461279 | D loss: 1.406906\n",
            "Step 4024: G loss: 24.649200 | D loss: 1.408336\n",
            "Step 4025: G loss: 23.778923 | D loss: 1.411136\n",
            "Step 4026: G loss: 31.440319 | D loss: 1.412454\n",
            "Step 4027: G loss: 26.389475 | D loss: 1.409204\n",
            "Step 4028: G loss: 29.212210 | D loss: 1.408269\n",
            "Step 4029: G loss: 25.941931 | D loss: 1.411355\n",
            "Step 4030: G loss: 21.115850 | D loss: 1.408621\n",
            "Step 4031: G loss: 25.588615 | D loss: 1.410294\n",
            "Step 4032: G loss: 27.182989 | D loss: 1.407138\n",
            "Step 4033: G loss: 40.094303 | D loss: 1.406082\n",
            "Step 4034: G loss: 18.576283 | D loss: 1.406372\n",
            "Step 4035: G loss: 23.992678 | D loss: 1.409579\n",
            "Step 4036: G loss: 44.404823 | D loss: 1.407905\n",
            "Step 4037: G loss: 23.083858 | D loss: 1.406847\n",
            "Step 4038: G loss: 30.717663 | D loss: 1.406033\n",
            "Step 4039: G loss: 38.695286 | D loss: 1.406835\n",
            "Step 4040: G loss: 25.812672 | D loss: 1.406274\n",
            "Step 4041: G loss: 35.431713 | D loss: 1.407523\n",
            "Step 4042: G loss: 28.569510 | D loss: 1.410860\n",
            "Step 4043: G loss: 25.104355 | D loss: 1.406002\n",
            "Step 4044: G loss: 21.589369 | D loss: 1.409622\n",
            "Step 4045: G loss: 34.926777 | D loss: 1.406760\n",
            "Step 4046: G loss: 25.608891 | D loss: 1.407897\n",
            "Step 4047: G loss: 30.058027 | D loss: 1.406367\n",
            "Step 4048: G loss: 43.814632 | D loss: 1.408040\n",
            "Step 4049: G loss: 23.468945 | D loss: 1.410870\n",
            "Step 4050: G loss: 21.527681 | D loss: 1.406085\n",
            "Step 4051: G loss: 41.610474 | D loss: 1.406897\n",
            "Step 4052: G loss: 28.720396 | D loss: 1.408959\n",
            "Step 4053: G loss: 37.401352 | D loss: 1.408224\n",
            "Step 4054: G loss: 25.446711 | D loss: 1.405955\n",
            "Step 4055: G loss: 29.470371 | D loss: 1.413077\n",
            "Step 4056: G loss: 26.894115 | D loss: 1.407439\n",
            "Step 4057: G loss: 24.527304 | D loss: 1.409198\n",
            "Step 4058: G loss: 20.226099 | D loss: 1.410065\n",
            "Step 4059: G loss: 35.876694 | D loss: 1.415815\n",
            "Step 4060: G loss: 36.106842 | D loss: 1.413103\n",
            "Step 4061: G loss: 20.821127 | D loss: 1.406920\n",
            "Step 4062: G loss: 31.598450 | D loss: 1.406969\n",
            "Step 4063: G loss: 23.616280 | D loss: 1.406923\n",
            "Step 4064: G loss: 30.337893 | D loss: 1.412692\n",
            "Step 4065: G loss: 26.704731 | D loss: 1.406164\n",
            "Step 4066: G loss: 22.315115 | D loss: 1.413940\n",
            "Step 4067: G loss: 27.329794 | D loss: 1.407290\n",
            "Step 4068: G loss: 27.315126 | D loss: 1.411418\n",
            "Step 4069: G loss: 24.983957 | D loss: 1.415651\n",
            "Step 4070: G loss: 38.627613 | D loss: 1.411194\n",
            "Step 4071: G loss: 31.454941 | D loss: 1.409697\n",
            "Step 4072: G loss: 29.963909 | D loss: 1.406658\n",
            "Step 4073: G loss: 25.880680 | D loss: 1.405686\n",
            "Step 4074: G loss: 19.812069 | D loss: 1.408717\n",
            "Step 4075: G loss: 19.508282 | D loss: 1.410928\n",
            "Step 4076: G loss: 24.040144 | D loss: 1.414673\n",
            "Step 4077: G loss: 38.543602 | D loss: 1.405730\n",
            "Step 4078: G loss: 32.251049 | D loss: 1.405798\n",
            "Step 4079: G loss: 30.899137 | D loss: 1.405733\n",
            "Step 4080: G loss: 26.842831 | D loss: 1.412369\n",
            "Step 4081: G loss: 29.684961 | D loss: 1.410443\n",
            "Step 4082: G loss: 45.855263 | D loss: 1.411376\n",
            "Step 4083: G loss: 35.514263 | D loss: 1.414991\n",
            "Step 4084: G loss: 29.516504 | D loss: 1.405704\n",
            "Step 4085: G loss: 24.777563 | D loss: 1.410951\n",
            "Step 4086: G loss: 26.947083 | D loss: 1.410594\n",
            "Step 4087: G loss: 35.681919 | D loss: 1.406023\n",
            "Step 4088: G loss: 37.184559 | D loss: 1.405650\n",
            "Step 4089: G loss: 29.994114 | D loss: 1.406940\n",
            "Step 4090: G loss: 22.903744 | D loss: 1.410283\n",
            "Step 4091: G loss: 31.203362 | D loss: 1.414196\n",
            "Step 4092: G loss: 35.520515 | D loss: 1.414880\n",
            "Step 4093: G loss: 23.014248 | D loss: 1.405931\n",
            "Step 4094: G loss: 30.276217 | D loss: 1.407003\n",
            "Step 4095: G loss: 34.586456 | D loss: 1.407226\n",
            "Step 4096: G loss: 20.851835 | D loss: 1.415765\n",
            "Step 4097: G loss: 28.111912 | D loss: 1.406981\n",
            "Step 4098: G loss: 24.258629 | D loss: 1.409383\n",
            "Step 4099: G loss: 31.652021 | D loss: 1.410517\n",
            "Step 4100: G loss: 26.187351 | D loss: 1.410041\n",
            "Step 4101: G loss: 23.743549 | D loss: 1.411026\n",
            "Step 4102: G loss: 21.320511 | D loss: 1.405555\n",
            "Step 4103: G loss: 21.784647 | D loss: 1.409725\n",
            "Step 4104: G loss: 28.523388 | D loss: 1.408966\n",
            "Step 4105: G loss: 22.027662 | D loss: 1.409637\n",
            "Step 4106: G loss: 30.327492 | D loss: 1.411716\n",
            "Step 4107: G loss: 35.127682 | D loss: 1.405400\n",
            "Step 4108: G loss: 20.746269 | D loss: 1.409476\n",
            "Step 4109: G loss: 34.714550 | D loss: 1.409395\n",
            "Step 4110: G loss: 34.809319 | D loss: 1.406392\n",
            "Step 4111: G loss: 26.973608 | D loss: 1.405300\n",
            "Step 4112: G loss: 25.022160 | D loss: 1.406172\n",
            "Step 4113: G loss: 27.726946 | D loss: 1.406097\n",
            "Step 4114: G loss: 27.307329 | D loss: 1.405277\n",
            "Step 4115: G loss: 33.276234 | D loss: 1.407040\n",
            "Step 4116: G loss: 27.913553 | D loss: 1.406506\n",
            "Step 4117: G loss: 28.254316 | D loss: 1.409486\n",
            "Step 4118: G loss: 23.233637 | D loss: 1.414057\n",
            "Step 4119: G loss: 23.092068 | D loss: 1.405615\n",
            "Step 4120: G loss: 40.891346 | D loss: 1.405542\n",
            "Step 4121: G loss: 23.813152 | D loss: 1.405786\n",
            "Step 4122: G loss: 39.347687 | D loss: 1.405808\n",
            "Step 4123: G loss: 21.643570 | D loss: 1.405197\n",
            "Step 4124: G loss: 27.757221 | D loss: 1.405227\n",
            "Step 4125: G loss: 21.403446 | D loss: 1.412332\n",
            "Step 4126: G loss: 25.922537 | D loss: 1.407404\n",
            "Step 4127: G loss: 26.056210 | D loss: 1.408402\n",
            "Step 4128: G loss: 25.186718 | D loss: 1.409482\n",
            "Step 4129: G loss: 30.960405 | D loss: 1.407533\n",
            "Step 4130: G loss: 28.235613 | D loss: 1.408333\n",
            "Step 4131: G loss: 26.660900 | D loss: 1.405477\n",
            "Step 4132: G loss: 22.422695 | D loss: 1.405490\n",
            "Step 4133: G loss: 29.695337 | D loss: 1.410511\n",
            "Step 4134: G loss: 36.210999 | D loss: 1.411236\n",
            "Step 4135: G loss: 20.248863 | D loss: 1.409942\n",
            "Step 4136: G loss: 34.721165 | D loss: 1.405177\n",
            "Step 4137: G loss: 25.583853 | D loss: 1.405780\n",
            "Step 4138: G loss: 34.530029 | D loss: 1.406637\n",
            "Step 4139: G loss: 24.751251 | D loss: 1.406100\n",
            "Step 4140: G loss: 35.649010 | D loss: 1.410176\n",
            "Step 4141: G loss: 40.199825 | D loss: 1.405145\n",
            "Step 4142: G loss: 25.058334 | D loss: 1.406919\n",
            "Step 4143: G loss: 30.767395 | D loss: 1.406366\n",
            "Step 4144: G loss: 34.703648 | D loss: 1.408780\n",
            "Step 4145: G loss: 21.403652 | D loss: 1.408903\n",
            "Step 4146: G loss: 28.381517 | D loss: 1.409880\n",
            "Step 4147: G loss: 28.728004 | D loss: 1.404937\n",
            "Step 4148: G loss: 32.204807 | D loss: 1.407581\n",
            "Step 4149: G loss: 26.084589 | D loss: 1.405559\n",
            "Step 4150: G loss: 29.735601 | D loss: 1.406195\n",
            "Step 4151: G loss: 34.893772 | D loss: 1.406605\n",
            "Step 4152: G loss: 23.035700 | D loss: 1.410295\n",
            "Step 4153: G loss: 45.075996 | D loss: 1.404984\n",
            "Step 4154: G loss: 25.922308 | D loss: 1.408487\n",
            "Step 4155: G loss: 23.582508 | D loss: 1.406968\n",
            "Step 4156: G loss: 29.475145 | D loss: 1.405433\n",
            "Step 4157: G loss: 22.168753 | D loss: 1.405936\n",
            "Step 4158: G loss: 24.231874 | D loss: 1.407822\n",
            "Step 4159: G loss: 25.581789 | D loss: 1.405439\n",
            "Step 4160: G loss: 30.574530 | D loss: 1.405707\n",
            "Step 4161: G loss: 23.943190 | D loss: 1.411546\n",
            "Step 4162: G loss: 23.867308 | D loss: 1.405829\n",
            "Step 4163: G loss: 19.804195 | D loss: 1.404868\n",
            "Step 4164: G loss: 26.888893 | D loss: 1.407533\n",
            "Step 4165: G loss: 30.399446 | D loss: 1.409072\n",
            "Step 4166: G loss: 23.725315 | D loss: 1.406495\n",
            "Step 4167: G loss: 24.170010 | D loss: 1.405682\n",
            "Step 4168: G loss: 24.248865 | D loss: 1.406363\n",
            "Step 4169: G loss: 22.371569 | D loss: 1.404836\n",
            "Step 4170: G loss: 22.276653 | D loss: 1.409713\n",
            "Step 4171: G loss: 28.201149 | D loss: 1.407637\n",
            "Step 4172: G loss: 35.712326 | D loss: 1.407581\n",
            "Step 4173: G loss: 29.783295 | D loss: 1.409303\n",
            "Step 4174: G loss: 34.595146 | D loss: 1.404833\n",
            "Step 4175: G loss: 32.013699 | D loss: 1.406107\n",
            "Step 4176: G loss: 32.249939 | D loss: 1.404652\n",
            "Step 4177: G loss: 28.075653 | D loss: 1.405262\n",
            "Step 4178: G loss: 26.009315 | D loss: 1.405348\n",
            "Step 4179: G loss: 27.361731 | D loss: 1.405886\n",
            "Step 4180: G loss: 25.225435 | D loss: 1.410429\n",
            "Step 4181: G loss: 20.206909 | D loss: 1.413139\n",
            "Step 4182: G loss: 19.093885 | D loss: 1.405509\n",
            "Step 4183: G loss: 36.983742 | D loss: 1.407907\n",
            "Step 4184: G loss: 32.153988 | D loss: 1.406814\n",
            "Step 4185: G loss: 19.136118 | D loss: 1.407033\n",
            "Step 4186: G loss: 16.308691 | D loss: 1.409867\n",
            "Step 4187: G loss: 31.916075 | D loss: 1.404991\n",
            "Step 4188: G loss: 22.291405 | D loss: 1.404840\n",
            "Step 4189: G loss: 33.437656 | D loss: 1.407369\n",
            "Step 4190: G loss: 21.568689 | D loss: 1.404655\n",
            "Step 4191: G loss: 24.658382 | D loss: 1.413136\n",
            "Step 4192: G loss: 24.807333 | D loss: 1.405438\n",
            "Step 4193: G loss: 36.806980 | D loss: 1.404666\n",
            "Step 4194: G loss: 30.421537 | D loss: 1.408426\n",
            "Step 4195: G loss: 35.921600 | D loss: 1.408958\n",
            "Step 4196: G loss: 30.240524 | D loss: 1.409890\n",
            "Step 4197: G loss: 27.229919 | D loss: 1.407973\n",
            "Step 4198: G loss: 28.255804 | D loss: 1.404563\n",
            "Step 4199: G loss: 31.079252 | D loss: 1.409016\n",
            "Step 4200: G loss: 37.452774 | D loss: 1.405508\n",
            "Step 4201: G loss: 23.779167 | D loss: 1.408535\n",
            "Step 4202: G loss: 26.815475 | D loss: 1.407476\n",
            "Step 4203: G loss: 25.310471 | D loss: 1.404681\n",
            "Step 4204: G loss: 22.870096 | D loss: 1.408239\n",
            "Step 4205: G loss: 32.545799 | D loss: 1.404369\n",
            "Step 4206: G loss: 22.814178 | D loss: 1.405765\n",
            "Step 4207: G loss: 28.031801 | D loss: 1.404658\n",
            "Step 4208: G loss: 23.244621 | D loss: 1.404573\n",
            "Step 4209: G loss: 28.770733 | D loss: 1.407571\n",
            "Step 4210: G loss: 25.507835 | D loss: 1.404338\n",
            "Step 4211: G loss: 23.659813 | D loss: 1.405470\n",
            "Step 4212: G loss: 28.117464 | D loss: 1.408427\n",
            "Step 4213: G loss: 23.245037 | D loss: 1.408439\n",
            "Step 4214: G loss: 27.391464 | D loss: 1.406532\n",
            "Step 4215: G loss: 40.855919 | D loss: 1.406640\n",
            "Step 4216: G loss: 30.181881 | D loss: 1.405996\n",
            "Step 4217: G loss: 26.350183 | D loss: 1.406071\n",
            "Step 4218: G loss: 39.726997 | D loss: 1.404326\n",
            "Step 4219: G loss: 28.275742 | D loss: 1.404520\n",
            "Step 4220: G loss: 34.678612 | D loss: 1.405106\n",
            "Step 4221: G loss: 31.095377 | D loss: 1.411253\n",
            "Step 4222: G loss: 19.771276 | D loss: 1.405045\n",
            "Step 4223: G loss: 22.399294 | D loss: 1.406391\n",
            "Step 4224: G loss: 20.886728 | D loss: 1.404169\n",
            "Step 4225: G loss: 26.674767 | D loss: 1.404361\n",
            "Step 4226: G loss: 22.799168 | D loss: 1.406930\n",
            "Step 4227: G loss: 29.230482 | D loss: 1.404187\n",
            "Step 4228: G loss: 34.270668 | D loss: 1.404212\n",
            "Step 4229: G loss: 30.821091 | D loss: 1.408815\n",
            "Step 4230: G loss: 27.332199 | D loss: 1.404893\n",
            "Step 4231: G loss: 33.719891 | D loss: 1.404107\n",
            "Step 4232: G loss: 25.361139 | D loss: 1.407552\n",
            "Step 4233: G loss: 28.114399 | D loss: 1.404143\n",
            "Step 4234: G loss: 34.238579 | D loss: 1.404286\n",
            "Step 4235: G loss: 20.039755 | D loss: 1.406224\n",
            "Step 4236: G loss: 28.007513 | D loss: 1.407686\n",
            "Step 4237: G loss: 43.310802 | D loss: 1.404213\n",
            "Step 4238: G loss: 23.534307 | D loss: 1.404788\n",
            "Step 4239: G loss: 31.306114 | D loss: 1.404081\n",
            "Step 4240: G loss: 24.915058 | D loss: 1.404345\n",
            "Step 4241: G loss: 31.118919 | D loss: 1.404338\n",
            "Step 4242: G loss: 39.711662 | D loss: 1.408651\n",
            "Step 4243: G loss: 24.476452 | D loss: 1.407015\n",
            "Step 4244: G loss: 35.754196 | D loss: 1.407398\n",
            "Step 4245: G loss: 30.726250 | D loss: 1.407884\n",
            "Step 4246: G loss: 27.684494 | D loss: 1.404284\n",
            "Step 4247: G loss: 26.410656 | D loss: 1.411170\n",
            "Step 4248: G loss: 25.825911 | D loss: 1.409924\n",
            "Step 4249: G loss: 31.036039 | D loss: 1.404348\n",
            "Step 4250: G loss: 39.440071 | D loss: 1.409276\n",
            "Step 4251: G loss: 29.464893 | D loss: 1.405090\n",
            "Step 4252: G loss: 36.421436 | D loss: 1.404774\n",
            "Step 4253: G loss: 32.570309 | D loss: 1.405452\n",
            "Step 4254: G loss: 23.340822 | D loss: 1.407655\n",
            "Step 4255: G loss: 27.032364 | D loss: 1.408347\n",
            "Step 4256: G loss: 27.360844 | D loss: 1.409876\n",
            "Step 4257: G loss: 28.508234 | D loss: 1.404495\n",
            "Step 4258: G loss: 25.241995 | D loss: 1.405968\n",
            "Step 4259: G loss: 35.275146 | D loss: 1.404966\n",
            "Step 4260: G loss: 33.304195 | D loss: 1.405737\n",
            "Step 4261: G loss: 24.197613 | D loss: 1.406565\n",
            "Step 4262: G loss: 27.282209 | D loss: 1.406334\n",
            "Step 4263: G loss: 22.988306 | D loss: 1.405052\n",
            "Step 4264: G loss: 25.184963 | D loss: 1.403828\n",
            "Step 4265: G loss: 20.327070 | D loss: 1.403815\n",
            "Step 4266: G loss: 29.230347 | D loss: 1.406126\n",
            "Step 4267: G loss: 42.001911 | D loss: 1.406290\n",
            "Step 4268: G loss: 30.411766 | D loss: 1.404700\n",
            "Step 4269: G loss: 28.661034 | D loss: 1.404387\n",
            "Step 4270: G loss: 27.906239 | D loss: 1.406446\n",
            "Step 4271: G loss: 29.751442 | D loss: 1.405462\n",
            "Step 4272: G loss: 29.919687 | D loss: 1.404205\n",
            "Step 4273: G loss: 23.489325 | D loss: 1.406608\n",
            "Step 4274: G loss: 21.984398 | D loss: 1.409858\n",
            "Step 4275: G loss: 42.162979 | D loss: 1.405025\n",
            "Step 4276: G loss: 24.446476 | D loss: 1.406818\n",
            "Step 4277: G loss: 24.929838 | D loss: 1.405471\n",
            "Step 4278: G loss: 31.191902 | D loss: 1.405964\n",
            "Step 4279: G loss: 21.575520 | D loss: 1.403656\n",
            "Step 4280: G loss: 20.977049 | D loss: 1.405063\n",
            "Step 4281: G loss: 26.711992 | D loss: 1.407867\n",
            "Step 4282: G loss: 27.204901 | D loss: 1.407755\n",
            "Step 4283: G loss: 39.277611 | D loss: 1.408412\n",
            "Step 4284: G loss: 30.007435 | D loss: 1.404811\n",
            "Step 4285: G loss: 36.411533 | D loss: 1.403833\n",
            "Step 4286: G loss: 21.162687 | D loss: 1.403686\n",
            "Step 4287: G loss: 31.002859 | D loss: 1.403644\n",
            "Step 4288: G loss: 24.048267 | D loss: 1.406937\n",
            "Step 4289: G loss: 33.944328 | D loss: 1.409369\n",
            "Step 4290: G loss: 40.205730 | D loss: 1.403532\n",
            "Step 4291: G loss: 32.285919 | D loss: 1.405564\n",
            "Step 4292: G loss: 20.657818 | D loss: 1.403856\n",
            "Step 4293: G loss: 22.175804 | D loss: 1.407067\n",
            "Step 4294: G loss: 26.438360 | D loss: 1.403510\n",
            "Step 4295: G loss: 26.067589 | D loss: 1.403973\n",
            "Step 4296: G loss: 25.325048 | D loss: 1.403482\n",
            "Step 4297: G loss: 29.510443 | D loss: 1.409398\n",
            "Step 4298: G loss: 29.979647 | D loss: 1.407829\n",
            "Step 4299: G loss: 30.282228 | D loss: 1.407081\n",
            "Step 4300: G loss: 36.535889 | D loss: 1.403432\n",
            "Step 4301: G loss: 31.786034 | D loss: 1.406772\n",
            "Step 4302: G loss: 19.522488 | D loss: 1.403832\n",
            "Step 4303: G loss: 32.495651 | D loss: 1.405103\n",
            "Step 4304: G loss: 37.002975 | D loss: 1.407521\n",
            "Step 4305: G loss: 25.635710 | D loss: 1.408612\n",
            "Step 4306: G loss: 25.537148 | D loss: 1.404438\n",
            "Step 4307: G loss: 33.141521 | D loss: 1.406324\n",
            "Step 4308: G loss: 25.331680 | D loss: 1.403438\n",
            "Step 4309: G loss: 25.023642 | D loss: 1.403518\n",
            "Step 4310: G loss: 22.412880 | D loss: 1.404037\n",
            "Step 4311: G loss: 20.823065 | D loss: 1.403933\n",
            "Step 4312: G loss: 26.907352 | D loss: 1.403377\n",
            "Step 4313: G loss: 30.629915 | D loss: 1.403321\n",
            "Step 4314: G loss: 24.406240 | D loss: 1.403541\n",
            "Step 4315: G loss: 26.772045 | D loss: 1.403387\n",
            "Step 4316: G loss: 35.800312 | D loss: 1.403584\n",
            "Step 4317: G loss: 27.768280 | D loss: 1.403263\n",
            "Step 4318: G loss: 35.428215 | D loss: 1.403728\n",
            "Step 4319: G loss: 30.558367 | D loss: 1.407509\n",
            "Step 4320: G loss: 36.601089 | D loss: 1.405304\n",
            "Step 4321: G loss: 36.495071 | D loss: 1.405878\n",
            "Step 4322: G loss: 34.552681 | D loss: 1.407085\n",
            "Step 4323: G loss: 24.974253 | D loss: 1.408460\n",
            "Step 4324: G loss: 27.627138 | D loss: 1.413105\n",
            "Step 4325: G loss: 31.857845 | D loss: 1.403804\n",
            "Step 4326: G loss: 26.907013 | D loss: 1.405711\n",
            "Step 4327: G loss: 33.855621 | D loss: 1.405868\n",
            "Step 4328: G loss: 23.918592 | D loss: 1.410133\n",
            "Step 4329: G loss: 34.977783 | D loss: 1.404460\n",
            "Step 4330: G loss: 20.058361 | D loss: 1.406187\n",
            "Step 4331: G loss: 22.058064 | D loss: 1.403247\n",
            "Step 4332: G loss: 31.945885 | D loss: 1.407001\n",
            "Step 4333: G loss: 31.074608 | D loss: 1.407981\n",
            "Step 4334: G loss: 34.998955 | D loss: 1.406821\n",
            "Step 4335: G loss: 29.089502 | D loss: 1.406400\n",
            "Step 4336: G loss: 19.412193 | D loss: 1.404875\n",
            "Step 4337: G loss: 33.153576 | D loss: 1.403124\n",
            "Step 4338: G loss: 33.177563 | D loss: 1.403730\n",
            "Step 4339: G loss: 29.682629 | D loss: 1.407714\n",
            "Step 4340: G loss: 29.108572 | D loss: 1.405590\n",
            "Step 4341: G loss: 26.385506 | D loss: 1.404453\n",
            "Step 4342: G loss: 25.305986 | D loss: 1.407557\n",
            "Step 4343: G loss: 23.892763 | D loss: 1.403444\n",
            "Step 4344: G loss: 24.785112 | D loss: 1.405548\n",
            "Step 4345: G loss: 21.780914 | D loss: 1.402987\n",
            "Step 4346: G loss: 43.701824 | D loss: 1.406469\n",
            "Step 4347: G loss: 24.458769 | D loss: 1.407199\n",
            "Step 4348: G loss: 33.962257 | D loss: 1.403387\n",
            "Step 4349: G loss: 25.264206 | D loss: 1.407119\n",
            "Step 4350: G loss: 27.405560 | D loss: 1.402988\n",
            "Step 4351: G loss: 33.762138 | D loss: 1.407687\n",
            "Step 4352: G loss: 39.635784 | D loss: 1.409138\n",
            "Step 4353: G loss: 29.526627 | D loss: 1.407535\n",
            "Step 4354: G loss: 23.010580 | D loss: 1.405323\n",
            "Step 4355: G loss: 19.887571 | D loss: 1.403131\n",
            "Step 4356: G loss: 35.608013 | D loss: 1.402968\n",
            "Step 4357: G loss: 32.706444 | D loss: 1.408685\n",
            "Step 4358: G loss: 43.695034 | D loss: 1.402829\n",
            "Step 4359: G loss: 34.137863 | D loss: 1.404158\n",
            "Step 4360: G loss: 32.439953 | D loss: 1.402870\n",
            "Step 4361: G loss: 28.337454 | D loss: 1.402904\n",
            "Step 4362: G loss: 27.774935 | D loss: 1.402827\n",
            "Step 4363: G loss: 29.253428 | D loss: 1.403525\n",
            "Step 4364: G loss: 24.347853 | D loss: 1.404006\n",
            "Step 4365: G loss: 37.204903 | D loss: 1.402988\n",
            "Step 4366: G loss: 36.154903 | D loss: 1.405063\n",
            "Step 4367: G loss: 28.586227 | D loss: 1.403114\n",
            "Step 4368: G loss: 23.407942 | D loss: 1.405316\n",
            "Step 4369: G loss: 17.961107 | D loss: 1.402848\n",
            "Step 4370: G loss: 35.387253 | D loss: 1.402942\n",
            "Step 4371: G loss: 29.475174 | D loss: 1.405620\n",
            "Step 4372: G loss: 52.076355 | D loss: 1.404479\n",
            "Step 4373: G loss: 22.089937 | D loss: 1.405216\n",
            "Step 4374: G loss: 27.097973 | D loss: 1.402701\n",
            "Step 4375: G loss: 27.228275 | D loss: 1.408571\n",
            "Step 4376: G loss: 24.563541 | D loss: 1.403320\n",
            "Step 4377: G loss: 24.978594 | D loss: 1.405086\n",
            "Step 4378: G loss: 28.965185 | D loss: 1.402705\n",
            "Step 4379: G loss: 23.886135 | D loss: 1.405224\n",
            "Step 4380: G loss: 26.462051 | D loss: 1.404757\n",
            "Step 4381: G loss: 29.352713 | D loss: 1.408224\n",
            "Step 4382: G loss: 16.133389 | D loss: 1.402842\n",
            "Step 4383: G loss: 22.702496 | D loss: 1.407003\n",
            "Step 4384: G loss: 35.949398 | D loss: 1.405948\n",
            "Step 4385: G loss: 26.327988 | D loss: 1.402654\n",
            "Step 4386: G loss: 25.657455 | D loss: 1.404055\n",
            "Step 4387: G loss: 39.622574 | D loss: 1.403333\n",
            "Step 4388: G loss: 25.545767 | D loss: 1.402715\n",
            "Step 4389: G loss: 22.500708 | D loss: 1.404681\n",
            "Step 4390: G loss: 23.536598 | D loss: 1.404706\n",
            "Step 4391: G loss: 28.432884 | D loss: 1.403202\n",
            "Step 4392: G loss: 24.113102 | D loss: 1.403532\n",
            "Step 4393: G loss: 22.754416 | D loss: 1.405696\n",
            "Step 4394: G loss: 24.154057 | D loss: 1.406131\n",
            "Step 4395: G loss: 20.816462 | D loss: 1.404027\n",
            "Step 4396: G loss: 28.055563 | D loss: 1.403159\n",
            "Step 4397: G loss: 24.912800 | D loss: 1.403089\n",
            "Step 4398: G loss: 18.917377 | D loss: 1.403560\n",
            "Step 4399: G loss: 23.616831 | D loss: 1.403712\n",
            "Step 4400: G loss: 34.305870 | D loss: 1.402627\n",
            "Step 4401: G loss: 22.678984 | D loss: 1.402475\n",
            "Step 4402: G loss: 23.799196 | D loss: 1.408819\n",
            "Step 4403: G loss: 23.362974 | D loss: 1.404769\n",
            "Step 4404: G loss: 28.036415 | D loss: 1.406323\n",
            "Step 4405: G loss: 26.283672 | D loss: 1.404210\n",
            "Step 4406: G loss: 29.946869 | D loss: 1.404013\n",
            "Step 4407: G loss: 24.510145 | D loss: 1.405328\n",
            "Step 4408: G loss: 21.602602 | D loss: 1.404618\n",
            "Step 4409: G loss: 25.440687 | D loss: 1.406887\n",
            "Step 4410: G loss: 30.480701 | D loss: 1.405728\n",
            "Step 4411: G loss: 36.718113 | D loss: 1.402443\n",
            "Step 4412: G loss: 16.654253 | D loss: 1.403525\n",
            "Step 4413: G loss: 24.714836 | D loss: 1.406489\n",
            "Step 4414: G loss: 42.513340 | D loss: 1.403775\n",
            "Step 4415: G loss: 22.969643 | D loss: 1.404490\n",
            "Step 4416: G loss: 30.325840 | D loss: 1.402301\n",
            "Step 4417: G loss: 36.706032 | D loss: 1.403065\n",
            "Step 4418: G loss: 26.298050 | D loss: 1.403440\n",
            "Step 4419: G loss: 34.009663 | D loss: 1.404470\n",
            "Step 4420: G loss: 28.381254 | D loss: 1.405998\n",
            "Step 4421: G loss: 24.207401 | D loss: 1.402249\n",
            "Step 4422: G loss: 21.897181 | D loss: 1.405947\n",
            "Step 4423: G loss: 34.399620 | D loss: 1.402572\n",
            "Step 4424: G loss: 24.729916 | D loss: 1.403594\n",
            "Step 4425: G loss: 29.751076 | D loss: 1.402635\n",
            "Step 4426: G loss: 39.761700 | D loss: 1.403458\n",
            "Step 4427: G loss: 23.156731 | D loss: 1.405851\n",
            "Step 4428: G loss: 21.327658 | D loss: 1.402726\n",
            "Step 4429: G loss: 37.036243 | D loss: 1.403701\n",
            "Step 4430: G loss: 27.096445 | D loss: 1.403479\n",
            "Step 4431: G loss: 36.428799 | D loss: 1.403882\n",
            "Step 4432: G loss: 24.732193 | D loss: 1.402255\n",
            "Step 4433: G loss: 28.584242 | D loss: 1.406405\n",
            "Step 4434: G loss: 26.222294 | D loss: 1.403029\n",
            "Step 4435: G loss: 25.411308 | D loss: 1.406325\n",
            "Step 4436: G loss: 19.178572 | D loss: 1.405415\n",
            "Step 4437: G loss: 35.517872 | D loss: 1.402719\n",
            "Step 4438: G loss: 35.700821 | D loss: 1.403634\n",
            "Step 4439: G loss: 20.329458 | D loss: 1.402130\n",
            "Step 4440: G loss: 31.284700 | D loss: 1.403029\n",
            "Step 4441: G loss: 21.833487 | D loss: 1.402173\n",
            "Step 4442: G loss: 28.801493 | D loss: 1.405027\n",
            "Step 4443: G loss: 24.767971 | D loss: 1.402242\n",
            "Step 4444: G loss: 20.930569 | D loss: 1.407290\n",
            "Step 4445: G loss: 26.045908 | D loss: 1.402539\n",
            "Step 4446: G loss: 26.135267 | D loss: 1.405528\n",
            "Step 4447: G loss: 24.652273 | D loss: 1.408652\n",
            "Step 4448: G loss: 38.156971 | D loss: 1.404992\n",
            "Step 4449: G loss: 31.105701 | D loss: 1.403468\n",
            "Step 4450: G loss: 28.929508 | D loss: 1.402103\n",
            "Step 4451: G loss: 30.041544 | D loss: 1.401916\n",
            "Step 4452: G loss: 19.999603 | D loss: 1.402909\n",
            "Step 4453: G loss: 20.798916 | D loss: 1.405338\n",
            "Step 4454: G loss: 25.760017 | D loss: 1.408317\n",
            "Step 4455: G loss: 38.528828 | D loss: 1.402241\n",
            "Step 4456: G loss: 32.566872 | D loss: 1.402314\n",
            "Step 4457: G loss: 29.874731 | D loss: 1.402129\n",
            "Step 4458: G loss: 28.495152 | D loss: 1.406782\n",
            "Step 4459: G loss: 28.703398 | D loss: 1.405067\n",
            "Step 4460: G loss: 47.365814 | D loss: 1.405475\n",
            "Step 4461: G loss: 35.875366 | D loss: 1.405140\n",
            "Step 4462: G loss: 27.953497 | D loss: 1.402166\n",
            "Step 4463: G loss: 24.834730 | D loss: 1.405363\n",
            "Step 4464: G loss: 27.594738 | D loss: 1.405434\n",
            "Step 4465: G loss: 34.556980 | D loss: 1.402495\n",
            "Step 4466: G loss: 38.197311 | D loss: 1.401831\n",
            "Step 4467: G loss: 29.439295 | D loss: 1.402485\n",
            "Step 4468: G loss: 22.540430 | D loss: 1.405151\n",
            "Step 4469: G loss: 28.796936 | D loss: 1.406244\n",
            "Step 4470: G loss: 34.468262 | D loss: 1.405954\n",
            "Step 4471: G loss: 23.967075 | D loss: 1.401845\n",
            "Step 4472: G loss: 28.549381 | D loss: 1.401921\n",
            "Step 4473: G loss: 33.085068 | D loss: 1.402085\n",
            "Step 4474: G loss: 20.086010 | D loss: 1.405486\n",
            "Step 4475: G loss: 27.823627 | D loss: 1.401954\n",
            "Step 4476: G loss: 23.777187 | D loss: 1.402919\n",
            "Step 4477: G loss: 27.436693 | D loss: 1.404216\n",
            "Step 4478: G loss: 25.974461 | D loss: 1.404062\n",
            "Step 4479: G loss: 23.225975 | D loss: 1.402831\n",
            "Step 4480: G loss: 21.424675 | D loss: 1.401660\n",
            "Step 4481: G loss: 21.129358 | D loss: 1.404514\n",
            "Step 4482: G loss: 28.995182 | D loss: 1.403585\n",
            "Step 4483: G loss: 24.601719 | D loss: 1.405177\n",
            "Step 4484: G loss: 29.700754 | D loss: 1.405892\n",
            "Step 4485: G loss: 33.708157 | D loss: 1.401998\n",
            "Step 4486: G loss: 16.965073 | D loss: 1.404257\n",
            "Step 4487: G loss: 31.955929 | D loss: 1.405139\n",
            "Step 4488: G loss: 34.670773 | D loss: 1.402268\n",
            "Step 4489: G loss: 28.536533 | D loss: 1.401540\n",
            "Step 4490: G loss: 25.981285 | D loss: 1.402652\n",
            "Step 4491: G loss: 27.382446 | D loss: 1.401608\n",
            "Step 4492: G loss: 26.497278 | D loss: 1.401515\n",
            "Step 4493: G loss: 33.123463 | D loss: 1.404111\n",
            "Step 4494: G loss: 27.098621 | D loss: 1.401726\n",
            "Step 4495: G loss: 28.569506 | D loss: 1.404401\n",
            "Step 4496: G loss: 20.980249 | D loss: 1.407132\n",
            "Step 4497: G loss: 23.438644 | D loss: 1.401485\n",
            "Step 4498: G loss: 39.519032 | D loss: 1.401523\n",
            "Step 4499: G loss: 23.152725 | D loss: 1.401422\n",
            "Step 4500: G loss: 38.250134 | D loss: 1.401530\n",
            "Step 4501: G loss: 22.988720 | D loss: 1.401411\n",
            "Step 4502: G loss: 25.559155 | D loss: 1.401542\n",
            "Step 4503: G loss: 19.753016 | D loss: 1.405916\n",
            "Step 4504: G loss: 24.032879 | D loss: 1.402587\n",
            "Step 4505: G loss: 24.770643 | D loss: 1.402787\n",
            "Step 4506: G loss: 23.877407 | D loss: 1.404124\n",
            "Step 4507: G loss: 30.864719 | D loss: 1.403007\n",
            "Step 4508: G loss: 25.821159 | D loss: 1.404543\n",
            "Step 4509: G loss: 26.506578 | D loss: 1.401560\n",
            "Step 4510: G loss: 23.061090 | D loss: 1.401536\n",
            "Step 4511: G loss: 28.931393 | D loss: 1.404197\n",
            "Step 4512: G loss: 33.147110 | D loss: 1.402829\n",
            "Step 4513: G loss: 20.304838 | D loss: 1.404586\n",
            "Step 4514: G loss: 32.852516 | D loss: 1.401331\n",
            "Step 4515: G loss: 24.014872 | D loss: 1.401562\n",
            "Step 4516: G loss: 33.314102 | D loss: 1.401322\n",
            "Step 4517: G loss: 24.094290 | D loss: 1.401415\n",
            "Step 4518: G loss: 35.884789 | D loss: 1.404804\n",
            "Step 4519: G loss: 36.199520 | D loss: 1.401269\n",
            "Step 4520: G loss: 23.813269 | D loss: 1.402229\n",
            "Step 4521: G loss: 28.664665 | D loss: 1.402078\n",
            "Step 4522: G loss: 32.920113 | D loss: 1.403695\n",
            "Step 4523: G loss: 20.480143 | D loss: 1.403826\n",
            "Step 4524: G loss: 27.435074 | D loss: 1.402908\n",
            "Step 4525: G loss: 28.606424 | D loss: 1.401185\n",
            "Step 4526: G loss: 31.676064 | D loss: 1.403078\n",
            "Step 4527: G loss: 27.303360 | D loss: 1.401747\n",
            "Step 4528: G loss: 28.447453 | D loss: 1.401503\n",
            "Step 4529: G loss: 33.713089 | D loss: 1.402661\n",
            "Step 4530: G loss: 22.570333 | D loss: 1.405522\n",
            "Step 4531: G loss: 42.134735 | D loss: 1.401175\n",
            "Step 4532: G loss: 23.844204 | D loss: 1.403904\n",
            "Step 4533: G loss: 22.420664 | D loss: 1.404397\n",
            "Step 4534: G loss: 31.381626 | D loss: 1.401498\n",
            "Step 4535: G loss: 20.819103 | D loss: 1.401919\n",
            "Step 4536: G loss: 22.788374 | D loss: 1.403424\n",
            "Step 4537: G loss: 25.235537 | D loss: 1.401271\n",
            "Step 4538: G loss: 28.875351 | D loss: 1.401981\n",
            "Step 4539: G loss: 24.574413 | D loss: 1.403900\n",
            "Step 4540: G loss: 21.964224 | D loss: 1.401615\n",
            "Step 4541: G loss: 20.665329 | D loss: 1.401091\n",
            "Step 4542: G loss: 25.577991 | D loss: 1.402268\n",
            "Step 4543: G loss: 29.659142 | D loss: 1.404034\n",
            "Step 4544: G loss: 22.573881 | D loss: 1.401972\n",
            "Step 4545: G loss: 22.368546 | D loss: 1.401361\n",
            "Step 4546: G loss: 23.487755 | D loss: 1.402070\n",
            "Step 4547: G loss: 20.545904 | D loss: 1.400965\n",
            "Step 4548: G loss: 21.719553 | D loss: 1.403719\n",
            "Step 4549: G loss: 27.550753 | D loss: 1.402673\n",
            "Step 4550: G loss: 35.358246 | D loss: 1.402694\n",
            "Step 4551: G loss: 22.317326 | D loss: 1.404302\n",
            "Step 4552: G loss: 33.975613 | D loss: 1.401405\n",
            "Step 4553: G loss: 30.563272 | D loss: 1.401843\n",
            "Step 4554: G loss: 32.179600 | D loss: 1.400929\n",
            "Step 4555: G loss: 27.233835 | D loss: 1.401161\n",
            "Step 4556: G loss: 23.782267 | D loss: 1.401558\n",
            "Step 4557: G loss: 27.636086 | D loss: 1.402888\n",
            "Step 4558: G loss: 24.353563 | D loss: 1.405193\n",
            "Step 4559: G loss: 20.275089 | D loss: 1.406415\n",
            "Step 4560: G loss: 18.846001 | D loss: 1.401901\n",
            "Step 4561: G loss: 34.612785 | D loss: 1.403938\n",
            "Step 4562: G loss: 30.498375 | D loss: 1.403113\n",
            "Step 4563: G loss: 17.355328 | D loss: 1.403205\n",
            "Step 4564: G loss: 15.741534 | D loss: 1.403330\n",
            "Step 4565: G loss: 28.231550 | D loss: 1.400795\n",
            "Step 4566: G loss: 21.074505 | D loss: 1.400808\n",
            "Step 4567: G loss: 31.311750 | D loss: 1.401940\n",
            "Step 4568: G loss: 20.285814 | D loss: 1.400753\n",
            "Step 4569: G loss: 23.167986 | D loss: 1.405871\n",
            "Step 4570: G loss: 23.880730 | D loss: 1.402322\n",
            "Step 4571: G loss: 33.760513 | D loss: 1.400885\n",
            "Step 4572: G loss: 29.804571 | D loss: 1.403098\n",
            "Step 4573: G loss: 33.718533 | D loss: 1.403834\n",
            "Step 4574: G loss: 25.848883 | D loss: 1.402219\n",
            "Step 4575: G loss: 25.474874 | D loss: 1.402763\n",
            "Step 4576: G loss: 28.608370 | D loss: 1.400750\n",
            "Step 4577: G loss: 28.114498 | D loss: 1.403472\n",
            "Step 4578: G loss: 37.761433 | D loss: 1.401612\n",
            "Step 4579: G loss: 22.351376 | D loss: 1.403592\n",
            "Step 4580: G loss: 25.899054 | D loss: 1.402673\n",
            "Step 4581: G loss: 24.282942 | D loss: 1.400775\n",
            "Step 4582: G loss: 22.598341 | D loss: 1.405058\n",
            "Step 4583: G loss: 30.450912 | D loss: 1.400592\n",
            "Step 4584: G loss: 22.858721 | D loss: 1.401981\n",
            "Step 4585: G loss: 26.616335 | D loss: 1.400746\n",
            "Step 4586: G loss: 21.349573 | D loss: 1.400958\n",
            "Step 4587: G loss: 28.034443 | D loss: 1.403181\n",
            "Step 4588: G loss: 24.865076 | D loss: 1.400544\n",
            "Step 4589: G loss: 22.375763 | D loss: 1.402783\n",
            "Step 4590: G loss: 25.554390 | D loss: 1.402789\n",
            "Step 4591: G loss: 22.182537 | D loss: 1.403458\n",
            "Step 4592: G loss: 28.339705 | D loss: 1.400790\n",
            "Step 4593: G loss: 39.179039 | D loss: 1.401210\n",
            "Step 4594: G loss: 29.917015 | D loss: 1.400830\n",
            "Step 4595: G loss: 25.639463 | D loss: 1.403143\n",
            "Step 4596: G loss: 40.102173 | D loss: 1.400468\n",
            "Step 4597: G loss: 29.279381 | D loss: 1.400523\n",
            "Step 4598: G loss: 32.780540 | D loss: 1.400574\n",
            "Step 4599: G loss: 26.355717 | D loss: 1.405571\n",
            "Step 4600: G loss: 19.217899 | D loss: 1.400440\n",
            "Step 4601: G loss: 22.137581 | D loss: 1.401992\n",
            "Step 4602: G loss: 21.660839 | D loss: 1.400406\n",
            "Step 4603: G loss: 25.378843 | D loss: 1.400675\n",
            "Step 4604: G loss: 22.078835 | D loss: 1.401246\n",
            "Step 4605: G loss: 24.665579 | D loss: 1.402573\n",
            "Step 4606: G loss: 34.983959 | D loss: 1.400516\n",
            "Step 4607: G loss: 31.230742 | D loss: 1.402285\n",
            "Step 4608: G loss: 27.083035 | D loss: 1.401963\n",
            "Step 4609: G loss: 31.087673 | D loss: 1.400355\n",
            "Step 4610: G loss: 25.485966 | D loss: 1.401708\n",
            "Step 4611: G loss: 26.910986 | D loss: 1.401656\n",
            "Step 4612: G loss: 34.979050 | D loss: 1.400411\n",
            "Step 4613: G loss: 18.847458 | D loss: 1.400728\n",
            "Step 4614: G loss: 26.836538 | D loss: 1.402300\n",
            "Step 4615: G loss: 42.288136 | D loss: 1.400474\n",
            "Step 4616: G loss: 22.276762 | D loss: 1.402869\n",
            "Step 4617: G loss: 30.008980 | D loss: 1.400273\n",
            "Step 4618: G loss: 22.505470 | D loss: 1.400548\n",
            "Step 4619: G loss: 30.498196 | D loss: 1.400287\n",
            "Step 4620: G loss: 35.865311 | D loss: 1.402260\n",
            "Step 4621: G loss: 23.363922 | D loss: 1.400854\n",
            "Step 4622: G loss: 35.399628 | D loss: 1.402907\n",
            "Step 4623: G loss: 27.864349 | D loss: 1.404130\n",
            "Step 4624: G loss: 27.575981 | D loss: 1.400243\n",
            "Step 4625: G loss: 26.388796 | D loss: 1.401695\n",
            "Step 4626: G loss: 24.121990 | D loss: 1.400363\n",
            "Step 4627: G loss: 27.361744 | D loss: 1.400179\n",
            "Step 4628: G loss: 38.833439 | D loss: 1.401473\n",
            "Step 4629: G loss: 27.811247 | D loss: 1.400196\n",
            "Step 4630: G loss: 37.466000 | D loss: 1.400218\n",
            "Step 4631: G loss: 31.292465 | D loss: 1.400164\n",
            "Step 4632: G loss: 22.760588 | D loss: 1.400561\n",
            "Step 4633: G loss: 26.243990 | D loss: 1.402257\n",
            "Step 4634: G loss: 25.797508 | D loss: 1.403376\n",
            "Step 4635: G loss: 27.683493 | D loss: 1.400480\n",
            "Step 4636: G loss: 24.472813 | D loss: 1.400274\n",
            "Step 4637: G loss: 31.911928 | D loss: 1.400436\n",
            "Step 4638: G loss: 31.852039 | D loss: 1.401089\n",
            "Step 4639: G loss: 22.139370 | D loss: 1.400689\n",
            "Step 4640: G loss: 25.609776 | D loss: 1.400210\n",
            "Step 4641: G loss: 23.010826 | D loss: 1.401626\n",
            "Step 4642: G loss: 24.869839 | D loss: 1.400012\n",
            "Step 4643: G loss: 16.535786 | D loss: 1.400041\n",
            "Step 4644: G loss: 27.941380 | D loss: 1.400601\n",
            "Step 4645: G loss: 39.667480 | D loss: 1.400409\n",
            "Step 4646: G loss: 28.792852 | D loss: 1.400331\n",
            "Step 4647: G loss: 29.198587 | D loss: 1.400150\n",
            "Step 4648: G loss: 27.451580 | D loss: 1.400968\n",
            "Step 4649: G loss: 28.435389 | D loss: 1.402029\n",
            "Step 4650: G loss: 29.125546 | D loss: 1.400073\n",
            "Step 4651: G loss: 23.181725 | D loss: 1.400866\n",
            "Step 4652: G loss: 21.148836 | D loss: 1.403057\n",
            "Step 4653: G loss: 37.993698 | D loss: 1.401097\n",
            "Step 4654: G loss: 24.373917 | D loss: 1.402164\n",
            "Step 4655: G loss: 22.443813 | D loss: 1.400032\n",
            "Step 4656: G loss: 30.691692 | D loss: 1.401557\n",
            "Step 4657: G loss: 20.679733 | D loss: 1.399937\n",
            "Step 4658: G loss: 20.344881 | D loss: 1.400952\n",
            "Step 4659: G loss: 24.810871 | D loss: 1.402900\n",
            "Step 4660: G loss: 25.770952 | D loss: 1.401566\n",
            "Step 4661: G loss: 35.421677 | D loss: 1.402174\n",
            "Step 4662: G loss: 28.849094 | D loss: 1.400784\n",
            "Step 4663: G loss: 36.084755 | D loss: 1.400484\n",
            "Step 4664: G loss: 19.283445 | D loss: 1.400009\n",
            "Step 4665: G loss: 27.764929 | D loss: 1.399920\n",
            "Step 4666: G loss: 23.945610 | D loss: 1.400888\n",
            "Step 4667: G loss: 33.441334 | D loss: 1.402895\n",
            "Step 4668: G loss: 38.594357 | D loss: 1.399788\n",
            "Step 4669: G loss: 31.241390 | D loss: 1.402076\n",
            "Step 4670: G loss: 22.062498 | D loss: 1.399930\n",
            "Step 4671: G loss: 20.594093 | D loss: 1.403329\n",
            "Step 4672: G loss: 26.482492 | D loss: 1.399804\n",
            "Step 4673: G loss: 27.137131 | D loss: 1.400062\n",
            "Step 4674: G loss: 25.905445 | D loss: 1.399730\n",
            "Step 4675: G loss: 28.513620 | D loss: 1.403610\n",
            "Step 4676: G loss: 29.269543 | D loss: 1.402323\n",
            "Step 4677: G loss: 29.998039 | D loss: 1.401700\n",
            "Step 4678: G loss: 37.467693 | D loss: 1.399676\n",
            "Step 4679: G loss: 29.806021 | D loss: 1.402418\n",
            "Step 4680: G loss: 19.980190 | D loss: 1.399771\n",
            "Step 4681: G loss: 30.044312 | D loss: 1.400422\n",
            "Step 4682: G loss: 35.904072 | D loss: 1.402392\n",
            "Step 4683: G loss: 25.571815 | D loss: 1.402442\n",
            "Step 4684: G loss: 24.623960 | D loss: 1.399858\n",
            "Step 4685: G loss: 32.504337 | D loss: 1.401143\n",
            "Step 4686: G loss: 26.184641 | D loss: 1.399725\n",
            "Step 4687: G loss: 25.516222 | D loss: 1.399809\n",
            "Step 4688: G loss: 21.880318 | D loss: 1.400050\n",
            "Step 4689: G loss: 22.148207 | D loss: 1.399763\n",
            "Step 4690: G loss: 26.880997 | D loss: 1.399570\n",
            "Step 4691: G loss: 29.121899 | D loss: 1.399547\n",
            "Step 4692: G loss: 24.280983 | D loss: 1.399672\n",
            "Step 4693: G loss: 26.179665 | D loss: 1.399589\n",
            "Step 4694: G loss: 32.911446 | D loss: 1.399672\n",
            "Step 4695: G loss: 27.448435 | D loss: 1.399503\n",
            "Step 4696: G loss: 37.241428 | D loss: 1.399854\n",
            "Step 4697: G loss: 29.715506 | D loss: 1.402138\n",
            "Step 4698: G loss: 34.440296 | D loss: 1.400949\n",
            "Step 4699: G loss: 35.944965 | D loss: 1.400481\n",
            "Step 4700: G loss: 34.153301 | D loss: 1.399737\n",
            "Step 4701: G loss: 23.695522 | D loss: 1.402098\n",
            "Step 4702: G loss: 26.943745 | D loss: 1.401169\n",
            "Step 4703: G loss: 28.383972 | D loss: 1.400113\n",
            "Step 4704: G loss: 26.396879 | D loss: 1.400788\n",
            "Step 4705: G loss: 30.472406 | D loss: 1.401002\n",
            "Step 4706: G loss: 23.936136 | D loss: 1.403303\n",
            "Step 4707: G loss: 33.883629 | D loss: 1.400858\n",
            "Step 4708: G loss: 20.258589 | D loss: 1.401747\n",
            "Step 4709: G loss: 22.863920 | D loss: 1.399549\n",
            "Step 4710: G loss: 29.007137 | D loss: 1.402003\n",
            "Step 4711: G loss: 29.116686 | D loss: 1.405220\n",
            "Step 4712: G loss: 32.522266 | D loss: 1.401865\n",
            "Step 4713: G loss: 30.224007 | D loss: 1.399913\n",
            "Step 4714: G loss: 20.233677 | D loss: 1.399881\n",
            "Step 4715: G loss: 30.288771 | D loss: 1.399308\n",
            "Step 4716: G loss: 30.258148 | D loss: 1.399572\n",
            "Step 4717: G loss: 29.609068 | D loss: 1.401149\n",
            "Step 4718: G loss: 30.032967 | D loss: 1.399811\n",
            "Step 4719: G loss: 27.081873 | D loss: 1.399590\n",
            "Step 4720: G loss: 23.417835 | D loss: 1.402288\n",
            "Step 4721: G loss: 23.608953 | D loss: 1.399437\n",
            "Step 4722: G loss: 23.319220 | D loss: 1.400895\n",
            "Step 4723: G loss: 20.092226 | D loss: 1.399227\n",
            "Step 4724: G loss: 37.947498 | D loss: 1.401474\n",
            "Step 4725: G loss: 25.472382 | D loss: 1.402587\n",
            "Step 4726: G loss: 33.021267 | D loss: 1.400648\n",
            "Step 4727: G loss: 25.807394 | D loss: 1.402277\n",
            "Step 4728: G loss: 25.278751 | D loss: 1.399193\n",
            "Step 4729: G loss: 31.775312 | D loss: 1.401259\n",
            "Step 4730: G loss: 39.389271 | D loss: 1.402988\n",
            "Step 4731: G loss: 28.824970 | D loss: 1.401914\n",
            "Step 4732: G loss: 22.222242 | D loss: 1.401318\n",
            "Step 4733: G loss: 19.902452 | D loss: 1.399353\n",
            "Step 4734: G loss: 31.696638 | D loss: 1.399324\n",
            "Step 4735: G loss: 30.316952 | D loss: 1.401573\n",
            "Step 4736: G loss: 42.718529 | D loss: 1.399128\n",
            "Step 4737: G loss: 29.309666 | D loss: 1.399617\n",
            "Step 4738: G loss: 31.217863 | D loss: 1.399147\n",
            "Step 4739: G loss: 24.969809 | D loss: 1.399128\n",
            "Step 4740: G loss: 27.635231 | D loss: 1.399079\n",
            "Step 4741: G loss: 27.514238 | D loss: 1.399971\n",
            "Step 4742: G loss: 22.508543 | D loss: 1.399876\n",
            "Step 4743: G loss: 39.293449 | D loss: 1.399265\n",
            "Step 4744: G loss: 34.603447 | D loss: 1.399752\n",
            "Step 4745: G loss: 26.970169 | D loss: 1.399270\n",
            "Step 4746: G loss: 21.654118 | D loss: 1.400494\n",
            "Step 4747: G loss: 17.351234 | D loss: 1.399083\n",
            "Step 4748: G loss: 35.516552 | D loss: 1.399101\n",
            "Step 4749: G loss: 29.005131 | D loss: 1.402545\n",
            "Step 4750: G loss: 49.906853 | D loss: 1.399798\n",
            "Step 4751: G loss: 22.565756 | D loss: 1.399821\n",
            "Step 4752: G loss: 26.677122 | D loss: 1.398947\n",
            "Step 4753: G loss: 26.197216 | D loss: 1.402459\n",
            "Step 4754: G loss: 22.874704 | D loss: 1.399860\n",
            "Step 4755: G loss: 24.641768 | D loss: 1.399867\n",
            "Step 4756: G loss: 27.310059 | D loss: 1.398929\n",
            "Step 4757: G loss: 23.220245 | D loss: 1.400403\n",
            "Step 4758: G loss: 24.107841 | D loss: 1.399714\n",
            "Step 4759: G loss: 28.610744 | D loss: 1.400828\n",
            "Step 4760: G loss: 17.307604 | D loss: 1.398935\n",
            "Step 4761: G loss: 22.267376 | D loss: 1.401063\n",
            "Step 4762: G loss: 34.877289 | D loss: 1.400265\n",
            "Step 4763: G loss: 26.046164 | D loss: 1.398852\n",
            "Step 4764: G loss: 24.532047 | D loss: 1.399264\n",
            "Step 4765: G loss: 38.960785 | D loss: 1.399193\n",
            "Step 4766: G loss: 25.381435 | D loss: 1.398834\n",
            "Step 4767: G loss: 21.513308 | D loss: 1.400426\n",
            "Step 4768: G loss: 23.786144 | D loss: 1.400291\n",
            "Step 4769: G loss: 27.427639 | D loss: 1.399203\n",
            "Step 4770: G loss: 23.378798 | D loss: 1.399629\n",
            "Step 4771: G loss: 22.207195 | D loss: 1.400552\n",
            "Step 4772: G loss: 26.115965 | D loss: 1.401237\n",
            "Step 4773: G loss: 17.325064 | D loss: 1.399576\n",
            "Step 4774: G loss: 28.229361 | D loss: 1.399294\n",
            "Step 4775: G loss: 23.202868 | D loss: 1.399355\n",
            "Step 4776: G loss: 19.238138 | D loss: 1.399676\n",
            "Step 4777: G loss: 22.104429 | D loss: 1.399507\n",
            "Step 4778: G loss: 32.315125 | D loss: 1.398744\n",
            "Step 4779: G loss: 21.814632 | D loss: 1.398791\n",
            "Step 4780: G loss: 22.379601 | D loss: 1.399300\n",
            "Step 4781: G loss: 24.780010 | D loss: 1.401024\n",
            "Step 4782: G loss: 27.915775 | D loss: 1.400826\n",
            "Step 4783: G loss: 25.898642 | D loss: 1.399795\n",
            "Step 4784: G loss: 27.791231 | D loss: 1.399903\n",
            "Step 4785: G loss: 23.050058 | D loss: 1.401179\n",
            "Step 4786: G loss: 20.372400 | D loss: 1.399949\n",
            "Step 4787: G loss: 24.698988 | D loss: 1.400857\n",
            "Step 4788: G loss: 26.545652 | D loss: 1.398847\n",
            "Step 4789: G loss: 32.669418 | D loss: 1.398585\n",
            "Step 4790: G loss: 14.403196 | D loss: 1.398858\n",
            "Step 4791: G loss: 22.531164 | D loss: 1.399959\n",
            "Step 4792: G loss: 41.888565 | D loss: 1.398996\n",
            "Step 4793: G loss: 20.064575 | D loss: 1.398625\n",
            "Step 4794: G loss: 30.660345 | D loss: 1.398522\n",
            "Step 4795: G loss: 35.612038 | D loss: 1.398725\n",
            "Step 4796: G loss: 24.393387 | D loss: 1.398653\n",
            "Step 4797: G loss: 32.753693 | D loss: 1.399836\n",
            "Step 4798: G loss: 25.734331 | D loss: 1.400850\n",
            "Step 4799: G loss: 23.459400 | D loss: 1.398483\n",
            "Step 4800: G loss: 21.409349 | D loss: 1.399435\n",
            "Step 4801: G loss: 34.084961 | D loss: 1.400875\n",
            "Step 4802: G loss: 23.628582 | D loss: 1.399098\n",
            "Step 4803: G loss: 29.708338 | D loss: 1.398691\n",
            "Step 4804: G loss: 36.720997 | D loss: 1.399439\n",
            "Step 4805: G loss: 21.183294 | D loss: 1.400676\n",
            "Step 4806: G loss: 22.710648 | D loss: 1.398545\n",
            "Step 4807: G loss: 34.614056 | D loss: 1.399247\n",
            "Step 4808: G loss: 26.826853 | D loss: 1.400067\n",
            "Step 4809: G loss: 34.441849 | D loss: 1.398887\n",
            "Step 4810: G loss: 22.880308 | D loss: 1.398389\n",
            "Step 4811: G loss: 27.875954 | D loss: 1.400954\n",
            "Step 4812: G loss: 25.870777 | D loss: 1.398843\n",
            "Step 4813: G loss: 25.115677 | D loss: 1.399928\n",
            "Step 4814: G loss: 18.409666 | D loss: 1.399231\n",
            "Step 4815: G loss: 34.202538 | D loss: 1.398580\n",
            "Step 4816: G loss: 34.937164 | D loss: 1.398795\n",
            "Step 4817: G loss: 19.915731 | D loss: 1.398316\n",
            "Step 4818: G loss: 32.595562 | D loss: 1.398599\n",
            "Step 4819: G loss: 22.047169 | D loss: 1.398457\n",
            "Step 4820: G loss: 27.964104 | D loss: 1.398661\n",
            "Step 4821: G loss: 24.901558 | D loss: 1.398377\n",
            "Step 4822: G loss: 20.918367 | D loss: 1.398894\n",
            "Step 4823: G loss: 24.742973 | D loss: 1.398505\n",
            "Step 4824: G loss: 25.949911 | D loss: 1.399658\n",
            "Step 4825: G loss: 24.147999 | D loss: 1.402131\n",
            "Step 4826: G loss: 36.849510 | D loss: 1.400170\n",
            "Step 4827: G loss: 30.655159 | D loss: 1.398589\n",
            "Step 4828: G loss: 26.282812 | D loss: 1.398219\n",
            "Step 4829: G loss: 25.722847 | D loss: 1.398174\n",
            "Step 4830: G loss: 21.167843 | D loss: 1.398846\n",
            "Step 4831: G loss: 18.667698 | D loss: 1.399822\n",
            "Step 4832: G loss: 24.137838 | D loss: 1.400125\n",
            "Step 4833: G loss: 37.030659 | D loss: 1.398427\n",
            "Step 4834: G loss: 30.609732 | D loss: 1.398364\n",
            "Step 4835: G loss: 29.474184 | D loss: 1.398255\n",
            "Step 4836: G loss: 25.098993 | D loss: 1.400578\n",
            "Step 4837: G loss: 27.581924 | D loss: 1.399959\n",
            "Step 4838: G loss: 43.974094 | D loss: 1.400515\n",
            "Step 4839: G loss: 33.660576 | D loss: 1.401388\n",
            "Step 4840: G loss: 27.553959 | D loss: 1.398346\n",
            "Step 4841: G loss: 23.571211 | D loss: 1.400475\n",
            "Step 4842: G loss: 26.084618 | D loss: 1.400344\n",
            "Step 4843: G loss: 33.493164 | D loss: 1.398474\n",
            "Step 4844: G loss: 33.657871 | D loss: 1.398061\n",
            "Step 4845: G loss: 28.210402 | D loss: 1.398372\n",
            "Step 4846: G loss: 21.827137 | D loss: 1.400033\n",
            "Step 4847: G loss: 26.821182 | D loss: 1.400735\n",
            "Step 4848: G loss: 33.835270 | D loss: 1.401013\n",
            "Step 4849: G loss: 26.684055 | D loss: 1.398018\n",
            "Step 4850: G loss: 26.279409 | D loss: 1.398047\n",
            "Step 4851: G loss: 31.699179 | D loss: 1.398099\n",
            "Step 4852: G loss: 19.327139 | D loss: 1.398909\n",
            "Step 4853: G loss: 27.609579 | D loss: 1.398109\n",
            "Step 4854: G loss: 23.337559 | D loss: 1.398324\n",
            "Step 4855: G loss: 25.642784 | D loss: 1.399392\n",
            "Step 4856: G loss: 24.806553 | D loss: 1.398923\n",
            "Step 4857: G loss: 24.095030 | D loss: 1.398492\n",
            "Step 4858: G loss: 20.905329 | D loss: 1.397926\n",
            "Step 4859: G loss: 18.966549 | D loss: 1.399121\n",
            "Step 4860: G loss: 27.661848 | D loss: 1.398710\n",
            "Step 4861: G loss: 20.153252 | D loss: 1.399329\n",
            "Step 4862: G loss: 25.709154 | D loss: 1.400485\n",
            "Step 4863: G loss: 33.795498 | D loss: 1.397831\n",
            "Step 4864: G loss: 17.596277 | D loss: 1.399132\n",
            "Step 4865: G loss: 32.798161 | D loss: 1.400038\n",
            "Step 4866: G loss: 32.958141 | D loss: 1.398029\n",
            "Step 4867: G loss: 25.435108 | D loss: 1.397798\n",
            "Step 4868: G loss: 24.540377 | D loss: 1.398794\n",
            "Step 4869: G loss: 25.704895 | D loss: 1.397815\n",
            "Step 4870: G loss: 26.359625 | D loss: 1.397768\n",
            "Step 4871: G loss: 32.660332 | D loss: 1.399207\n",
            "Step 4872: G loss: 25.276497 | D loss: 1.397960\n",
            "Step 4873: G loss: 28.029678 | D loss: 1.399332\n",
            "Step 4874: G loss: 20.737879 | D loss: 1.402796\n",
            "Step 4875: G loss: 23.106203 | D loss: 1.397865\n",
            "Step 4876: G loss: 40.924541 | D loss: 1.397741\n",
            "Step 4877: G loss: 23.697376 | D loss: 1.397689\n",
            "Step 4878: G loss: 36.689922 | D loss: 1.397706\n",
            "Step 4879: G loss: 21.027348 | D loss: 1.397682\n",
            "Step 4880: G loss: 22.809570 | D loss: 1.397722\n",
            "Step 4881: G loss: 19.591866 | D loss: 1.400329\n",
            "Step 4882: G loss: 22.596771 | D loss: 1.400163\n",
            "Step 4883: G loss: 23.954334 | D loss: 1.398683\n",
            "Step 4884: G loss: 23.323986 | D loss: 1.399176\n",
            "Step 4885: G loss: 30.376310 | D loss: 1.398598\n",
            "Step 4886: G loss: 24.376797 | D loss: 1.399453\n",
            "Step 4887: G loss: 25.144434 | D loss: 1.398930\n",
            "Step 4888: G loss: 22.238049 | D loss: 1.397613\n",
            "Step 4889: G loss: 27.936594 | D loss: 1.398678\n",
            "Step 4890: G loss: 32.837746 | D loss: 1.397900\n",
            "Step 4891: G loss: 19.585003 | D loss: 1.399670\n",
            "Step 4892: G loss: 31.470543 | D loss: 1.397563\n",
            "Step 4893: G loss: 22.044516 | D loss: 1.397629\n",
            "Step 4894: G loss: 31.090727 | D loss: 1.397589\n",
            "Step 4895: G loss: 21.878593 | D loss: 1.397551\n",
            "Step 4896: G loss: 33.198269 | D loss: 1.398088\n",
            "Step 4897: G loss: 34.788952 | D loss: 1.397520\n",
            "Step 4898: G loss: 23.165508 | D loss: 1.397993\n",
            "Step 4899: G loss: 27.074011 | D loss: 1.398106\n",
            "Step 4900: G loss: 32.124992 | D loss: 1.399031\n",
            "Step 4901: G loss: 18.772261 | D loss: 1.398529\n",
            "Step 4902: G loss: 26.462999 | D loss: 1.397852\n",
            "Step 4903: G loss: 28.528664 | D loss: 1.397438\n",
            "Step 4904: G loss: 30.907841 | D loss: 1.398593\n",
            "Step 4905: G loss: 26.295416 | D loss: 1.397954\n",
            "Step 4906: G loss: 27.198458 | D loss: 1.397799\n",
            "Step 4907: G loss: 32.401031 | D loss: 1.398191\n",
            "Step 4908: G loss: 20.551027 | D loss: 1.399997\n",
            "Step 4909: G loss: 44.052048 | D loss: 1.397414\n",
            "Step 4910: G loss: 22.570112 | D loss: 1.398722\n",
            "Step 4911: G loss: 21.798912 | D loss: 1.399632\n",
            "Step 4912: G loss: 27.421675 | D loss: 1.397429\n",
            "Step 4913: G loss: 20.734421 | D loss: 1.397493\n",
            "Step 4914: G loss: 23.614809 | D loss: 1.398185\n",
            "Step 4915: G loss: 26.770269 | D loss: 1.397364\n",
            "Step 4916: G loss: 27.567450 | D loss: 1.397753\n",
            "Step 4917: G loss: 24.569937 | D loss: 1.398542\n",
            "Step 4918: G loss: 21.784798 | D loss: 1.397455\n",
            "Step 4919: G loss: 19.887407 | D loss: 1.397294\n",
            "Step 4920: G loss: 25.949493 | D loss: 1.397535\n",
            "Step 4921: G loss: 28.317089 | D loss: 1.398799\n",
            "Step 4922: G loss: 23.383604 | D loss: 1.397602\n",
            "Step 4923: G loss: 20.793159 | D loss: 1.397315\n",
            "Step 4924: G loss: 23.384401 | D loss: 1.397616\n",
            "Step 4925: G loss: 20.732254 | D loss: 1.397217\n",
            "Step 4926: G loss: 22.300417 | D loss: 1.399219\n",
            "Step 4927: G loss: 28.473104 | D loss: 1.397774\n",
            "Step 4928: G loss: 32.325680 | D loss: 1.398149\n",
            "Step 4929: G loss: 19.555397 | D loss: 1.399227\n",
            "Step 4930: G loss: 31.934593 | D loss: 1.397340\n",
            "Step 4931: G loss: 29.585194 | D loss: 1.397681\n",
            "Step 4932: G loss: 30.837828 | D loss: 1.397155\n",
            "Step 4933: G loss: 27.197601 | D loss: 1.397161\n",
            "Step 4934: G loss: 23.084784 | D loss: 1.397346\n",
            "Step 4935: G loss: 25.882845 | D loss: 1.397290\n",
            "Step 4936: G loss: 24.111353 | D loss: 1.398934\n",
            "Step 4937: G loss: 19.330639 | D loss: 1.399995\n",
            "Step 4938: G loss: 18.463043 | D loss: 1.398148\n",
            "Step 4939: G loss: 32.135624 | D loss: 1.399111\n",
            "Step 4940: G loss: 31.435135 | D loss: 1.398181\n",
            "Step 4941: G loss: 17.469185 | D loss: 1.398961\n",
            "Step 4942: G loss: 16.550180 | D loss: 1.398052\n",
            "Step 4943: G loss: 28.300953 | D loss: 1.397057\n",
            "Step 4944: G loss: 20.904533 | D loss: 1.397061\n",
            "Step 4945: G loss: 29.350567 | D loss: 1.397821\n",
            "Step 4946: G loss: 19.861319 | D loss: 1.397031\n",
            "Step 4947: G loss: 21.475924 | D loss: 1.399855\n",
            "Step 4948: G loss: 22.368988 | D loss: 1.397456\n",
            "Step 4949: G loss: 30.593027 | D loss: 1.397111\n",
            "Step 4950: G loss: 28.034435 | D loss: 1.398399\n",
            "Step 4951: G loss: 30.745110 | D loss: 1.398875\n",
            "Step 4952: G loss: 22.892019 | D loss: 1.397889\n",
            "Step 4953: G loss: 24.766754 | D loss: 1.398137\n",
            "Step 4954: G loss: 28.296495 | D loss: 1.396968\n",
            "Step 4955: G loss: 25.966110 | D loss: 1.398733\n",
            "Step 4956: G loss: 38.603806 | D loss: 1.397233\n",
            "Step 4957: G loss: 21.887157 | D loss: 1.398592\n",
            "Step 4958: G loss: 28.759956 | D loss: 1.397977\n",
            "Step 4959: G loss: 23.475674 | D loss: 1.397074\n",
            "Step 4960: G loss: 23.540524 | D loss: 1.398313\n",
            "Step 4961: G loss: 28.652859 | D loss: 1.396868\n",
            "Step 4962: G loss: 23.686104 | D loss: 1.397681\n",
            "Step 4963: G loss: 26.509293 | D loss: 1.396887\n",
            "Step 4964: G loss: 20.738104 | D loss: 1.396924\n",
            "Step 4965: G loss: 27.966246 | D loss: 1.397897\n",
            "Step 4966: G loss: 27.967018 | D loss: 1.396834\n",
            "Step 4967: G loss: 20.420946 | D loss: 1.397014\n",
            "Step 4968: G loss: 25.274403 | D loss: 1.398429\n",
            "Step 4969: G loss: 22.552002 | D loss: 1.398624\n",
            "Step 4970: G loss: 29.069454 | D loss: 1.396793\n",
            "Step 4971: G loss: 38.245224 | D loss: 1.397451\n",
            "Step 4972: G loss: 26.038239 | D loss: 1.396987\n",
            "Step 4973: G loss: 25.013046 | D loss: 1.398259\n",
            "Step 4974: G loss: 40.325874 | D loss: 1.396744\n",
            "Step 4975: G loss: 28.703592 | D loss: 1.396772\n",
            "Step 4976: G loss: 30.896097 | D loss: 1.396917\n",
            "Step 4977: G loss: 27.495384 | D loss: 1.399052\n",
            "Step 4978: G loss: 17.258360 | D loss: 1.396726\n",
            "Step 4979: G loss: 21.955120 | D loss: 1.397015\n",
            "Step 4980: G loss: 19.992651 | D loss: 1.396690\n",
            "Step 4981: G loss: 24.356672 | D loss: 1.396737\n",
            "Step 4982: G loss: 22.648787 | D loss: 1.397803\n",
            "Step 4983: G loss: 24.793404 | D loss: 1.396665\n",
            "Step 4984: G loss: 35.415886 | D loss: 1.396665\n",
            "Step 4985: G loss: 30.255859 | D loss: 1.398384\n",
            "Step 4986: G loss: 26.925539 | D loss: 1.396758\n",
            "Step 4987: G loss: 26.458544 | D loss: 1.396618\n",
            "Step 4988: G loss: 27.737288 | D loss: 1.397344\n",
            "Step 4989: G loss: 27.008537 | D loss: 1.396621\n",
            "Step 4990: G loss: 32.846016 | D loss: 1.396632\n",
            "Step 4991: G loss: 19.430656 | D loss: 1.396797\n",
            "Step 4992: G loss: 24.483252 | D loss: 1.397637\n",
            "Step 4993: G loss: 41.149536 | D loss: 1.396608\n",
            "Step 4994: G loss: 21.827456 | D loss: 1.396663\n",
            "Step 4995: G loss: 26.989689 | D loss: 1.396559\n",
            "Step 4996: G loss: 19.756561 | D loss: 1.396636\n",
            "Step 4997: G loss: 30.238291 | D loss: 1.396554\n",
            "Step 4998: G loss: 30.581028 | D loss: 1.398151\n",
            "Step 4999: G loss: 22.636839 | D loss: 1.396978\n",
            "Step 5000: G loss: 35.068035 | D loss: 1.397874\n",
            "Step 5001: G loss: 23.495316 | D loss: 1.397486\n",
            "Step 5002: G loss: 25.818216 | D loss: 1.396501\n",
            "Step 5003: G loss: 24.887671 | D loss: 1.397962\n",
            "Step 5004: G loss: 23.362127 | D loss: 1.398992\n",
            "Step 5005: G loss: 25.646477 | D loss: 1.396721\n",
            "Step 5006: G loss: 36.935753 | D loss: 1.397591\n",
            "Step 5007: G loss: 29.944933 | D loss: 1.396710\n",
            "Step 5008: G loss: 34.824303 | D loss: 1.396590\n",
            "Step 5009: G loss: 30.794521 | D loss: 1.396950\n",
            "Step 5010: G loss: 23.017586 | D loss: 1.398435\n",
            "Step 5011: G loss: 25.486284 | D loss: 1.397755\n",
            "Step 5012: G loss: 24.639549 | D loss: 1.399066\n",
            "Step 5013: G loss: 25.927015 | D loss: 1.396686\n",
            "Step 5014: G loss: 23.858870 | D loss: 1.396829\n",
            "Step 5015: G loss: 30.403196 | D loss: 1.396619\n",
            "Step 5016: G loss: 31.361734 | D loss: 1.396984\n",
            "Step 5017: G loss: 20.862526 | D loss: 1.396684\n",
            "Step 5018: G loss: 25.434944 | D loss: 1.396522\n",
            "Step 5019: G loss: 24.430027 | D loss: 1.396972\n",
            "Step 5020: G loss: 24.269934 | D loss: 1.396300\n",
            "Step 5021: G loss: 17.046934 | D loss: 1.396323\n",
            "Step 5022: G loss: 28.915232 | D loss: 1.396803\n",
            "Step 5023: G loss: 37.214317 | D loss: 1.397150\n",
            "Step 5024: G loss: 28.590641 | D loss: 1.396576\n",
            "Step 5025: G loss: 28.097353 | D loss: 1.396589\n",
            "Step 5026: G loss: 27.387571 | D loss: 1.397390\n",
            "Step 5027: G loss: 28.672609 | D loss: 1.396340\n",
            "Step 5028: G loss: 27.635719 | D loss: 1.396279\n",
            "Step 5029: G loss: 24.029520 | D loss: 1.397100\n",
            "Step 5030: G loss: 21.820316 | D loss: 1.397055\n",
            "Step 5031: G loss: 36.617161 | D loss: 1.396300\n",
            "Step 5032: G loss: 24.078671 | D loss: 1.397269\n",
            "Step 5033: G loss: 22.053762 | D loss: 1.396313\n",
            "Step 5034: G loss: 30.287764 | D loss: 1.396539\n",
            "Step 5035: G loss: 21.923479 | D loss: 1.396167\n",
            "Step 5036: G loss: 21.808199 | D loss: 1.396460\n",
            "Step 5037: G loss: 24.811590 | D loss: 1.397405\n",
            "Step 5038: G loss: 25.002197 | D loss: 1.396906\n",
            "Step 5039: G loss: 32.645348 | D loss: 1.397096\n",
            "Step 5040: G loss: 28.842892 | D loss: 1.396241\n",
            "Step 5041: G loss: 32.081024 | D loss: 1.396396\n",
            "Step 5042: G loss: 18.876026 | D loss: 1.396110\n",
            "Step 5043: G loss: 27.550369 | D loss: 1.396118\n",
            "Step 5044: G loss: 23.270123 | D loss: 1.396373\n",
            "Step 5045: G loss: 32.679298 | D loss: 1.398138\n",
            "Step 5046: G loss: 35.883297 | D loss: 1.396065\n",
            "Step 5047: G loss: 31.319748 | D loss: 1.396858\n",
            "Step 5048: G loss: 20.579844 | D loss: 1.396249\n",
            "Step 5049: G loss: 19.538532 | D loss: 1.396910\n",
            "Step 5050: G loss: 26.317720 | D loss: 1.396031\n",
            "Step 5051: G loss: 26.650459 | D loss: 1.396115\n",
            "Step 5052: G loss: 25.461372 | D loss: 1.396011\n",
            "Step 5053: G loss: 28.690466 | D loss: 1.397845\n",
            "Step 5054: G loss: 29.197922 | D loss: 1.397268\n",
            "Step 5055: G loss: 30.002535 | D loss: 1.396254\n",
            "Step 5056: G loss: 39.135906 | D loss: 1.395980\n",
            "Step 5057: G loss: 28.976364 | D loss: 1.397132\n",
            "Step 5058: G loss: 20.080141 | D loss: 1.396001\n",
            "Step 5059: G loss: 28.172138 | D loss: 1.397859\n",
            "Step 5060: G loss: 34.986286 | D loss: 1.397428\n",
            "Step 5061: G loss: 26.957960 | D loss: 1.396336\n",
            "Step 5062: G loss: 25.013184 | D loss: 1.396433\n",
            "Step 5063: G loss: 30.819937 | D loss: 1.396250\n",
            "Step 5064: G loss: 25.302174 | D loss: 1.395910\n",
            "Step 5065: G loss: 25.082443 | D loss: 1.395951\n",
            "Step 5066: G loss: 21.784338 | D loss: 1.396027\n",
            "Step 5067: G loss: 21.950594 | D loss: 1.395868\n",
            "Step 5068: G loss: 28.177595 | D loss: 1.395875\n",
            "Step 5069: G loss: 29.311966 | D loss: 1.395835\n",
            "Step 5070: G loss: 23.627314 | D loss: 1.395875\n",
            "Step 5071: G loss: 25.620764 | D loss: 1.395829\n",
            "Step 5072: G loss: 30.753725 | D loss: 1.395851\n",
            "Step 5073: G loss: 26.415016 | D loss: 1.395804\n",
            "Step 5074: G loss: 35.291706 | D loss: 1.395940\n",
            "Step 5075: G loss: 28.446701 | D loss: 1.397315\n",
            "Step 5076: G loss: 31.822226 | D loss: 1.395914\n",
            "Step 5077: G loss: 34.739536 | D loss: 1.397030\n",
            "Step 5078: G loss: 33.945858 | D loss: 1.395810\n",
            "Step 5079: G loss: 22.034845 | D loss: 1.397070\n",
            "Step 5080: G loss: 26.090940 | D loss: 1.396066\n",
            "Step 5081: G loss: 28.230494 | D loss: 1.395806\n",
            "Step 5082: G loss: 24.440741 | D loss: 1.396348\n",
            "Step 5083: G loss: 32.523636 | D loss: 1.396610\n",
            "Step 5084: G loss: 21.279299 | D loss: 1.397380\n",
            "Step 5085: G loss: 29.346874 | D loss: 1.395908\n",
            "Step 5086: G loss: 22.101517 | D loss: 1.397507\n",
            "Step 5087: G loss: 22.938545 | D loss: 1.395759\n",
            "Step 5088: G loss: 26.321356 | D loss: 1.397233\n",
            "Step 5089: G loss: 28.592136 | D loss: 1.399063\n",
            "Step 5090: G loss: 34.929184 | D loss: 1.397009\n",
            "Step 5091: G loss: 28.523127 | D loss: 1.397603\n",
            "Step 5092: G loss: 18.864157 | D loss: 1.395797\n",
            "Step 5093: G loss: 29.315176 | D loss: 1.395608\n",
            "Step 5094: G loss: 28.781603 | D loss: 1.395927\n",
            "Step 5095: G loss: 27.974661 | D loss: 1.396419\n",
            "Step 5096: G loss: 30.239021 | D loss: 1.396258\n",
            "Step 5097: G loss: 25.815310 | D loss: 1.395962\n",
            "Step 5098: G loss: 22.129898 | D loss: 1.397224\n",
            "Step 5099: G loss: 23.734468 | D loss: 1.395951\n",
            "Step 5100: G loss: 22.587603 | D loss: 1.395827\n",
            "Step 5101: G loss: 19.993069 | D loss: 1.395530\n",
            "Step 5102: G loss: 34.778599 | D loss: 1.396289\n",
            "Step 5103: G loss: 23.430750 | D loss: 1.397365\n",
            "Step 5104: G loss: 30.451153 | D loss: 1.395607\n",
            "Step 5105: G loss: 24.828079 | D loss: 1.396994\n",
            "Step 5106: G loss: 26.527721 | D loss: 1.395479\n",
            "Step 5107: G loss: 28.581562 | D loss: 1.396103\n",
            "Step 5108: G loss: 38.236076 | D loss: 1.396770\n",
            "Step 5109: G loss: 27.555866 | D loss: 1.395937\n",
            "Step 5110: G loss: 21.579910 | D loss: 1.395709\n",
            "Step 5111: G loss: 18.688173 | D loss: 1.395458\n",
            "Step 5112: G loss: 29.299917 | D loss: 1.395428\n",
            "Step 5113: G loss: 29.686867 | D loss: 1.396536\n",
            "Step 5114: G loss: 39.399048 | D loss: 1.395398\n",
            "Step 5115: G loss: 27.336975 | D loss: 1.395496\n",
            "Step 5116: G loss: 29.774662 | D loss: 1.395400\n",
            "Step 5117: G loss: 23.235569 | D loss: 1.395386\n",
            "Step 5118: G loss: 25.655207 | D loss: 1.395401\n",
            "Step 5119: G loss: 27.243914 | D loss: 1.395741\n",
            "Step 5120: G loss: 21.014565 | D loss: 1.395690\n",
            "Step 5121: G loss: 31.667486 | D loss: 1.395370\n",
            "Step 5122: G loss: 31.776701 | D loss: 1.396016\n",
            "Step 5123: G loss: 26.722980 | D loss: 1.395396\n",
            "Step 5124: G loss: 20.288290 | D loss: 1.396107\n",
            "Step 5125: G loss: 18.251162 | D loss: 1.395373\n",
            "Step 5126: G loss: 32.742992 | D loss: 1.395339\n",
            "Step 5127: G loss: 29.006172 | D loss: 1.397902\n",
            "Step 5128: G loss: 42.327263 | D loss: 1.396075\n",
            "Step 5129: G loss: 23.242199 | D loss: 1.395965\n",
            "Step 5130: G loss: 26.023628 | D loss: 1.395259\n",
            "Step 5131: G loss: 25.357775 | D loss: 1.397141\n",
            "Step 5132: G loss: 23.224466 | D loss: 1.395584\n",
            "Step 5133: G loss: 23.441551 | D loss: 1.395522\n",
            "Step 5134: G loss: 25.911020 | D loss: 1.395365\n",
            "Step 5135: G loss: 22.463705 | D loss: 1.395866\n",
            "Step 5136: G loss: 22.171480 | D loss: 1.395308\n",
            "Step 5137: G loss: 25.656363 | D loss: 1.396130\n",
            "Step 5138: G loss: 19.149246 | D loss: 1.395198\n",
            "Step 5139: G loss: 21.520140 | D loss: 1.395775\n",
            "Step 5140: G loss: 33.698189 | D loss: 1.396678\n",
            "Step 5141: G loss: 26.019499 | D loss: 1.395164\n",
            "Step 5142: G loss: 22.609804 | D loss: 1.395406\n",
            "Step 5143: G loss: 33.922680 | D loss: 1.395190\n",
            "Step 5144: G loss: 22.797874 | D loss: 1.395169\n",
            "Step 5145: G loss: 20.635309 | D loss: 1.395988\n",
            "Step 5146: G loss: 21.609602 | D loss: 1.395728\n",
            "Step 5147: G loss: 25.706545 | D loss: 1.395797\n",
            "Step 5148: G loss: 22.613773 | D loss: 1.395161\n",
            "Step 5149: G loss: 19.798246 | D loss: 1.395223\n",
            "Step 5150: G loss: 22.679058 | D loss: 1.395765\n",
            "Step 5151: G loss: 16.810154 | D loss: 1.395206\n",
            "Step 5152: G loss: 26.936031 | D loss: 1.395085\n",
            "Step 5153: G loss: 22.741322 | D loss: 1.395155\n",
            "Step 5154: G loss: 19.181192 | D loss: 1.395439\n",
            "Step 5155: G loss: 23.186535 | D loss: 1.395203\n",
            "Step 5156: G loss: 31.843864 | D loss: 1.395014\n",
            "Step 5157: G loss: 20.663048 | D loss: 1.395148\n",
            "Step 5158: G loss: 21.691259 | D loss: 1.395205\n",
            "Step 5159: G loss: 23.950993 | D loss: 1.396277\n",
            "Step 5160: G loss: 26.002859 | D loss: 1.396106\n",
            "Step 5161: G loss: 25.220093 | D loss: 1.395657\n",
            "Step 5162: G loss: 26.895887 | D loss: 1.395311\n",
            "Step 5163: G loss: 21.746601 | D loss: 1.396268\n",
            "Step 5164: G loss: 20.195597 | D loss: 1.395601\n",
            "Step 5165: G loss: 24.471331 | D loss: 1.395808\n",
            "Step 5166: G loss: 24.681250 | D loss: 1.394989\n",
            "Step 5167: G loss: 30.056181 | D loss: 1.394903\n",
            "Step 5168: G loss: 13.500391 | D loss: 1.394912\n",
            "Step 5169: G loss: 20.498497 | D loss: 1.395141\n",
            "Step 5170: G loss: 40.467209 | D loss: 1.395130\n",
            "Step 5171: G loss: 19.364943 | D loss: 1.394889\n",
            "Step 5172: G loss: 29.406506 | D loss: 1.394861\n",
            "Step 5173: G loss: 31.135427 | D loss: 1.395054\n",
            "Step 5174: G loss: 24.082743 | D loss: 1.394882\n",
            "Step 5175: G loss: 32.221478 | D loss: 1.395517\n",
            "Step 5176: G loss: 23.876595 | D loss: 1.395965\n",
            "Step 5177: G loss: 21.596617 | D loss: 1.394816\n",
            "Step 5178: G loss: 21.338058 | D loss: 1.395094\n",
            "Step 5179: G loss: 31.871290 | D loss: 1.395027\n",
            "Step 5180: G loss: 23.616831 | D loss: 1.395061\n",
            "Step 5181: G loss: 28.997154 | D loss: 1.394812\n",
            "Step 5182: G loss: 29.871967 | D loss: 1.394990\n",
            "Step 5183: G loss: 21.448050 | D loss: 1.395962\n",
            "Step 5184: G loss: 21.215748 | D loss: 1.394777\n",
            "Step 5185: G loss: 29.787449 | D loss: 1.395014\n",
            "Step 5186: G loss: 27.368307 | D loss: 1.394865\n",
            "Step 5187: G loss: 34.689430 | D loss: 1.394884\n",
            "Step 5188: G loss: 22.549398 | D loss: 1.394737\n",
            "Step 5189: G loss: 27.252630 | D loss: 1.395470\n",
            "Step 5190: G loss: 25.307758 | D loss: 1.394870\n",
            "Step 5191: G loss: 25.270460 | D loss: 1.395578\n",
            "Step 5192: G loss: 19.400356 | D loss: 1.395736\n",
            "Step 5193: G loss: 34.301109 | D loss: 1.395228\n",
            "Step 5194: G loss: 35.429882 | D loss: 1.394807\n",
            "Step 5195: G loss: 19.910343 | D loss: 1.394662\n",
            "Step 5196: G loss: 31.308678 | D loss: 1.394693\n",
            "Step 5197: G loss: 19.703957 | D loss: 1.394683\n",
            "Step 5198: G loss: 26.547750 | D loss: 1.394879\n",
            "Step 5199: G loss: 22.367441 | D loss: 1.394645\n",
            "Step 5200: G loss: 20.761845 | D loss: 1.395020\n",
            "Step 5201: G loss: 24.131062 | D loss: 1.394685\n",
            "Step 5202: G loss: 24.931189 | D loss: 1.395482\n",
            "Step 5203: G loss: 23.783983 | D loss: 1.396486\n",
            "Step 5204: G loss: 36.099140 | D loss: 1.395691\n",
            "Step 5205: G loss: 30.716253 | D loss: 1.394698\n",
            "Step 5206: G loss: 24.853819 | D loss: 1.394564\n",
            "Step 5207: G loss: 24.945219 | D loss: 1.394541\n",
            "Step 5208: G loss: 20.331562 | D loss: 1.394611\n",
            "Step 5209: G loss: 19.861198 | D loss: 1.395353\n",
            "Step 5210: G loss: 25.147861 | D loss: 1.394642\n",
            "Step 5211: G loss: 36.912983 | D loss: 1.394564\n",
            "Step 5212: G loss: 32.143208 | D loss: 1.394565\n",
            "Step 5213: G loss: 27.997713 | D loss: 1.394539\n",
            "Step 5214: G loss: 25.354959 | D loss: 1.395457\n",
            "Step 5215: G loss: 25.975931 | D loss: 1.395549\n",
            "Step 5216: G loss: 42.178699 | D loss: 1.395634\n",
            "Step 5217: G loss: 33.121696 | D loss: 1.395608\n",
            "Step 5218: G loss: 27.879917 | D loss: 1.394467\n",
            "Step 5219: G loss: 22.998810 | D loss: 1.395615\n",
            "Step 5220: G loss: 27.379688 | D loss: 1.395599\n",
            "Step 5221: G loss: 31.694916 | D loss: 1.394466\n",
            "Step 5222: G loss: 32.154350 | D loss: 1.394426\n",
            "Step 5223: G loss: 28.125637 | D loss: 1.394618\n",
            "Step 5224: G loss: 20.193821 | D loss: 1.395446\n",
            "Step 5225: G loss: 27.529411 | D loss: 1.395203\n",
            "Step 5226: G loss: 33.028027 | D loss: 1.395348\n",
            "Step 5227: G loss: 21.965948 | D loss: 1.394372\n",
            "Step 5228: G loss: 27.578791 | D loss: 1.394512\n",
            "Step 5229: G loss: 26.819450 | D loss: 1.394424\n",
            "Step 5230: G loss: 18.825125 | D loss: 1.394597\n",
            "Step 5231: G loss: 27.714943 | D loss: 1.394346\n",
            "Step 5232: G loss: 22.235952 | D loss: 1.394365\n",
            "Step 5233: G loss: 23.285109 | D loss: 1.394781\n",
            "Step 5234: G loss: 24.757168 | D loss: 1.394496\n",
            "Step 5235: G loss: 24.149742 | D loss: 1.394598\n",
            "Step 5236: G loss: 19.521952 | D loss: 1.394281\n",
            "Step 5237: G loss: 17.361654 | D loss: 1.394876\n",
            "Step 5238: G loss: 27.192781 | D loss: 1.394577\n",
            "Step 5239: G loss: 19.045059 | D loss: 1.396083\n",
            "Step 5240: G loss: 28.354610 | D loss: 1.395558\n",
            "Step 5241: G loss: 32.554596 | D loss: 1.394225\n",
            "Step 5242: G loss: 16.894342 | D loss: 1.394924\n",
            "Step 5243: G loss: 32.083981 | D loss: 1.394598\n",
            "Step 5244: G loss: 31.443262 | D loss: 1.394379\n",
            "Step 5245: G loss: 29.164473 | D loss: 1.394191\n",
            "Step 5246: G loss: 21.996716 | D loss: 1.394251\n",
            "Step 5247: G loss: 25.005043 | D loss: 1.394234\n",
            "Step 5248: G loss: 23.512047 | D loss: 1.394163\n",
            "Step 5249: G loss: 32.634079 | D loss: 1.394797\n",
            "Step 5250: G loss: 24.506554 | D loss: 1.394651\n",
            "Step 5251: G loss: 27.817127 | D loss: 1.394865\n",
            "Step 5252: G loss: 19.091669 | D loss: 1.395758\n",
            "Step 5253: G loss: 22.758356 | D loss: 1.394127\n",
            "Step 5254: G loss: 37.085075 | D loss: 1.394129\n",
            "Step 5255: G loss: 23.383802 | D loss: 1.394092\n",
            "Step 5256: G loss: 32.315922 | D loss: 1.394097\n",
            "Step 5257: G loss: 21.864841 | D loss: 1.394081\n",
            "Step 5258: G loss: 21.805155 | D loss: 1.394112\n",
            "Step 5259: G loss: 18.083126 | D loss: 1.395311\n",
            "Step 5260: G loss: 23.274052 | D loss: 1.394701\n",
            "Step 5261: G loss: 24.208822 | D loss: 1.394281\n",
            "Step 5262: G loss: 21.936888 | D loss: 1.394828\n",
            "Step 5263: G loss: 29.859751 | D loss: 1.394491\n",
            "Step 5264: G loss: 23.956018 | D loss: 1.395524\n",
            "Step 5265: G loss: 26.018291 | D loss: 1.394013\n",
            "Step 5266: G loss: 22.223478 | D loss: 1.394010\n",
            "Step 5267: G loss: 28.313606 | D loss: 1.394688\n",
            "Step 5268: G loss: 31.530771 | D loss: 1.394075\n",
            "Step 5269: G loss: 18.853268 | D loss: 1.395024\n",
            "Step 5270: G loss: 29.851824 | D loss: 1.393965\n",
            "Step 5271: G loss: 23.393688 | D loss: 1.394000\n",
            "Step 5272: G loss: 31.338673 | D loss: 1.393959\n",
            "Step 5273: G loss: 20.837824 | D loss: 1.393965\n",
            "Step 5274: G loss: 31.610741 | D loss: 1.394530\n",
            "Step 5275: G loss: 34.112316 | D loss: 1.393919\n",
            "Step 5276: G loss: 20.430122 | D loss: 1.394090\n",
            "Step 5277: G loss: 25.512592 | D loss: 1.394058\n",
            "Step 5278: G loss: 30.164650 | D loss: 1.394648\n",
            "Step 5279: G loss: 19.035192 | D loss: 1.394130\n",
            "Step 5280: G loss: 26.007530 | D loss: 1.394451\n",
            "Step 5281: G loss: 28.574842 | D loss: 1.393855\n",
            "Step 5282: G loss: 30.678308 | D loss: 1.394454\n",
            "Step 5283: G loss: 27.473587 | D loss: 1.393949\n",
            "Step 5284: G loss: 26.567741 | D loss: 1.393967\n",
            "Step 5285: G loss: 31.632734 | D loss: 1.393938\n",
            "Step 5286: G loss: 19.771568 | D loss: 1.395010\n",
            "Step 5287: G loss: 39.288605 | D loss: 1.393813\n",
            "Step 5288: G loss: 23.291414 | D loss: 1.394147\n",
            "Step 5289: G loss: 21.842329 | D loss: 1.394806\n",
            "Step 5290: G loss: 26.781097 | D loss: 1.393799\n",
            "Step 5291: G loss: 20.879473 | D loss: 1.393916\n",
            "Step 5292: G loss: 21.983179 | D loss: 1.394082\n",
            "Step 5293: G loss: 24.990057 | D loss: 1.393753\n",
            "Step 5294: G loss: 26.493380 | D loss: 1.393881\n",
            "Step 5295: G loss: 23.626862 | D loss: 1.394294\n",
            "Step 5296: G loss: 20.360559 | D loss: 1.393753\n",
            "Step 5297: G loss: 20.716568 | D loss: 1.393714\n",
            "Step 5298: G loss: 24.853014 | D loss: 1.393738\n",
            "Step 5299: G loss: 27.344910 | D loss: 1.394431\n",
            "Step 5300: G loss: 21.726463 | D loss: 1.393763\n",
            "Step 5301: G loss: 19.361547 | D loss: 1.393696\n",
            "Step 5302: G loss: 22.988739 | D loss: 1.393732\n",
            "Step 5303: G loss: 21.173258 | D loss: 1.393657\n",
            "Step 5304: G loss: 22.399710 | D loss: 1.394623\n",
            "Step 5305: G loss: 26.580730 | D loss: 1.393786\n",
            "Step 5306: G loss: 31.617094 | D loss: 1.394215\n",
            "Step 5307: G loss: 19.777859 | D loss: 1.394551\n",
            "Step 5308: G loss: 31.590313 | D loss: 1.393720\n",
            "Step 5309: G loss: 29.440815 | D loss: 1.393781\n",
            "Step 5310: G loss: 29.389067 | D loss: 1.393597\n",
            "Step 5311: G loss: 26.707195 | D loss: 1.393587\n",
            "Step 5312: G loss: 21.904606 | D loss: 1.393681\n",
            "Step 5313: G loss: 26.226610 | D loss: 1.393644\n",
            "Step 5314: G loss: 23.869635 | D loss: 1.394110\n",
            "Step 5315: G loss: 18.762054 | D loss: 1.394786\n",
            "Step 5316: G loss: 17.569021 | D loss: 1.393612\n",
            "Step 5317: G loss: 30.261925 | D loss: 1.394423\n",
            "Step 5318: G loss: 31.389032 | D loss: 1.393706\n",
            "Step 5319: G loss: 17.378309 | D loss: 1.394029\n",
            "Step 5320: G loss: 16.137804 | D loss: 1.393613\n",
            "Step 5321: G loss: 27.163799 | D loss: 1.393500\n",
            "Step 5322: G loss: 21.568039 | D loss: 1.393492\n",
            "Step 5323: G loss: 28.879770 | D loss: 1.393670\n",
            "Step 5324: G loss: 19.360788 | D loss: 1.393477\n",
            "Step 5325: G loss: 20.939919 | D loss: 1.394452\n",
            "Step 5326: G loss: 22.115648 | D loss: 1.393773\n",
            "Step 5327: G loss: 27.215273 | D loss: 1.393465\n",
            "Step 5328: G loss: 26.023926 | D loss: 1.394005\n",
            "Step 5329: G loss: 27.280848 | D loss: 1.394359\n",
            "Step 5330: G loss: 22.090752 | D loss: 1.393679\n",
            "Step 5331: G loss: 23.388191 | D loss: 1.393599\n",
            "Step 5332: G loss: 26.322403 | D loss: 1.393414\n",
            "Step 5333: G loss: 25.350288 | D loss: 1.394092\n",
            "Step 5334: G loss: 37.826786 | D loss: 1.393531\n",
            "Step 5335: G loss: 21.247730 | D loss: 1.394182\n",
            "Step 5336: G loss: 23.706797 | D loss: 1.393693\n",
            "Step 5337: G loss: 22.345936 | D loss: 1.393438\n",
            "Step 5338: G loss: 20.249783 | D loss: 1.394136\n",
            "Step 5339: G loss: 29.390680 | D loss: 1.393341\n",
            "Step 5340: G loss: 22.256874 | D loss: 1.393722\n",
            "Step 5341: G loss: 26.500751 | D loss: 1.393379\n",
            "Step 5342: G loss: 20.251135 | D loss: 1.393598\n",
            "Step 5343: G loss: 26.101057 | D loss: 1.393583\n",
            "Step 5344: G loss: 25.306608 | D loss: 1.393298\n",
            "Step 5345: G loss: 21.239388 | D loss: 1.393533\n",
            "Step 5346: G loss: 22.322174 | D loss: 1.394009\n",
            "Step 5347: G loss: 20.771687 | D loss: 1.394122\n",
            "Step 5348: G loss: 28.034477 | D loss: 1.393257\n",
            "Step 5349: G loss: 36.693619 | D loss: 1.393473\n",
            "Step 5350: G loss: 25.303461 | D loss: 1.393301\n",
            "Step 5351: G loss: 25.171389 | D loss: 1.393509\n",
            "Step 5352: G loss: 37.588177 | D loss: 1.393220\n",
            "Step 5353: G loss: 26.492376 | D loss: 1.393219\n",
            "Step 5354: G loss: 30.888758 | D loss: 1.393242\n",
            "Step 5355: G loss: 24.468103 | D loss: 1.394175\n",
            "Step 5356: G loss: 17.667805 | D loss: 1.393187\n",
            "Step 5357: G loss: 22.006651 | D loss: 1.393558\n",
            "Step 5358: G loss: 20.697519 | D loss: 1.393173\n",
            "Step 5359: G loss: 24.669180 | D loss: 1.393182\n",
            "Step 5360: G loss: 23.103720 | D loss: 1.393387\n",
            "Step 5361: G loss: 22.758984 | D loss: 1.393145\n",
            "Step 5362: G loss: 32.866329 | D loss: 1.393141\n",
            "Step 5363: G loss: 28.536608 | D loss: 1.394022\n",
            "Step 5364: G loss: 24.973436 | D loss: 1.393142\n",
            "Step 5365: G loss: 21.614286 | D loss: 1.393105\n",
            "Step 5366: G loss: 28.319901 | D loss: 1.393525\n",
            "Step 5367: G loss: 26.063068 | D loss: 1.393094\n",
            "Step 5368: G loss: 30.861296 | D loss: 1.393088\n",
            "Step 5369: G loss: 18.425938 | D loss: 1.393124\n",
            "Step 5370: G loss: 24.708633 | D loss: 1.393591\n",
            "Step 5371: G loss: 39.213001 | D loss: 1.393070\n",
            "Step 5372: G loss: 22.201046 | D loss: 1.393520\n",
            "Step 5373: G loss: 27.555822 | D loss: 1.393044\n",
            "Step 5374: G loss: 20.069187 | D loss: 1.393092\n",
            "Step 5375: G loss: 30.684134 | D loss: 1.393026\n",
            "Step 5376: G loss: 29.029257 | D loss: 1.393707\n",
            "Step 5377: G loss: 21.923401 | D loss: 1.393407\n",
            "Step 5378: G loss: 34.093094 | D loss: 1.393613\n",
            "Step 5379: G loss: 22.744293 | D loss: 1.393315\n",
            "Step 5380: G loss: 26.892878 | D loss: 1.393012\n",
            "Step 5381: G loss: 23.771839 | D loss: 1.393322\n",
            "Step 5382: G loss: 22.160751 | D loss: 1.393612\n",
            "Step 5383: G loss: 27.780735 | D loss: 1.392992\n",
            "Step 5384: G loss: 37.403748 | D loss: 1.393086\n",
            "Step 5385: G loss: 29.060839 | D loss: 1.392991\n",
            "Step 5386: G loss: 35.118664 | D loss: 1.392947\n",
            "Step 5387: G loss: 31.898800 | D loss: 1.393018\n",
            "Step 5388: G loss: 22.032633 | D loss: 1.393479\n",
            "Step 5389: G loss: 25.617264 | D loss: 1.393303\n",
            "Step 5390: G loss: 22.798540 | D loss: 1.393994\n",
            "Step 5391: G loss: 25.795685 | D loss: 1.393070\n",
            "Step 5392: G loss: 25.266317 | D loss: 1.392952\n",
            "Step 5393: G loss: 29.282036 | D loss: 1.392933\n",
            "Step 5394: G loss: 31.836040 | D loss: 1.393077\n",
            "Step 5395: G loss: 21.125700 | D loss: 1.392872\n",
            "Step 5396: G loss: 23.686077 | D loss: 1.392863\n",
            "Step 5397: G loss: 22.509964 | D loss: 1.392857\n",
            "Step 5398: G loss: 23.602343 | D loss: 1.392822\n",
            "Step 5399: G loss: 16.989979 | D loss: 1.392821\n",
            "Step 5400: G loss: 28.948666 | D loss: 1.392957\n",
            "Step 5401: G loss: 34.807030 | D loss: 1.392980\n",
            "Step 5402: G loss: 27.586664 | D loss: 1.392865\n",
            "Step 5403: G loss: 31.885471 | D loss: 1.392833\n",
            "Step 5404: G loss: 26.268276 | D loss: 1.393074\n",
            "Step 5405: G loss: 26.924751 | D loss: 1.392798\n",
            "Step 5406: G loss: 24.856495 | D loss: 1.392782\n",
            "Step 5407: G loss: 20.595243 | D loss: 1.392926\n",
            "Step 5408: G loss: 21.695915 | D loss: 1.392922\n",
            "Step 5409: G loss: 34.617710 | D loss: 1.392830\n",
            "Step 5410: G loss: 23.624125 | D loss: 1.393013\n",
            "Step 5411: G loss: 20.883629 | D loss: 1.392910\n",
            "Step 5412: G loss: 28.438906 | D loss: 1.392834\n",
            "Step 5413: G loss: 20.273035 | D loss: 1.392694\n",
            "Step 5414: G loss: 21.532768 | D loss: 1.392731\n",
            "Step 5415: G loss: 23.169695 | D loss: 1.393067\n",
            "Step 5416: G loss: 26.823084 | D loss: 1.393065\n",
            "Step 5417: G loss: 29.969936 | D loss: 1.393114\n",
            "Step 5418: G loss: 28.851505 | D loss: 1.392921\n",
            "Step 5419: G loss: 31.540104 | D loss: 1.392856\n",
            "Step 5420: G loss: 18.632614 | D loss: 1.392651\n",
            "Step 5421: G loss: 24.564739 | D loss: 1.392665\n",
            "Step 5422: G loss: 24.628471 | D loss: 1.392725\n",
            "Step 5423: G loss: 31.503136 | D loss: 1.393553\n",
            "Step 5424: G loss: 31.799957 | D loss: 1.392608\n",
            "Step 5425: G loss: 29.478540 | D loss: 1.392894\n",
            "Step 5426: G loss: 20.748617 | D loss: 1.392657\n",
            "Step 5427: G loss: 23.340160 | D loss: 1.392703\n",
            "Step 5428: G loss: 24.322531 | D loss: 1.392568\n",
            "Step 5429: G loss: 25.546942 | D loss: 1.392697\n",
            "Step 5430: G loss: 23.991968 | D loss: 1.392548\n",
            "Step 5431: G loss: 28.044666 | D loss: 1.393343\n",
            "Step 5432: G loss: 28.731260 | D loss: 1.393070\n",
            "Step 5433: G loss: 28.858021 | D loss: 1.392575\n",
            "Step 5434: G loss: 33.827366 | D loss: 1.392515\n",
            "Step 5435: G loss: 30.526384 | D loss: 1.393076\n",
            "Step 5436: G loss: 20.071037 | D loss: 1.392513\n",
            "Step 5437: G loss: 25.798864 | D loss: 1.392727\n",
            "Step 5438: G loss: 33.873909 | D loss: 1.393154\n",
            "Step 5439: G loss: 24.030552 | D loss: 1.392962\n",
            "Step 5440: G loss: 24.455519 | D loss: 1.392495\n",
            "Step 5441: G loss: 35.465549 | D loss: 1.392694\n",
            "Step 5442: G loss: 25.184963 | D loss: 1.392477\n",
            "Step 5443: G loss: 25.996212 | D loss: 1.392488\n",
            "Step 5444: G loss: 21.976034 | D loss: 1.392534\n",
            "Step 5445: G loss: 19.964020 | D loss: 1.392428\n",
            "Step 5446: G loss: 27.052193 | D loss: 1.392416\n",
            "Step 5447: G loss: 29.165674 | D loss: 1.392403\n",
            "Step 5448: G loss: 24.168610 | D loss: 1.392408\n",
            "Step 5449: G loss: 25.339842 | D loss: 1.392391\n",
            "Step 5450: G loss: 31.386614 | D loss: 1.392402\n",
            "Step 5451: G loss: 26.503159 | D loss: 1.392372\n",
            "Step 5452: G loss: 32.512703 | D loss: 1.392399\n",
            "Step 5453: G loss: 27.941513 | D loss: 1.393016\n",
            "Step 5454: G loss: 30.763325 | D loss: 1.392396\n",
            "Step 5455: G loss: 32.375431 | D loss: 1.392835\n",
            "Step 5456: G loss: 30.628710 | D loss: 1.392351\n",
            "Step 5457: G loss: 22.479618 | D loss: 1.392617\n",
            "Step 5458: G loss: 25.635307 | D loss: 1.392364\n",
            "Step 5459: G loss: 25.877691 | D loss: 1.392387\n",
            "Step 5460: G loss: 22.946356 | D loss: 1.392515\n",
            "Step 5461: G loss: 26.973974 | D loss: 1.392659\n",
            "Step 5462: G loss: 21.165131 | D loss: 1.392864\n",
            "Step 5463: G loss: 30.475634 | D loss: 1.392535\n",
            "Step 5464: G loss: 20.739708 | D loss: 1.392677\n",
            "Step 5465: G loss: 22.148022 | D loss: 1.392259\n",
            "Step 5466: G loss: 27.196478 | D loss: 1.392787\n",
            "Step 5467: G loss: 27.821085 | D loss: 1.393215\n",
            "Step 5468: G loss: 32.655468 | D loss: 1.392677\n",
            "Step 5469: G loss: 28.100103 | D loss: 1.392706\n",
            "Step 5470: G loss: 21.786366 | D loss: 1.392212\n",
            "Step 5471: G loss: 29.030310 | D loss: 1.392200\n",
            "Step 5472: G loss: 27.178396 | D loss: 1.392259\n",
            "Step 5473: G loss: 28.197908 | D loss: 1.392335\n",
            "Step 5474: G loss: 29.924902 | D loss: 1.392551\n",
            "Step 5475: G loss: 25.437607 | D loss: 1.392175\n",
            "Step 5476: G loss: 21.285526 | D loss: 1.392844\n",
            "Step 5477: G loss: 21.743336 | D loss: 1.392227\n",
            "Step 5478: G loss: 22.672592 | D loss: 1.392202\n",
            "Step 5479: G loss: 18.252867 | D loss: 1.392133\n",
            "Step 5480: G loss: 29.691929 | D loss: 1.392241\n",
            "Step 5481: G loss: 21.419960 | D loss: 1.392823\n",
            "Step 5482: G loss: 29.279776 | D loss: 1.392127\n",
            "Step 5483: G loss: 24.533106 | D loss: 1.392354\n",
            "Step 5484: G loss: 24.239323 | D loss: 1.392090\n",
            "Step 5485: G loss: 27.225996 | D loss: 1.392559\n",
            "Step 5486: G loss: 36.353382 | D loss: 1.392504\n",
            "Step 5487: G loss: 25.203775 | D loss: 1.392192\n",
            "Step 5488: G loss: 22.038359 | D loss: 1.392175\n",
            "Step 5489: G loss: 17.890011 | D loss: 1.392057\n",
            "Step 5490: G loss: 28.640123 | D loss: 1.392042\n",
            "Step 5491: G loss: 30.303114 | D loss: 1.392367\n",
            "Step 5492: G loss: 39.227406 | D loss: 1.392022\n",
            "Step 5493: G loss: 26.990049 | D loss: 1.392110\n",
            "Step 5494: G loss: 26.791088 | D loss: 1.392015\n",
            "Step 5495: G loss: 23.882603 | D loss: 1.392001\n",
            "Step 5496: G loss: 23.324625 | D loss: 1.392003\n",
            "Step 5497: G loss: 24.917482 | D loss: 1.392064\n",
            "Step 5498: G loss: 20.346157 | D loss: 1.392116\n",
            "Step 5499: G loss: 30.925003 | D loss: 1.391986\n",
            "Step 5500: G loss: 32.073059 | D loss: 1.392073\n",
            "Step 5501: G loss: 29.042631 | D loss: 1.391968\n",
            "Step 5502: G loss: 19.970922 | D loss: 1.392115\n",
            "Step 5503: G loss: 17.842091 | D loss: 1.391950\n",
            "Step 5504: G loss: 32.647621 | D loss: 1.391940\n",
            "Step 5505: G loss: 31.139622 | D loss: 1.392193\n",
            "Step 5506: G loss: 34.692867 | D loss: 1.392213\n",
            "Step 5507: G loss: 24.043890 | D loss: 1.391984\n",
            "Step 5508: G loss: 27.236078 | D loss: 1.391895\n",
            "Step 5509: G loss: 23.740715 | D loss: 1.392720\n",
            "Step 5510: G loss: 23.145254 | D loss: 1.392029\n",
            "Step 5511: G loss: 22.401249 | D loss: 1.391933\n",
            "Step 5512: G loss: 25.470551 | D loss: 1.391890\n",
            "Step 5513: G loss: 21.873180 | D loss: 1.392141\n",
            "Step 5514: G loss: 21.864983 | D loss: 1.391859\n",
            "Step 5515: G loss: 25.958963 | D loss: 1.391945\n",
            "Step 5516: G loss: 17.251415 | D loss: 1.391836\n",
            "Step 5517: G loss: 20.599850 | D loss: 1.392060\n",
            "Step 5518: G loss: 34.252533 | D loss: 1.392105\n",
            "Step 5519: G loss: 25.108177 | D loss: 1.391807\n",
            "Step 5520: G loss: 22.610062 | D loss: 1.391933\n",
            "Step 5521: G loss: 35.192993 | D loss: 1.391879\n",
            "Step 5522: G loss: 22.253122 | D loss: 1.391784\n",
            "Step 5523: G loss: 20.566559 | D loss: 1.392170\n",
            "Step 5524: G loss: 19.860666 | D loss: 1.392250\n",
            "Step 5525: G loss: 25.137367 | D loss: 1.391779\n",
            "Step 5526: G loss: 22.183641 | D loss: 1.391770\n",
            "Step 5527: G loss: 19.770281 | D loss: 1.391801\n",
            "Step 5528: G loss: 22.048424 | D loss: 1.391800\n",
            "Step 5529: G loss: 16.011999 | D loss: 1.391730\n",
            "Step 5530: G loss: 27.212002 | D loss: 1.391725\n",
            "Step 5531: G loss: 21.445755 | D loss: 1.391745\n",
            "Step 5532: G loss: 18.415812 | D loss: 1.391844\n",
            "Step 5533: G loss: 21.720322 | D loss: 1.391737\n",
            "Step 5534: G loss: 30.825251 | D loss: 1.391685\n",
            "Step 5535: G loss: 20.101543 | D loss: 1.391710\n",
            "Step 5536: G loss: 21.347515 | D loss: 1.391809\n",
            "Step 5537: G loss: 23.020905 | D loss: 1.392209\n",
            "Step 5538: G loss: 24.547314 | D loss: 1.392076\n",
            "Step 5539: G loss: 24.416239 | D loss: 1.391933\n",
            "Step 5540: G loss: 25.154116 | D loss: 1.391745\n",
            "Step 5541: G loss: 21.319057 | D loss: 1.392181\n",
            "Step 5542: G loss: 21.634100 | D loss: 1.391860\n",
            "Step 5543: G loss: 23.984097 | D loss: 1.391738\n",
            "Step 5544: G loss: 23.843121 | D loss: 1.391633\n",
            "Step 5545: G loss: 28.462055 | D loss: 1.391592\n",
            "Step 5546: G loss: 12.474807 | D loss: 1.391588\n",
            "Step 5547: G loss: 20.623564 | D loss: 1.391704\n",
            "Step 5548: G loss: 39.831306 | D loss: 1.391588\n",
            "Step 5549: G loss: 18.338024 | D loss: 1.391570\n",
            "Step 5550: G loss: 28.638958 | D loss: 1.391554\n",
            "Step 5551: G loss: 28.632431 | D loss: 1.391600\n",
            "Step 5552: G loss: 23.854420 | D loss: 1.391583\n",
            "Step 5553: G loss: 30.981775 | D loss: 1.391785\n",
            "Step 5554: G loss: 23.330050 | D loss: 1.392013\n",
            "Step 5555: G loss: 22.527365 | D loss: 1.391515\n",
            "Step 5556: G loss: 21.865639 | D loss: 1.391637\n",
            "Step 5557: G loss: 31.954954 | D loss: 1.391555\n",
            "Step 5558: G loss: 22.991859 | D loss: 1.391579\n",
            "Step 5559: G loss: 28.337429 | D loss: 1.391488\n",
            "Step 5560: G loss: 30.286085 | D loss: 1.391522\n",
            "Step 5561: G loss: 20.709768 | D loss: 1.391957\n",
            "Step 5562: G loss: 20.072617 | D loss: 1.391466\n",
            "Step 5563: G loss: 28.966658 | D loss: 1.391538\n",
            "Step 5564: G loss: 25.413580 | D loss: 1.391489\n",
            "Step 5565: G loss: 32.216492 | D loss: 1.391632\n",
            "Step 5566: G loss: 23.396002 | D loss: 1.391432\n",
            "Step 5567: G loss: 26.347734 | D loss: 1.391747\n",
            "Step 5568: G loss: 23.135742 | D loss: 1.391452\n",
            "Step 5569: G loss: 23.709110 | D loss: 1.391904\n",
            "Step 5570: G loss: 16.633533 | D loss: 1.391611\n",
            "Step 5571: G loss: 32.260883 | D loss: 1.391716\n",
            "Step 5572: G loss: 34.504494 | D loss: 1.391417\n",
            "Step 5573: G loss: 21.485630 | D loss: 1.391373\n",
            "Step 5574: G loss: 29.426283 | D loss: 1.391418\n",
            "Step 5575: G loss: 18.602732 | D loss: 1.391366\n",
            "Step 5576: G loss: 25.290846 | D loss: 1.391472\n",
            "Step 5577: G loss: 25.520607 | D loss: 1.391343\n",
            "Step 5578: G loss: 20.647892 | D loss: 1.391393\n",
            "Step 5579: G loss: 22.707649 | D loss: 1.391343\n",
            "Step 5580: G loss: 24.018881 | D loss: 1.391630\n",
            "Step 5581: G loss: 23.366428 | D loss: 1.391993\n",
            "Step 5582: G loss: 33.871872 | D loss: 1.391734\n",
            "Step 5583: G loss: 28.263006 | D loss: 1.391355\n",
            "Step 5584: G loss: 25.848385 | D loss: 1.391288\n",
            "Step 5585: G loss: 23.910233 | D loss: 1.391275\n",
            "Step 5586: G loss: 20.676958 | D loss: 1.391541\n",
            "Step 5587: G loss: 18.438530 | D loss: 1.391330\n",
            "Step 5588: G loss: 23.469995 | D loss: 1.391279\n",
            "Step 5589: G loss: 34.964378 | D loss: 1.391248\n",
            "Step 5590: G loss: 29.666798 | D loss: 1.391244\n",
            "Step 5591: G loss: 29.399948 | D loss: 1.391234\n",
            "Step 5592: G loss: 24.718918 | D loss: 1.391301\n",
            "Step 5593: G loss: 23.896044 | D loss: 1.391648\n",
            "Step 5594: G loss: 43.259480 | D loss: 1.391676\n",
            "Step 5595: G loss: 31.323799 | D loss: 1.391503\n",
            "Step 5596: G loss: 26.478670 | D loss: 1.391193\n",
            "Step 5597: G loss: 21.828806 | D loss: 1.391615\n",
            "Step 5598: G loss: 25.636051 | D loss: 1.391627\n",
            "Step 5599: G loss: 30.250902 | D loss: 1.391173\n",
            "Step 5600: G loss: 31.965273 | D loss: 1.391163\n",
            "Step 5601: G loss: 26.894329 | D loss: 1.391242\n",
            "Step 5602: G loss: 19.273712 | D loss: 1.391568\n",
            "Step 5603: G loss: 24.683029 | D loss: 1.391495\n",
            "Step 5604: G loss: 31.736557 | D loss: 1.391222\n",
            "Step 5605: G loss: 22.587128 | D loss: 1.391121\n",
            "Step 5606: G loss: 26.371862 | D loss: 1.391118\n",
            "Step 5607: G loss: 27.525517 | D loss: 1.391115\n",
            "Step 5608: G loss: 18.030294 | D loss: 1.391145\n",
            "Step 5609: G loss: 27.864511 | D loss: 1.391093\n",
            "Step 5610: G loss: 22.192194 | D loss: 1.391099\n",
            "Step 5611: G loss: 21.450916 | D loss: 1.391103\n",
            "Step 5612: G loss: 24.450619 | D loss: 1.391102\n",
            "Step 5613: G loss: 21.090208 | D loss: 1.391112\n",
            "Step 5614: G loss: 18.075893 | D loss: 1.391052\n",
            "Step 5615: G loss: 16.408449 | D loss: 1.391217\n",
            "Step 5616: G loss: 27.017151 | D loss: 1.391098\n",
            "Step 5617: G loss: 19.066353 | D loss: 1.391556\n",
            "Step 5618: G loss: 21.612566 | D loss: 1.391398\n",
            "Step 5619: G loss: 29.365679 | D loss: 1.391018\n",
            "Step 5620: G loss: 16.546612 | D loss: 1.391127\n",
            "Step 5621: G loss: 30.239096 | D loss: 1.391094\n",
            "Step 5622: G loss: 31.559196 | D loss: 1.391017\n",
            "Step 5623: G loss: 26.065166 | D loss: 1.390982\n",
            "Step 5624: G loss: 22.281609 | D loss: 1.391008\n",
            "Step 5625: G loss: 25.318377 | D loss: 1.390969\n",
            "Step 5626: G loss: 22.353071 | D loss: 1.390958\n",
            "Step 5627: G loss: 31.773441 | D loss: 1.391158\n",
            "Step 5628: G loss: 24.157251 | D loss: 1.391015\n",
            "Step 5629: G loss: 28.194084 | D loss: 1.391244\n",
            "Step 5630: G loss: 20.020769 | D loss: 1.391559\n",
            "Step 5631: G loss: 23.045412 | D loss: 1.390922\n",
            "Step 5632: G loss: 36.930111 | D loss: 1.390916\n",
            "Step 5633: G loss: 22.590624 | D loss: 1.390901\n",
            "Step 5634: G loss: 31.993622 | D loss: 1.390897\n",
            "Step 5635: G loss: 20.330391 | D loss: 1.390887\n",
            "Step 5636: G loss: 20.456594 | D loss: 1.390920\n",
            "Step 5637: G loss: 17.132301 | D loss: 1.391317\n",
            "Step 5638: G loss: 22.381973 | D loss: 1.390915\n",
            "Step 5639: G loss: 21.880024 | D loss: 1.390916\n",
            "Step 5640: G loss: 22.558558 | D loss: 1.391177\n",
            "Step 5641: G loss: 30.296661 | D loss: 1.390954\n",
            "Step 5642: G loss: 22.963081 | D loss: 1.391376\n",
            "Step 5643: G loss: 27.283554 | D loss: 1.390832\n",
            "Step 5644: G loss: 21.993685 | D loss: 1.390827\n",
            "Step 5645: G loss: 26.519417 | D loss: 1.390982\n",
            "Step 5646: G loss: 31.188131 | D loss: 1.390848\n",
            "Step 5647: G loss: 18.831446 | D loss: 1.391182\n",
            "Step 5648: G loss: 28.984741 | D loss: 1.390791\n",
            "Step 5649: G loss: 20.211487 | D loss: 1.390795\n",
            "Step 5650: G loss: 31.045563 | D loss: 1.390789\n",
            "Step 5651: G loss: 20.417019 | D loss: 1.390769\n",
            "Step 5652: G loss: 31.928959 | D loss: 1.390971\n",
            "Step 5653: G loss: 32.435734 | D loss: 1.390752\n",
            "Step 5654: G loss: 20.627001 | D loss: 1.390807\n",
            "Step 5655: G loss: 25.140373 | D loss: 1.390824\n",
            "Step 5656: G loss: 32.551254 | D loss: 1.390993\n",
            "Step 5657: G loss: 17.596901 | D loss: 1.390737\n",
            "Step 5658: G loss: 23.916391 | D loss: 1.390947\n",
            "Step 5659: G loss: 29.299217 | D loss: 1.390705\n",
            "Step 5660: G loss: 29.823318 | D loss: 1.391003\n",
            "Step 5661: G loss: 25.731565 | D loss: 1.390710\n",
            "Step 5662: G loss: 24.177195 | D loss: 1.390717\n",
            "Step 5663: G loss: 30.761671 | D loss: 1.390688\n",
            "Step 5664: G loss: 19.636530 | D loss: 1.391000\n",
            "Step 5665: G loss: 38.195995 | D loss: 1.390664\n",
            "Step 5666: G loss: 20.825478 | D loss: 1.390930\n",
            "Step 5667: G loss: 21.388662 | D loss: 1.391023\n",
            "Step 5668: G loss: 26.098717 | D loss: 1.390643\n",
            "Step 5669: G loss: 21.935997 | D loss: 1.390659\n",
            "Step 5670: G loss: 19.635866 | D loss: 1.390636\n",
            "Step 5671: G loss: 25.519974 | D loss: 1.390615\n",
            "Step 5672: G loss: 25.914574 | D loss: 1.390646\n",
            "Step 5673: G loss: 26.043495 | D loss: 1.390707\n",
            "Step 5674: G loss: 20.052034 | D loss: 1.390595\n",
            "Step 5675: G loss: 20.102299 | D loss: 1.390587\n",
            "Step 5676: G loss: 22.344585 | D loss: 1.390597\n",
            "Step 5677: G loss: 25.519203 | D loss: 1.390777\n",
            "Step 5678: G loss: 20.915440 | D loss: 1.390572\n",
            "Step 5679: G loss: 18.463324 | D loss: 1.390563\n",
            "Step 5680: G loss: 23.815552 | D loss: 1.390567\n",
            "Step 5681: G loss: 21.641970 | D loss: 1.390542\n",
            "Step 5682: G loss: 21.454082 | D loss: 1.390854\n",
            "Step 5683: G loss: 26.044594 | D loss: 1.390705\n",
            "Step 5684: G loss: 32.722866 | D loss: 1.390701\n",
            "Step 5685: G loss: 18.803364 | D loss: 1.390848\n",
            "Step 5686: G loss: 30.066227 | D loss: 1.390553\n",
            "Step 5687: G loss: 28.537874 | D loss: 1.390524\n",
            "Step 5688: G loss: 32.727894 | D loss: 1.390491\n",
            "Step 5689: G loss: 25.920233 | D loss: 1.390483\n",
            "Step 5690: G loss: 21.291594 | D loss: 1.390508\n",
            "Step 5691: G loss: 25.220236 | D loss: 1.390505\n",
            "Step 5692: G loss: 23.009390 | D loss: 1.390527\n",
            "Step 5693: G loss: 18.699682 | D loss: 1.390810\n",
            "Step 5694: G loss: 20.716494 | D loss: 1.390470\n",
            "Step 5695: G loss: 27.459991 | D loss: 1.390772\n",
            "Step 5696: G loss: 28.618298 | D loss: 1.390531\n",
            "Step 5697: G loss: 17.828529 | D loss: 1.390551\n",
            "Step 5698: G loss: 17.264582 | D loss: 1.390434\n",
            "Step 5699: G loss: 26.977835 | D loss: 1.390410\n",
            "Step 5700: G loss: 20.341585 | D loss: 1.390404\n",
            "Step 5701: G loss: 26.667555 | D loss: 1.390532\n",
            "Step 5702: G loss: 18.953791 | D loss: 1.390390\n",
            "Step 5703: G loss: 20.456303 | D loss: 1.390651\n",
            "Step 5704: G loss: 20.909813 | D loss: 1.390418\n",
            "Step 5705: G loss: 23.823851 | D loss: 1.390372\n",
            "Step 5706: G loss: 25.426550 | D loss: 1.390547\n",
            "Step 5707: G loss: 27.622301 | D loss: 1.390659\n",
            "Step 5708: G loss: 21.159159 | D loss: 1.390417\n",
            "Step 5709: G loss: 22.637573 | D loss: 1.390425\n",
            "Step 5710: G loss: 27.008869 | D loss: 1.390334\n",
            "Step 5711: G loss: 25.443005 | D loss: 1.390394\n",
            "Step 5712: G loss: 37.376991 | D loss: 1.390378\n",
            "Step 5713: G loss: 21.489658 | D loss: 1.390515\n",
            "Step 5714: G loss: 23.238848 | D loss: 1.390499\n",
            "Step 5715: G loss: 22.744358 | D loss: 1.390325\n",
            "Step 5716: G loss: 22.307295 | D loss: 1.390444\n",
            "Step 5717: G loss: 27.591652 | D loss: 1.390280\n",
            "Step 5718: G loss: 23.536736 | D loss: 1.390401\n",
            "Step 5719: G loss: 25.663691 | D loss: 1.390272\n",
            "Step 5720: G loss: 20.659241 | D loss: 1.390306\n",
            "Step 5721: G loss: 24.692854 | D loss: 1.390288\n",
            "Step 5722: G loss: 27.898306 | D loss: 1.390251\n",
            "Step 5723: G loss: 21.944094 | D loss: 1.390414\n",
            "Step 5724: G loss: 23.640713 | D loss: 1.390483\n",
            "Step 5725: G loss: 20.402897 | D loss: 1.390464\n",
            "Step 5726: G loss: 29.267014 | D loss: 1.390217\n",
            "Step 5727: G loss: 38.196030 | D loss: 1.390254\n",
            "Step 5728: G loss: 26.059250 | D loss: 1.390210\n",
            "Step 5729: G loss: 23.189531 | D loss: 1.390208\n",
            "Step 5730: G loss: 36.441280 | D loss: 1.390188\n",
            "Step 5731: G loss: 26.247454 | D loss: 1.390183\n",
            "Step 5732: G loss: 27.802769 | D loss: 1.390178\n",
            "Step 5733: G loss: 24.259466 | D loss: 1.390439\n",
            "Step 5734: G loss: 16.363384 | D loss: 1.390161\n",
            "Step 5735: G loss: 21.839090 | D loss: 1.390215\n",
            "Step 5736: G loss: 19.229631 | D loss: 1.390146\n",
            "Step 5737: G loss: 22.572048 | D loss: 1.390142\n",
            "Step 5738: G loss: 21.382626 | D loss: 1.390159\n",
            "Step 5739: G loss: 21.828907 | D loss: 1.390126\n",
            "Step 5740: G loss: 30.623499 | D loss: 1.390123\n",
            "Step 5741: G loss: 27.158209 | D loss: 1.390361\n",
            "Step 5742: G loss: 24.918932 | D loss: 1.390108\n",
            "Step 5743: G loss: 17.463463 | D loss: 1.390098\n",
            "Step 5744: G loss: 25.662819 | D loss: 1.390224\n",
            "Step 5745: G loss: 25.944565 | D loss: 1.390085\n",
            "Step 5746: G loss: 29.866291 | D loss: 1.390080\n",
            "Step 5747: G loss: 18.709908 | D loss: 1.390087\n",
            "Step 5748: G loss: 25.328661 | D loss: 1.390240\n",
            "Step 5749: G loss: 37.479118 | D loss: 1.390061\n",
            "Step 5750: G loss: 20.427273 | D loss: 1.390249\n",
            "Step 5751: G loss: 25.346815 | D loss: 1.390045\n",
            "Step 5752: G loss: 21.091398 | D loss: 1.390073\n",
            "Step 5753: G loss: 29.587278 | D loss: 1.390030\n",
            "Step 5754: G loss: 26.718119 | D loss: 1.390262\n",
            "Step 5755: G loss: 20.475849 | D loss: 1.390190\n",
            "Step 5756: G loss: 33.339390 | D loss: 1.390143\n",
            "Step 5757: G loss: 18.905310 | D loss: 1.390056\n",
            "Step 5758: G loss: 25.514837 | D loss: 1.390005\n",
            "Step 5759: G loss: 22.696468 | D loss: 1.390177\n",
            "Step 5760: G loss: 21.971933 | D loss: 1.390018\n",
            "Step 5761: G loss: 24.434826 | D loss: 1.389976\n",
            "Step 5762: G loss: 34.182411 | D loss: 1.389969\n",
            "Step 5763: G loss: 28.067120 | D loss: 1.389964\n",
            "Step 5764: G loss: 32.666550 | D loss: 1.389954\n",
            "Step 5765: G loss: 29.997427 | D loss: 1.389949\n",
            "Step 5766: G loss: 23.045298 | D loss: 1.389969\n",
            "Step 5767: G loss: 23.953068 | D loss: 1.390048\n",
            "Step 5768: G loss: 23.327700 | D loss: 1.390010\n",
            "Step 5769: G loss: 23.006861 | D loss: 1.389938\n",
            "Step 5770: G loss: 22.818455 | D loss: 1.389935\n",
            "Step 5771: G loss: 27.163729 | D loss: 1.389920\n",
            "Step 5772: G loss: 30.174831 | D loss: 1.389941\n",
            "Step 5773: G loss: 20.542992 | D loss: 1.389895\n",
            "Step 5774: G loss: 22.787251 | D loss: 1.389893\n",
            "Step 5775: G loss: 20.861853 | D loss: 1.389882\n",
            "Step 5776: G loss: 23.140318 | D loss: 1.389875\n",
            "Step 5777: G loss: 15.042776 | D loss: 1.389870\n",
            "Step 5778: G loss: 27.635338 | D loss: 1.389888\n",
            "Step 5779: G loss: 31.728209 | D loss: 1.389885\n",
            "Step 5780: G loss: 26.530436 | D loss: 1.389856\n",
            "Step 5781: G loss: 29.101892 | D loss: 1.389868\n",
            "Step 5782: G loss: 25.572859 | D loss: 1.389884\n",
            "Step 5783: G loss: 26.324602 | D loss: 1.389838\n",
            "Step 5784: G loss: 24.809242 | D loss: 1.389824\n",
            "Step 5785: G loss: 20.231464 | D loss: 1.389867\n",
            "Step 5786: G loss: 19.258600 | D loss: 1.389853\n",
            "Step 5787: G loss: 33.589027 | D loss: 1.389810\n",
            "Step 5788: G loss: 22.600443 | D loss: 1.389836\n",
            "Step 5789: G loss: 20.444292 | D loss: 1.389805\n",
            "Step 5790: G loss: 27.746668 | D loss: 1.389823\n",
            "Step 5791: G loss: 19.476061 | D loss: 1.389775\n",
            "Step 5792: G loss: 20.206020 | D loss: 1.389776\n",
            "Step 5793: G loss: 24.102552 | D loss: 1.389903\n",
            "Step 5794: G loss: 26.189558 | D loss: 1.389790\n",
            "Step 5795: G loss: 26.536480 | D loss: 1.389854\n",
            "Step 5796: G loss: 25.565912 | D loss: 1.389747\n",
            "Step 5797: G loss: 29.525059 | D loss: 1.389757\n",
            "Step 5798: G loss: 19.922600 | D loss: 1.389730\n",
            "Step 5799: G loss: 22.848082 | D loss: 1.389726\n",
            "Step 5800: G loss: 22.946323 | D loss: 1.389738\n",
            "Step 5801: G loss: 30.425615 | D loss: 1.389993\n",
            "Step 5802: G loss: 31.024752 | D loss: 1.389703\n",
            "Step 5803: G loss: 28.837675 | D loss: 1.389742\n",
            "Step 5804: G loss: 19.075247 | D loss: 1.389706\n",
            "Step 5805: G loss: 20.064732 | D loss: 1.389719\n",
            "Step 5806: G loss: 23.481159 | D loss: 1.389677\n",
            "Step 5807: G loss: 25.061914 | D loss: 1.389723\n",
            "Step 5808: G loss: 23.246973 | D loss: 1.389664\n",
            "Step 5809: G loss: 25.620710 | D loss: 1.389882\n",
            "Step 5810: G loss: 28.969938 | D loss: 1.389766\n",
            "Step 5811: G loss: 28.886396 | D loss: 1.389658\n",
            "Step 5812: G loss: 30.385122 | D loss: 1.389638\n",
            "Step 5813: G loss: 31.039036 | D loss: 1.389793\n",
            "Step 5814: G loss: 19.260782 | D loss: 1.389629\n",
            "Step 5815: G loss: 24.785763 | D loss: 1.389676\n",
            "Step 5816: G loss: 33.251266 | D loss: 1.389815\n",
            "Step 5817: G loss: 24.164999 | D loss: 1.389753\n",
            "Step 5818: G loss: 22.218336 | D loss: 1.389624\n",
            "Step 5819: G loss: 30.936184 | D loss: 1.389629\n",
            "Step 5820: G loss: 24.030245 | D loss: 1.389587\n",
            "Step 5821: G loss: 26.118835 | D loss: 1.389583\n",
            "Step 5822: G loss: 20.770695 | D loss: 1.389601\n",
            "Step 5823: G loss: 18.740559 | D loss: 1.389568\n",
            "Step 5824: G loss: 26.134787 | D loss: 1.389562\n",
            "Step 5825: G loss: 26.995180 | D loss: 1.389553\n",
            "Step 5826: G loss: 24.158854 | D loss: 1.389549\n",
            "Step 5827: G loss: 24.682634 | D loss: 1.389541\n",
            "Step 5828: G loss: 28.293831 | D loss: 1.389543\n",
            "Step 5829: G loss: 25.296642 | D loss: 1.389528\n",
            "Step 5830: G loss: 33.649574 | D loss: 1.389531\n",
            "Step 5831: G loss: 27.293486 | D loss: 1.389706\n",
            "Step 5832: G loss: 29.284773 | D loss: 1.389517\n",
            "Step 5833: G loss: 32.626507 | D loss: 1.389555\n",
            "Step 5834: G loss: 28.958735 | D loss: 1.389505\n",
            "Step 5835: G loss: 22.194489 | D loss: 1.389568\n",
            "Step 5836: G loss: 25.026899 | D loss: 1.389510\n",
            "Step 5837: G loss: 24.180901 | D loss: 1.389545\n",
            "Step 5838: G loss: 22.164892 | D loss: 1.389511\n",
            "Step 5839: G loss: 26.492172 | D loss: 1.389553\n",
            "Step 5840: G loss: 21.905766 | D loss: 1.389599\n",
            "Step 5841: G loss: 26.155909 | D loss: 1.389495\n",
            "Step 5842: G loss: 22.303709 | D loss: 1.389551\n",
            "Step 5843: G loss: 20.842205 | D loss: 1.389440\n",
            "Step 5844: G loss: 26.142344 | D loss: 1.389583\n",
            "Step 5845: G loss: 24.047750 | D loss: 1.389773\n",
            "Step 5846: G loss: 31.112474 | D loss: 1.389510\n",
            "Step 5847: G loss: 29.643759 | D loss: 1.389688\n",
            "Step 5848: G loss: 19.474428 | D loss: 1.389407\n",
            "Step 5849: G loss: 27.313519 | D loss: 1.389400\n",
            "Step 5850: G loss: 25.816818 | D loss: 1.389401\n",
            "Step 5851: G loss: 28.471479 | D loss: 1.389410\n",
            "Step 5852: G loss: 28.013428 | D loss: 1.389464\n",
            "Step 5853: G loss: 25.302332 | D loss: 1.389377\n",
            "Step 5854: G loss: 20.820009 | D loss: 1.389564\n",
            "Step 5855: G loss: 21.210781 | D loss: 1.389388\n",
            "Step 5856: G loss: 19.900759 | D loss: 1.389372\n",
            "Step 5857: G loss: 17.813126 | D loss: 1.389350\n",
            "Step 5858: G loss: 27.295691 | D loss: 1.389380\n",
            "Step 5859: G loss: 19.599018 | D loss: 1.389526\n",
            "Step 5860: G loss: 29.718599 | D loss: 1.389335\n",
            "Step 5861: G loss: 24.417385 | D loss: 1.389451\n",
            "Step 5862: G loss: 23.431910 | D loss: 1.389318\n",
            "Step 5863: G loss: 27.278446 | D loss: 1.389457\n",
            "Step 5864: G loss: 35.132416 | D loss: 1.389394\n",
            "Step 5865: G loss: 24.518259 | D loss: 1.389386\n",
            "Step 5866: G loss: 21.476963 | D loss: 1.389356\n",
            "Step 5867: G loss: 20.313051 | D loss: 1.389287\n",
            "Step 5868: G loss: 27.115871 | D loss: 1.389281\n",
            "Step 5869: G loss: 30.087994 | D loss: 1.389376\n",
            "Step 5870: G loss: 36.230579 | D loss: 1.389268\n",
            "Step 5871: G loss: 26.713171 | D loss: 1.389273\n",
            "Step 5872: G loss: 26.844234 | D loss: 1.389258\n",
            "Step 5873: G loss: 21.310898 | D loss: 1.389251\n",
            "Step 5874: G loss: 23.116894 | D loss: 1.389248\n",
            "Step 5875: G loss: 23.618803 | D loss: 1.389243\n",
            "Step 5876: G loss: 20.310026 | D loss: 1.389267\n",
            "Step 5877: G loss: 30.651367 | D loss: 1.389229\n",
            "Step 5878: G loss: 29.863508 | D loss: 1.389364\n",
            "Step 5879: G loss: 27.336159 | D loss: 1.389216\n",
            "Step 5880: G loss: 19.275906 | D loss: 1.389278\n",
            "Step 5881: G loss: 17.950787 | D loss: 1.389212\n",
            "Step 5882: G loss: 29.836157 | D loss: 1.389197\n",
            "Step 5883: G loss: 29.814917 | D loss: 1.389287\n",
            "Step 5884: G loss: 36.469078 | D loss: 1.389231\n",
            "Step 5885: G loss: 22.841276 | D loss: 1.389224\n",
            "Step 5886: G loss: 24.885525 | D loss: 1.389172\n",
            "Step 5887: G loss: 23.080956 | D loss: 1.389293\n",
            "Step 5888: G loss: 22.325323 | D loss: 1.389167\n",
            "Step 5889: G loss: 21.934507 | D loss: 1.389168\n",
            "Step 5890: G loss: 24.460991 | D loss: 1.389190\n",
            "Step 5891: G loss: 23.136627 | D loss: 1.389243\n",
            "Step 5892: G loss: 20.504164 | D loss: 1.389136\n",
            "Step 5893: G loss: 24.719923 | D loss: 1.389141\n",
            "Step 5894: G loss: 15.955685 | D loss: 1.389125\n",
            "Step 5895: G loss: 20.254068 | D loss: 1.389191\n",
            "Step 5896: G loss: 32.969952 | D loss: 1.389256\n",
            "Step 5897: G loss: 24.486078 | D loss: 1.389106\n",
            "Step 5898: G loss: 21.664841 | D loss: 1.389180\n",
            "Step 5899: G loss: 34.082596 | D loss: 1.389180\n",
            "Step 5900: G loss: 21.108936 | D loss: 1.389089\n",
            "Step 5901: G loss: 20.160030 | D loss: 1.389140\n",
            "Step 5902: G loss: 19.424891 | D loss: 1.389143\n",
            "Step 5903: G loss: 21.901627 | D loss: 1.389120\n",
            "Step 5904: G loss: 22.789061 | D loss: 1.389074\n",
            "Step 5905: G loss: 18.234810 | D loss: 1.389073\n",
            "Step 5906: G loss: 22.481140 | D loss: 1.389062\n",
            "Step 5907: G loss: 15.192399 | D loss: 1.389048\n",
            "Step 5908: G loss: 27.888973 | D loss: 1.389044\n",
            "Step 5909: G loss: 21.453972 | D loss: 1.389050\n",
            "Step 5910: G loss: 17.904526 | D loss: 1.389042\n",
            "Step 5911: G loss: 26.955593 | D loss: 1.389030\n",
            "Step 5912: G loss: 31.085619 | D loss: 1.389018\n",
            "Step 5913: G loss: 21.829252 | D loss: 1.389013\n",
            "Step 5914: G loss: 20.934368 | D loss: 1.389103\n",
            "Step 5915: G loss: 23.177084 | D loss: 1.389051\n",
            "Step 5916: G loss: 25.137136 | D loss: 1.389090\n",
            "Step 5917: G loss: 24.663872 | D loss: 1.389062\n",
            "Step 5918: G loss: 23.624861 | D loss: 1.388988\n",
            "Step 5919: G loss: 22.436333 | D loss: 1.389109\n",
            "Step 5920: G loss: 20.225285 | D loss: 1.389038\n",
            "Step 5921: G loss: 23.879488 | D loss: 1.388980\n",
            "Step 5922: G loss: 22.812860 | D loss: 1.388967\n",
            "Step 5923: G loss: 25.883917 | D loss: 1.388954\n",
            "Step 5924: G loss: 12.171686 | D loss: 1.388949\n",
            "Step 5925: G loss: 20.028751 | D loss: 1.388972\n",
            "Step 5926: G loss: 38.861626 | D loss: 1.388944\n",
            "Step 5927: G loss: 17.733028 | D loss: 1.388933\n",
            "Step 5928: G loss: 26.010832 | D loss: 1.388926\n",
            "Step 5929: G loss: 24.033100 | D loss: 1.388925\n",
            "Step 5930: G loss: 23.435177 | D loss: 1.388917\n",
            "Step 5931: G loss: 30.537790 | D loss: 1.388990\n",
            "Step 5932: G loss: 23.246330 | D loss: 1.389038\n",
            "Step 5933: G loss: 21.664103 | D loss: 1.388898\n",
            "Step 5934: G loss: 18.990795 | D loss: 1.388943\n",
            "Step 5935: G loss: 30.752579 | D loss: 1.388891\n",
            "Step 5936: G loss: 24.989780 | D loss: 1.388890\n",
            "Step 5937: G loss: 27.407644 | D loss: 1.388877\n",
            "Step 5938: G loss: 25.249447 | D loss: 1.388887\n",
            "Step 5939: G loss: 20.885914 | D loss: 1.388983\n",
            "Step 5940: G loss: 19.473280 | D loss: 1.388860\n",
            "Step 5941: G loss: 24.493364 | D loss: 1.388867\n",
            "Step 5942: G loss: 25.726471 | D loss: 1.388857\n",
            "Step 5943: G loss: 30.198057 | D loss: 1.388845\n",
            "Step 5944: G loss: 21.149614 | D loss: 1.388837\n",
            "Step 5945: G loss: 26.265913 | D loss: 1.388873\n",
            "Step 5946: G loss: 23.917763 | D loss: 1.388837\n",
            "Step 5947: G loss: 24.700602 | D loss: 1.388898\n",
            "Step 5948: G loss: 17.343967 | D loss: 1.388924\n",
            "Step 5949: G loss: 31.822067 | D loss: 1.388811\n",
            "Step 5950: G loss: 34.579308 | D loss: 1.388809\n",
            "Step 5951: G loss: 20.419413 | D loss: 1.388798\n",
            "Step 5952: G loss: 27.132086 | D loss: 1.388793\n",
            "Step 5953: G loss: 18.177446 | D loss: 1.388788\n",
            "Step 5954: G loss: 26.631775 | D loss: 1.388781\n",
            "Step 5955: G loss: 22.823910 | D loss: 1.388776\n",
            "Step 5956: G loss: 20.632339 | D loss: 1.388775\n",
            "Step 5957: G loss: 22.631168 | D loss: 1.388766\n",
            "Step 5958: G loss: 23.225561 | D loss: 1.388801\n",
            "Step 5959: G loss: 23.006224 | D loss: 1.388914\n",
            "Step 5960: G loss: 33.930901 | D loss: 1.388841\n",
            "Step 5961: G loss: 28.816805 | D loss: 1.388748\n",
            "Step 5962: G loss: 22.949022 | D loss: 1.388738\n",
            "Step 5963: G loss: 25.358414 | D loss: 1.388732\n",
            "Step 5964: G loss: 19.405304 | D loss: 1.388743\n",
            "Step 5965: G loss: 18.917646 | D loss: 1.388728\n",
            "Step 5966: G loss: 21.812782 | D loss: 1.388726\n",
            "Step 5967: G loss: 34.231213 | D loss: 1.388711\n",
            "Step 5968: G loss: 28.494158 | D loss: 1.388706\n",
            "Step 5969: G loss: 28.268250 | D loss: 1.388701\n",
            "Step 5970: G loss: 23.772915 | D loss: 1.388709\n",
            "Step 5971: G loss: 23.286734 | D loss: 1.388792\n",
            "Step 5972: G loss: 39.447727 | D loss: 1.388798\n",
            "Step 5973: G loss: 30.712513 | D loss: 1.388729\n",
            "Step 5974: G loss: 25.715431 | D loss: 1.388673\n",
            "Step 5975: G loss: 20.797882 | D loss: 1.388780\n",
            "Step 5976: G loss: 24.372938 | D loss: 1.388776\n",
            "Step 5977: G loss: 28.951824 | D loss: 1.388657\n",
            "Step 5978: G loss: 31.163179 | D loss: 1.388651\n",
            "Step 5979: G loss: 29.672611 | D loss: 1.388661\n",
            "Step 5980: G loss: 21.748947 | D loss: 1.388750\n",
            "Step 5981: G loss: 26.024620 | D loss: 1.388668\n",
            "Step 5982: G loss: 33.047779 | D loss: 1.388646\n",
            "Step 5983: G loss: 20.935457 | D loss: 1.388625\n",
            "Step 5984: G loss: 25.489986 | D loss: 1.388623\n",
            "Step 5985: G loss: 26.967379 | D loss: 1.388614\n",
            "Step 5986: G loss: 16.645889 | D loss: 1.388629\n",
            "Step 5987: G loss: 26.550835 | D loss: 1.388605\n",
            "Step 5988: G loss: 21.192339 | D loss: 1.388600\n",
            "Step 5989: G loss: 20.949362 | D loss: 1.388597\n",
            "Step 5990: G loss: 27.853477 | D loss: 1.388591\n",
            "Step 5991: G loss: 19.425226 | D loss: 1.388592\n",
            "Step 5992: G loss: 20.028099 | D loss: 1.388578\n",
            "Step 5993: G loss: 16.638567 | D loss: 1.388612\n",
            "Step 5994: G loss: 25.827971 | D loss: 1.388589\n",
            "Step 5995: G loss: 17.922419 | D loss: 1.388586\n",
            "Step 5996: G loss: 21.399286 | D loss: 1.388657\n",
            "Step 5997: G loss: 29.919924 | D loss: 1.388556\n",
            "Step 5998: G loss: 16.550194 | D loss: 1.388556\n",
            "Step 5999: G loss: 28.532890 | D loss: 1.388557\n",
            "Step 6000: G loss: 30.740784 | D loss: 1.388540\n",
            "Model saved in file: /content/models/model.ckpt\n",
            "Step 6001: G loss: 25.342632 | D loss: 1.388531\n",
            "Step 6002: G loss: 21.628826 | D loss: 1.388527\n",
            "Step 6003: G loss: 25.516865 | D loss: 1.388521\n",
            "Step 6004: G loss: 21.438520 | D loss: 1.388516\n",
            "Step 6005: G loss: 32.660435 | D loss: 1.388516\n",
            "Step 6006: G loss: 23.823189 | D loss: 1.388507\n",
            "Step 6007: G loss: 26.632858 | D loss: 1.388560\n",
            "Step 6008: G loss: 18.265720 | D loss: 1.388613\n",
            "Step 6009: G loss: 21.717981 | D loss: 1.388490\n",
            "Step 6010: G loss: 34.009491 | D loss: 1.388487\n",
            "Step 6011: G loss: 22.584030 | D loss: 1.388480\n",
            "Step 6012: G loss: 34.761574 | D loss: 1.388476\n",
            "Step 6013: G loss: 20.106735 | D loss: 1.388470\n",
            "Step 6014: G loss: 18.664202 | D loss: 1.388468\n",
            "Step 6015: G loss: 17.118546 | D loss: 1.388561\n",
            "Step 6016: G loss: 21.918222 | D loss: 1.388464\n",
            "Step 6017: G loss: 20.470798 | D loss: 1.388457\n",
            "Step 6018: G loss: 22.056639 | D loss: 1.388518\n",
            "Step 6019: G loss: 29.900200 | D loss: 1.388447\n",
            "Step 6020: G loss: 23.402981 | D loss: 1.388493\n",
            "Step 6021: G loss: 26.574549 | D loss: 1.388430\n",
            "Step 6022: G loss: 20.656986 | D loss: 1.388427\n",
            "Step 6023: G loss: 26.281380 | D loss: 1.388435\n",
            "Step 6024: G loss: 29.829224 | D loss: 1.388423\n",
            "Step 6025: G loss: 18.722523 | D loss: 1.388492\n",
            "Step 6026: G loss: 29.293518 | D loss: 1.388405\n",
            "Step 6027: G loss: 19.658518 | D loss: 1.388404\n",
            "Step 6028: G loss: 30.200523 | D loss: 1.388397\n",
            "Step 6029: G loss: 19.128887 | D loss: 1.388391\n",
            "Step 6030: G loss: 30.098251 | D loss: 1.388419\n",
            "Step 6031: G loss: 31.391422 | D loss: 1.388380\n",
            "Step 6032: G loss: 19.485018 | D loss: 1.388390\n",
            "Step 6033: G loss: 23.359938 | D loss: 1.388377\n",
            "Step 6034: G loss: 28.835943 | D loss: 1.388414\n",
            "Step 6035: G loss: 17.599009 | D loss: 1.388363\n",
            "Step 6036: G loss: 25.047016 | D loss: 1.388393\n",
            "Step 6037: G loss: 28.015913 | D loss: 1.388351\n",
            "Step 6038: G loss: 29.391102 | D loss: 1.388413\n",
            "Step 6039: G loss: 25.438446 | D loss: 1.388344\n",
            "Step 6040: G loss: 23.389391 | D loss: 1.388342\n",
            "Step 6041: G loss: 31.422640 | D loss: 1.388332\n",
            "Step 6042: G loss: 18.533630 | D loss: 1.388384\n",
            "Step 6043: G loss: 34.513309 | D loss: 1.388322\n",
            "Step 6044: G loss: 20.661671 | D loss: 1.388350\n",
            "Step 6045: G loss: 20.131527 | D loss: 1.388359\n",
            "Step 6046: G loss: 24.979300 | D loss: 1.388308\n",
            "Step 6047: G loss: 19.261429 | D loss: 1.388316\n",
            "Step 6048: G loss: 20.942795 | D loss: 1.388298\n",
            "Step 6049: G loss: 27.199110 | D loss: 1.388293\n",
            "Step 6050: G loss: 24.587709 | D loss: 1.388292\n",
            "Step 6051: G loss: 25.348703 | D loss: 1.388298\n",
            "Step 6052: G loss: 19.999149 | D loss: 1.388279\n",
            "Step 6053: G loss: 18.221863 | D loss: 1.388274\n",
            "Step 6054: G loss: 23.611887 | D loss: 1.388271\n",
            "Step 6055: G loss: 28.387033 | D loss: 1.388301\n",
            "Step 6056: G loss: 20.656317 | D loss: 1.388261\n",
            "Step 6057: G loss: 18.981657 | D loss: 1.388256\n",
            "Step 6058: G loss: 24.987694 | D loss: 1.388254\n",
            "Step 6059: G loss: 20.506355 | D loss: 1.388246\n",
            "Step 6060: G loss: 22.243380 | D loss: 1.388281\n",
            "Step 6061: G loss: 27.797472 | D loss: 1.388251\n",
            "Step 6062: G loss: 32.045170 | D loss: 1.388287\n",
            "Step 6063: G loss: 17.555946 | D loss: 1.388279\n",
            "Step 6064: G loss: 30.796997 | D loss: 1.388264\n",
            "Step 6065: G loss: 31.522663 | D loss: 1.388218\n",
            "Step 6066: G loss: 28.352425 | D loss: 1.388213\n",
            "Step 6067: G loss: 26.215067 | D loss: 1.388208\n",
            "Step 6068: G loss: 20.368313 | D loss: 1.388205\n",
            "Step 6069: G loss: 23.652088 | D loss: 1.388206\n",
            "Step 6070: G loss: 22.049303 | D loss: 1.388195\n",
            "Step 6071: G loss: 17.285975 | D loss: 1.388254\n",
            "Step 6072: G loss: 17.643150 | D loss: 1.388190\n",
            "Step 6073: G loss: 26.166845 | D loss: 1.388249\n",
            "Step 6074: G loss: 28.125334 | D loss: 1.388214\n",
            "Step 6075: G loss: 17.277473 | D loss: 1.388181\n",
            "Step 6076: G loss: 17.290503 | D loss: 1.388168\n",
            "Step 6077: G loss: 26.149302 | D loss: 1.388161\n",
            "Step 6078: G loss: 20.186470 | D loss: 1.388157\n",
            "Step 6079: G loss: 25.902733 | D loss: 1.388165\n",
            "Step 6080: G loss: 18.315174 | D loss: 1.388148\n",
            "Step 6081: G loss: 18.560371 | D loss: 1.388175\n",
            "Step 6082: G loss: 21.768534 | D loss: 1.388141\n",
            "Step 6083: G loss: 23.957008 | D loss: 1.388135\n",
            "Step 6084: G loss: 25.110220 | D loss: 1.388165\n",
            "Step 6085: G loss: 24.051544 | D loss: 1.388188\n",
            "Step 6086: G loss: 19.964779 | D loss: 1.388140\n",
            "Step 6087: G loss: 24.489340 | D loss: 1.388149\n",
            "Step 6088: G loss: 24.448164 | D loss: 1.388112\n",
            "Step 6089: G loss: 23.365442 | D loss: 1.388103\n",
            "Step 6090: G loss: 36.823296 | D loss: 1.388131\n",
            "Step 6091: G loss: 19.529692 | D loss: 1.388105\n",
            "Step 6092: G loss: 23.366798 | D loss: 1.388146\n",
            "Step 6093: G loss: 20.709110 | D loss: 1.388096\n",
            "Step 6094: G loss: 21.164623 | D loss: 1.388117\n",
            "Step 6095: G loss: 27.308464 | D loss: 1.388080\n",
            "Step 6096: G loss: 25.574535 | D loss: 1.388087\n",
            "Step 6097: G loss: 25.354921 | D loss: 1.388072\n",
            "Step 6098: G loss: 21.538876 | D loss: 1.388074\n",
            "Step 6099: G loss: 24.779181 | D loss: 1.388064\n",
            "Step 6100: G loss: 24.814875 | D loss: 1.388059\n",
            "Step 6101: G loss: 22.840630 | D loss: 1.388092\n",
            "Step 6102: G loss: 21.480730 | D loss: 1.388099\n",
            "Step 6103: G loss: 21.032560 | D loss: 1.388101\n",
            "Step 6104: G loss: 27.634974 | D loss: 1.388041\n",
            "Step 6105: G loss: 36.520748 | D loss: 1.388044\n",
            "Step 6106: G loss: 24.745699 | D loss: 1.388034\n",
            "Step 6107: G loss: 25.376535 | D loss: 1.388028\n",
            "Step 6108: G loss: 38.154724 | D loss: 1.388023\n",
            "Step 6109: G loss: 24.874254 | D loss: 1.388019\n",
            "Step 6110: G loss: 29.290314 | D loss: 1.388015\n",
            "Step 6111: G loss: 23.309200 | D loss: 1.388069\n",
            "Step 6112: G loss: 17.039183 | D loss: 1.388006\n",
            "Step 6113: G loss: 23.082170 | D loss: 1.388014\n",
            "Step 6114: G loss: 19.683626 | D loss: 1.387997\n",
            "Step 6115: G loss: 21.625015 | D loss: 1.387993\n",
            "Step 6116: G loss: 19.892406 | D loss: 1.387994\n",
            "Step 6117: G loss: 23.095636 | D loss: 1.387984\n",
            "Step 6118: G loss: 31.199438 | D loss: 1.387980\n",
            "Step 6119: G loss: 26.946157 | D loss: 1.388024\n",
            "Step 6120: G loss: 24.823679 | D loss: 1.387972\n",
            "Step 6121: G loss: 17.334202 | D loss: 1.387967\n",
            "Step 6122: G loss: 25.234184 | D loss: 1.387980\n",
            "Step 6123: G loss: 23.718828 | D loss: 1.387959\n",
            "Step 6124: G loss: 28.320032 | D loss: 1.387955\n",
            "Step 6125: G loss: 17.734938 | D loss: 1.387954\n",
            "Step 6126: G loss: 22.347996 | D loss: 1.387972\n",
            "Step 6127: G loss: 34.689972 | D loss: 1.387943\n",
            "Step 6128: G loss: 20.334845 | D loss: 1.387976\n",
            "Step 6129: G loss: 24.196697 | D loss: 1.387934\n",
            "Step 6130: G loss: 17.318289 | D loss: 1.387944\n",
            "Step 6131: G loss: 30.590374 | D loss: 1.387925\n",
            "Step 6132: G loss: 23.357296 | D loss: 1.387964\n",
            "Step 6133: G loss: 22.054905 | D loss: 1.387925\n",
            "Step 6134: G loss: 32.625988 | D loss: 1.387941\n",
            "Step 6135: G loss: 18.469091 | D loss: 1.387916\n",
            "Step 6136: G loss: 24.770948 | D loss: 1.387905\n",
            "Step 6137: G loss: 23.661980 | D loss: 1.387943\n",
            "Step 6138: G loss: 21.354362 | D loss: 1.387895\n",
            "Step 6139: G loss: 24.985083 | D loss: 1.387892\n",
            "Step 6140: G loss: 34.466122 | D loss: 1.387888\n",
            "Step 6141: G loss: 26.951159 | D loss: 1.387884\n",
            "Step 6142: G loss: 35.366478 | D loss: 1.387880\n",
            "Step 6143: G loss: 28.748030 | D loss: 1.387876\n",
            "Step 6144: G loss: 23.848106 | D loss: 1.387877\n",
            "Step 6145: G loss: 23.597795 | D loss: 1.387893\n",
            "Step 6146: G loss: 22.275024 | D loss: 1.387864\n",
            "Step 6147: G loss: 22.742172 | D loss: 1.387862\n",
            "Step 6148: G loss: 25.176165 | D loss: 1.387858\n",
            "Step 6149: G loss: 25.706463 | D loss: 1.387853\n",
            "Step 6150: G loss: 28.515610 | D loss: 1.387854\n",
            "Step 6151: G loss: 19.652449 | D loss: 1.387844\n",
            "Step 6152: G loss: 22.662884 | D loss: 1.387841\n",
            "Step 6153: G loss: 20.977749 | D loss: 1.387836\n",
            "Step 6154: G loss: 23.893208 | D loss: 1.387832\n",
            "Step 6155: G loss: 16.436377 | D loss: 1.387827\n",
            "Step 6156: G loss: 29.001654 | D loss: 1.387828\n",
            "Step 6157: G loss: 30.956345 | D loss: 1.387827\n",
            "Step 6158: G loss: 26.972078 | D loss: 1.387815\n",
            "Step 6159: G loss: 27.824282 | D loss: 1.387812\n",
            "Step 6160: G loss: 25.732925 | D loss: 1.387774\n",
            "Step 6161: G loss: 24.039724 | D loss: 1.387804\n",
            "Step 6162: G loss: 22.649107 | D loss: 1.387800\n",
            "Step 6163: G loss: 20.510723 | D loss: 1.387806\n",
            "Step 6164: G loss: 19.723881 | D loss: 1.387806\n",
            "Step 6165: G loss: 30.068851 | D loss: 1.387788\n",
            "Step 6166: G loss: 26.008774 | D loss: 1.387790\n",
            "Step 6167: G loss: 19.935965 | D loss: 1.387781\n",
            "Step 6168: G loss: 27.329758 | D loss: 1.387779\n",
            "Step 6169: G loss: 21.453287 | D loss: 1.387773\n",
            "Step 6170: G loss: 21.187674 | D loss: 1.387769\n",
            "Step 6171: G loss: 22.695335 | D loss: 1.387775\n",
            "Step 6172: G loss: 25.141888 | D loss: 1.387762\n",
            "Step 6173: G loss: 23.925602 | D loss: 1.387782\n",
            "Step 6174: G loss: 26.668388 | D loss: 1.387752\n",
            "Step 6175: G loss: 30.233377 | D loss: 1.387750\n",
            "Step 6176: G loss: 17.243654 | D loss: 1.387746\n",
            "Step 6177: G loss: 20.889404 | D loss: 1.387742\n",
            "Step 6178: G loss: 21.682978 | D loss: 1.387739\n",
            "Step 6179: G loss: 30.096628 | D loss: 1.387779\n",
            "Step 6180: G loss: 29.738661 | D loss: 1.387730\n",
            "Step 6181: G loss: 28.538235 | D loss: 1.387729\n",
            "Step 6182: G loss: 20.566105 | D loss: 1.387726\n",
            "Step 6183: G loss: 18.468348 | D loss: 1.387703\n",
            "Step 6184: G loss: 24.601988 | D loss: 1.387715\n",
            "Step 6185: G loss: 27.131992 | D loss: 1.387711\n",
            "Step 6186: G loss: 24.500675 | D loss: 1.387708\n",
            "Step 6187: G loss: 28.837732 | D loss: 1.387741\n",
            "Step 6188: G loss: 26.958429 | D loss: 1.387702\n",
            "Step 6189: G loss: 27.945253 | D loss: 1.387698\n",
            "Step 6190: G loss: 29.854286 | D loss: 1.387692\n",
            "Step 6191: G loss: 27.636358 | D loss: 1.387711\n",
            "Step 6192: G loss: 19.617201 | D loss: 1.387686\n",
            "Step 6193: G loss: 22.991348 | D loss: 1.387679\n",
            "Step 6194: G loss: 32.667725 | D loss: 1.387713\n",
            "Step 6195: G loss: 26.246960 | D loss: 1.387684\n",
            "Step 6196: G loss: 22.546797 | D loss: 1.387671\n",
            "Step 6197: G loss: 29.552437 | D loss: 1.387669\n",
            "Step 6198: G loss: 22.946419 | D loss: 1.387662\n",
            "Step 6199: G loss: 24.134493 | D loss: 1.387659\n",
            "Step 6200: G loss: 20.439873 | D loss: 1.387661\n",
            "Step 6201: G loss: 17.878658 | D loss: 1.387652\n",
            "Step 6202: G loss: 24.581118 | D loss: 1.387649\n",
            "Step 6203: G loss: 25.756617 | D loss: 1.387644\n",
            "Step 6204: G loss: 23.088802 | D loss: 1.387641\n",
            "Step 6205: G loss: 22.934366 | D loss: 1.387637\n",
            "Step 6206: G loss: 27.294550 | D loss: 1.387634\n",
            "Step 6207: G loss: 25.436680 | D loss: 1.387630\n",
            "Step 6208: G loss: 32.412518 | D loss: 1.387628\n",
            "Step 6209: G loss: 27.312275 | D loss: 1.387654\n",
            "Step 6210: G loss: 28.871229 | D loss: 1.387620\n",
            "Step 6211: G loss: 31.548090 | D loss: 1.387627\n",
            "Step 6212: G loss: 27.435719 | D loss: 1.387612\n",
            "Step 6213: G loss: 20.657106 | D loss: 1.387617\n",
            "Step 6214: G loss: 24.939837 | D loss: 1.387598\n",
            "Step 6215: G loss: 23.201811 | D loss: 1.387609\n",
            "Step 6216: G loss: 21.463657 | D loss: 1.387601\n",
            "Step 6217: G loss: 22.815746 | D loss: 1.387600\n",
            "Step 6218: G loss: 20.713591 | D loss: 1.387602\n",
            "Step 6219: G loss: 24.368372 | D loss: 1.387591\n",
            "Step 6220: G loss: 20.871281 | D loss: 1.387560\n",
            "Step 6221: G loss: 20.252810 | D loss: 1.387580\n",
            "Step 6222: G loss: 23.492617 | D loss: 1.387604\n",
            "Step 6223: G loss: 25.968367 | D loss: 1.387576\n",
            "Step 6224: G loss: 31.329540 | D loss: 1.387579\n",
            "Step 6225: G loss: 27.676208 | D loss: 1.387551\n",
            "Step 6226: G loss: 21.122049 | D loss: 1.387562\n",
            "Step 6227: G loss: 26.908041 | D loss: 1.387559\n",
            "Step 6228: G loss: 25.868132 | D loss: 1.387556\n",
            "Step 6229: G loss: 31.209410 | D loss: 1.387554\n",
            "Step 6230: G loss: 27.212971 | D loss: 1.387564\n",
            "Step 6231: G loss: 24.753654 | D loss: 1.387545\n",
            "Step 6232: G loss: 20.163803 | D loss: 1.387571\n",
            "Step 6233: G loss: 21.169724 | D loss: 1.387539\n",
            "Step 6234: G loss: 20.015821 | D loss: 1.387539\n",
            "Step 6235: G loss: 17.717524 | D loss: 1.387531\n",
            "Step 6236: G loss: 25.095665 | D loss: 1.387527\n",
            "Step 6237: G loss: 19.068220 | D loss: 1.387554\n",
            "Step 6238: G loss: 26.724249 | D loss: 1.387521\n",
            "Step 6239: G loss: 23.153975 | D loss: 1.387532\n",
            "Step 6240: G loss: 20.141245 | D loss: 1.387514\n",
            "Step 6241: G loss: 25.938465 | D loss: 1.387510\n",
            "Step 6242: G loss: 33.040649 | D loss: 1.387508\n",
            "Step 6243: G loss: 23.343288 | D loss: 1.387499\n",
            "Step 6244: G loss: 21.699306 | D loss: 1.387475\n",
            "Step 6245: G loss: 18.377848 | D loss: 1.387497\n",
            "Step 6246: G loss: 25.732578 | D loss: 1.387494\n",
            "Step 6247: G loss: 29.373533 | D loss: 1.387503\n",
            "Step 6248: G loss: 34.577118 | D loss: 1.387487\n",
            "Step 6249: G loss: 24.665852 | D loss: 1.387477\n",
            "Step 6250: G loss: 24.598404 | D loss: 1.387481\n",
            "Step 6251: G loss: 24.433058 | D loss: 1.387477\n",
            "Step 6252: G loss: 21.205446 | D loss: 1.387474\n",
            "Step 6253: G loss: 23.603344 | D loss: 1.387471\n",
            "Step 6254: G loss: 19.576046 | D loss: 1.387472\n",
            "Step 6255: G loss: 27.181774 | D loss: 1.387464\n",
            "Step 6256: G loss: 28.500746 | D loss: 1.387447\n",
            "Step 6257: G loss: 27.843548 | D loss: 1.387458\n",
            "Step 6258: G loss: 19.376936 | D loss: 1.387461\n",
            "Step 6259: G loss: 18.668354 | D loss: 1.387451\n",
            "Step 6260: G loss: 29.695753 | D loss: 1.387448\n",
            "Step 6261: G loss: 28.593979 | D loss: 1.387444\n",
            "Step 6262: G loss: 33.572952 | D loss: 1.387447\n",
            "Step 6263: G loss: 20.746719 | D loss: 1.387439\n",
            "Step 6264: G loss: 24.449762 | D loss: 1.387435\n",
            "Step 6265: G loss: 23.698355 | D loss: 1.387429\n",
            "Step 6266: G loss: 24.845156 | D loss: 1.387429\n",
            "Step 6267: G loss: 21.489098 | D loss: 1.387426\n",
            "Step 6268: G loss: 24.700878 | D loss: 1.387434\n",
            "Step 6269: G loss: 21.741648 | D loss: 1.387432\n",
            "Step 6270: G loss: 21.175692 | D loss: 1.387413\n",
            "Step 6271: G loss: 28.094095 | D loss: 1.387398\n",
            "Step 6272: G loss: 15.596733 | D loss: 1.387409\n",
            "Step 6273: G loss: 18.783588 | D loss: 1.387415\n",
            "Step 6274: G loss: 32.860477 | D loss: 1.387396\n",
            "Step 6275: G loss: 24.108183 | D loss: 1.387400\n",
            "Step 6276: G loss: 20.201122 | D loss: 1.387383\n",
            "Step 6277: G loss: 34.194729 | D loss: 1.387386\n",
            "Step 6278: G loss: 21.953165 | D loss: 1.387390\n",
            "Step 6279: G loss: 20.249229 | D loss: 1.387389\n",
            "Step 6280: G loss: 17.847120 | D loss: 1.387387\n",
            "Step 6281: G loss: 24.153057 | D loss: 1.387388\n",
            "Step 6282: G loss: 22.231146 | D loss: 1.387372\n",
            "Step 6283: G loss: 17.387136 | D loss: 1.387367\n",
            "Step 6284: G loss: 21.346859 | D loss: 1.387372\n",
            "Step 6285: G loss: 16.447086 | D loss: 1.387369\n",
            "Step 6286: G loss: 27.592455 | D loss: 1.387365\n",
            "Step 6287: G loss: 21.358612 | D loss: 1.387355\n",
            "Step 6288: G loss: 17.145718 | D loss: 1.387359\n",
            "Step 6289: G loss: 22.601526 | D loss: 1.387357\n",
            "Step 6290: G loss: 31.155560 | D loss: 1.387352\n",
            "Step 6291: G loss: 20.418488 | D loss: 1.387350\n",
            "Step 6292: G loss: 20.874134 | D loss: 1.387343\n",
            "Step 6293: G loss: 21.483860 | D loss: 1.387346\n",
            "Step 6294: G loss: 21.893019 | D loss: 1.387349\n",
            "Step 6295: G loss: 23.855522 | D loss: 1.387349\n",
            "Step 6296: G loss: 24.353939 | D loss: 1.387335\n",
            "Step 6297: G loss: 20.997816 | D loss: 1.387348\n",
            "Step 6298: G loss: 21.493919 | D loss: 1.387330\n",
            "Step 6299: G loss: 23.459242 | D loss: 1.387313\n",
            "Step 6300: G loss: 21.811628 | D loss: 1.387324\n",
            "Step 6301: G loss: 23.116192 | D loss: 1.387320\n",
            "Step 6302: G loss: 12.246391 | D loss: 1.387317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d2fe94d4bf44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;31m# normalize because generator use tanh activation in its output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgloss_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step %d: G loss: %f | D loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgloss_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-dc026b8cf05c>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, sess, g_inputs, d_inputs_a, d_inputs_b, is_training)\u001b[0m\n\u001b[1;32m     30\u001b[0m             feed_dict={self._d_inputs_a : d_inputs_a, self._d_inputs_b : d_inputs_b, self._g_inputs : g_inputs, self._is_training : is_training})\n\u001b[1;32m     31\u001b[0m         _, gloss_curr = sess.run([self._g_train_step, self._g_loss],\n\u001b[0;32m---> 32\u001b[0;31m                 feed_dict={self._g_inputs : g_inputs, self._d_inputs_a : d_inputs_a,   self._d_inputs_b : d_inputs_b,self._is_training : is_training})\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgloss_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzwcuUpK31A"
      },
      "source": [
        "# example of loading a pix2pix model and using it for one-off image translation\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# load an image\n",
        "def load_image(filename, size=(256,256)):\n",
        "\t# load image with the preferred size\n",
        "\tpixels = load_img(filename, target_size=size)\n",
        "\t# convert to numpy array\n",
        "\tpixels = img_to_array(pixels)\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tpixels = (pixels - 127.5) / 127.5\n",
        "\t# reshape to 1 sample\n",
        "\tpixels = expand_dims(pixels, 0)\n",
        "\treturn pixels\n",
        " \n",
        "# load source image\n",
        "src_image = load_image('satellite.jpg')\n",
        "print('Loaded', src_image.shape)\n",
        "# load model\n",
        "model = load_model('model_109600.h5')\n",
        "# generate image from source\n",
        "gen_image = model.predict(src_image)\n",
        "# scale from [-1,1] to [0,1]\n",
        "gen_image = (gen_image + 1) / 2.0\n",
        "# plot the image\n",
        "pyplot.imshow(gen_image[0])\n",
        "pyplot.axis('off')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}